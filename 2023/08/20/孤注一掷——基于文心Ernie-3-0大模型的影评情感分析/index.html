<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>孤注一掷——基于文心Ernie-3.0大模型的影评情感分析 | 咋的个人博客</title><meta name="author" content="咋"><meta name="copyright" content="咋"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="孤注一掷——基于文心Ernie-3.0大模型的影评情感分析写在前面前些天看了《孤注一掷》，感觉是一个很不错的电影，狠狠劝赌！  人有两颗心，一颗贪心，一颗不甘心，诱惑的背后只有陷阱，恐惧的尽头只剩绝望。  希望大家提高防诈骗意识，别信，别贪，别冲动！  这个项目使用文言一心大模型，对爬取的电影评论数据进行小样本的预训练学习。  使用Ernie-3.0-medium-zh大模型（感谢三岁大佬），为百">
<meta property="og:type" content="article">
<meta property="og:title" content="孤注一掷——基于文心Ernie-3.0大模型的影评情感分析">
<meta property="og:url" content="https://www.lizhiyang.xyz/2023/08/20/%E5%AD%A4%E6%B3%A8%E4%B8%80%E6%8E%B7%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E6%96%87%E5%BF%83Ernie-3-0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E8%AF%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/index.html">
<meta property="og:site_name" content="咋的个人博客">
<meta property="og:description" content="孤注一掷——基于文心Ernie-3.0大模型的影评情感分析写在前面前些天看了《孤注一掷》，感觉是一个很不错的电影，狠狠劝赌！  人有两颗心，一颗贪心，一颗不甘心，诱惑的背后只有陷阱，恐惧的尽头只剩绝望。  希望大家提高防诈骗意识，别信，别贪，别冲动！  这个项目使用文言一心大模型，对爬取的电影评论数据进行小样本的预训练学习。  使用Ernie-3.0-medium-zh大模型（感谢三岁大佬），为百">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic-bed-ar2.pages.dev/img/13.jpg">
<meta property="article:published_time" content="2023-08-20T12:00:00.000Z">
<meta property="article:modified_time" content="2023-08-20T12:30:00.000Z">
<meta property="article:author" content="咋">
<meta property="article:tag" content="深度学习,Java,Python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic-bed-ar2.pages.dev/img/13.jpg"><link rel="shortcut icon" href="https://pic-bed-ar2.pages.dev/img/11.jpg"><link rel="canonical" href="https://www.lizhiyang.xyz/2023/08/20/%E5%AD%A4%E6%B3%A8%E4%B8%80%E6%8E%B7%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E6%96%87%E5%BF%83Ernie-3-0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E8%AF%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: true,
    post: true
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"top-right"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '孤注一掷——基于文心Ernie-3.0大模型的影评情感分析',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-08-20 20:30:00'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const now = new Date()
          const hour = now.getHours()
          const isNight = hour <= 6 || hour >= 18
          if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
          else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic-bed-ar2.pages.dev/img/12.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 和贝贝</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://pic-bed-ar2.pages.dev/img/13.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="咋的个人博客"><span class="site-name">咋的个人博客</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 文章</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 和贝贝</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 清单</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 电影</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">孤注一掷——基于文心Ernie-3.0大模型的影评情感分析</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-20T12:00:00.000Z" title="发表于 2023-08-20 20:00:00">2023-08-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-08-20T12:30:00.000Z" title="更新于 2023-08-20 20:30:00">2023-08-20</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="孤注一掷——基于文心Ernie-3.0大模型的影评情感分析"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="孤注一掷——基于文心Ernie-3-0大模型的影评情感分析"><a href="#孤注一掷——基于文心Ernie-3-0大模型的影评情感分析" class="headerlink" title="孤注一掷——基于文心Ernie-3.0大模型的影评情感分析"></a>孤注一掷——基于文心Ernie-3.0大模型的影评情感分析</h1><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>前些天看了<font size=4 color=green><strong>《孤注一掷》</strong></font>，感觉是一个很不错的电影，<strong>狠狠劝赌！</strong></p>
<ul>
<li><p>人有两颗心，一颗贪心，一颗不甘心，诱惑的背后只有陷阱，恐惧的尽头只剩绝望。</p>
</li>
<li><p>希望大家提高防诈骗意识，<strong>别信，别贪，别冲动！</strong><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/e3986421f0364fc0b47fa0c5b95f24a9aa5d01b9a77d4f998755d6e60410e932"></p>
</li>
<li><p>这个项目使用文言一心大模型，对爬取的电影评论数据进行小样本的预训练学习。</p>
</li>
<li><p>使用<strong>Ernie-3.0-medium-zh</strong>大模型（感谢三岁大佬），为百亿参数知识增强的大模型，能够快速解决中文数据学习困难，准确率低的问题。</p>
</li>
<li><p>项目环境：<code>PaddlePaddle2.4.0</code>，<code>PaddleNLP2.4.2</code></p>
</li>
</ul>
<h2 id="一、数据直观可视化"><a href="#一、数据直观可视化" class="headerlink" title="一、数据直观可视化"></a>一、数据直观可视化</h2><p>电影《孤注一掷》豆瓣短评数据信息如下（感谢马哥<code>公众号老男孩的平凡之路</code>）</p>
<ul>
<li>共30页，600条数据</li>
<li>含6个字段：页码,评论者昵称,评论星级（1-5星）,评论时间,评论者IP属地,评论内容</li>
<li>豆瓣短评页面上最多显示30页，再往后翻页就会显示“加载中”，获取不到后面的数据，所以只有30页</li>
<li>对数据进行简单的处理，由于涉及到情感分类，将评星低于三星的认为差评，等于三星的认为中立，高于三星的认为好评</li>
</ul>
<h3 id="1-1-各评价所占人数"><a href="#1-1-各评价所占人数" class="headerlink" title="1.1 各评价所占人数"></a>1.1 各评价所占人数</h3><p>由于存在一定误差（比如三星的评论可能是好评也可能是差评，低于三星的评论也可能是好评，还有一些没有价值的评论），故用误差棒使结果更加严谨，从数据中统计可得：</p>
<ul>
<li><code>好评</code>：218人</li>
<li><code>中立</code>：159人</li>
<li><code>差评</code>：223人<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/f3094d266cac4b96839167444a84d038aa429243a11a4b4887c24c9750a00d86"></li>
</ul>
<p>可以看出三个评价的人数<code>基本相近</code></p>
<h3 id="1-2-词云可视化"><a href="#1-2-词云可视化" class="headerlink" title="1.2 词云可视化"></a>1.2 词云可视化</h3><ul>
<li><p>词云可视化可以帮助用户快速识别影评中的关键词和热门话题。通过将频率较高的词语放大显示，用户可以一目了然地了解影评的主题和重点。</p>
</li>
<li><p>我将背景设置成一个骷髅，不知道大家能不能看出来<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/2d9ee553231848e3982bbf4a0380626b98331e631c1c4d8bb1162068257a4eea"></p>
</li>
<li><p>由于aistudio里面词云字体会出现打不开的情况，所有我是在本地跑的，现在将代码贴在这里，感兴趣的小伙伴可以copy下来在自己的本地环境里面跑一下。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud  <span class="comment"># 词云库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt  <span class="comment"># 数学绘图库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读数据</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;output.txt&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    text = f.read()</span><br><span class="line"></span><br><span class="line">mask = np.array(Image.<span class="built_in">open</span>(<span class="string">&quot;img_7.png&quot;</span>))</span><br><span class="line">wc1 = WordCloud(</span><br><span class="line">    background_color=<span class="string">&quot;white&quot;</span>,  <span class="comment"># 背景为白色</span></span><br><span class="line">    font_path=<span class="string">&#x27;C:/Windows/Fonts/msyh.ttc&#x27;</span>,  <span class="comment"># 使用的字体库:当前字体支持中文</span></span><br><span class="line">    max_words=<span class="number">2000</span>,  <span class="comment"># 最大显示的关键词数量</span></span><br><span class="line">    width=<span class="number">1000</span>,  <span class="comment"># 生成词云的宽</span></span><br><span class="line">    height=<span class="number">860</span>,  <span class="comment"># 生成词云的高</span></span><br><span class="line">    collocations=<span class="literal">False</span>,  <span class="comment"># 解决关键词重复：是否包括两个词的搭配</span></span><br><span class="line">    mask=mask</span><br><span class="line">    <span class="comment"># stopwords=STOPWORDS, #屏蔽的内容</span></span><br><span class="line">)</span><br><span class="line">wc2 = wc1.generate(text)</span><br><span class="line"></span><br><span class="line">plt.imshow(wc2)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;词云.jpg&#x27;</span>, dpi=<span class="number">2600</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**&lt;font size=<span class="number">6</span> color=green&gt;接下来正式开始大模型之旅！**</span><br><span class="line"></span><br><span class="line"><span class="comment">## 二、更新PaddleNLP</span></span><br><span class="line">`clear_output`主要是为了清除输出信息，对更新没有影响，为了最后项目的美观，所以在最后加上了一句 `clear_output`</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># 清除输出，使项目更清晰</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> clear_output</span><br><span class="line">!pip install paddlenlp==<span class="number">2.4</span><span class="number">.2</span> -i https://pypi.org/simple</span><br><span class="line"><span class="comment"># 清除输出</span></span><br><span class="line">clear_output()</span><br></pre></td></tr></table></figure></li>
</ul>
<p>查看版本号是否正确</p>
<ul>
<li><code>paddlepaddle</code>的版本为<code>2.4.0</code>，<code>paddlenlp</code>的版本为<code>2.4.2</code></li>
<li>如果版本不匹配的话可能后面会出现cannot import name <code>&#39;AutoModelForSequenceclassification&#39; from paddlenlp.transfomers</code>的错误</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddlenlp</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;paddle版本&quot;</span>,paddle.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;paddlenlp版本&quot;</span>,paddlenlp.__version__)</span><br></pre></td></tr></table></figure>

<pre><code>paddle版本 2.4.0
paddlenlp版本 2.4.2
</code></pre>
<h2 id="二、数据处理"><a href="#二、数据处理" class="headerlink" title="二、数据处理"></a>二、数据处理</h2><ul>
<li>利用&#96;正则表达式清理数据</li>
<li>利用<code>paddlenlp.datasets</code>中的 <code>DatasetBuilder</code>函数对数据进行处理</li>
<li>数据变成了[{‘text_a’: ‘data’, ‘label’: label},……] 的格式</li>
</ul>
<h3 id="2-1-清洗数据"><a href="#2-1-清洗数据" class="headerlink" title="2.1 清洗数据"></a>2.1 清洗数据</h3><ul>
<li>使用<code>正则表达式</code>去除音频中的中文标点符号，并和标签一起写入txt文件中</li>
<li>用到的正则表达式为<code> re.sub(r&#39;[^\u4e00-\u9fa5a-zA-Z0-9\s]+&#39;, &#39; &#39;, content)</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 读取CSV文件</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;data.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 遍历每一行，将内容存入txt文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;output.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        content = row[<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">        content =  re.sub(<span class="string">r&#x27;[^\u4e00-\u9fa5a-zA-Z0-9\s]+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, content)</span><br><span class="line">        label = row[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">        file.write(<span class="string">f&quot;<span class="subst">&#123;label&#125;</span>\t<span class="subst">&#123;content&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>清洗完的数据如下：</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/4baf88211b974dbb86dc4bc5fc10d8503606abaf10ef4ec490d3ce2b36ead0c5"></p>
<h3 id="2-2-划分数据集"><a href="#2-2-划分数据集" class="headerlink" title="2.2 划分数据集"></a>2.2 划分数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取output.txt文件中的内容</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;output.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    lines = file.readlines()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机打乱数据</span></span><br><span class="line">random.shuffle(lines)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算切分的索引</span></span><br><span class="line">total_lines = <span class="built_in">len</span>(lines)</span><br><span class="line">train_end = <span class="built_in">int</span>(total_lines * <span class="number">0.7</span>)</span><br><span class="line">validation_end = <span class="built_in">int</span>(total_lines * <span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切分数据</span></span><br><span class="line">train_data = lines[:train_end]</span><br><span class="line">validation_data = lines[train_end:validation_end]</span><br><span class="line">test_data = lines[validation_end:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据写入train.txt</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;train.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.writelines(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据写入validation.txt</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;validation.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.writelines(validation_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据写入test.txt</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;test.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.writelines(test_data)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="2-3-加载数据"><a href="#2-3-加载数据" class="headerlink" title="2.3 加载数据"></a>2.3 加载数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入DatasetBuilder</span></span><br><span class="line"><span class="keyword">from</span> paddlenlp.datasets <span class="keyword">import</span> DatasetBuilder</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NewsData</span>(<span class="title class_ inherited__">DatasetBuilder</span>):</span><br><span class="line">    SPLITS = &#123;</span><br><span class="line">        <span class="string">&#x27;train&#x27;</span>: <span class="string">&#x27;/home/aistudio/train.txt&#x27;</span>,  <span class="comment"># 训练集</span></span><br><span class="line">        <span class="string">&#x27;dev&#x27;</span>: <span class="string">&#x27;/home/aistudio/validation.txt&#x27;</span>,      <span class="comment"># 验证集</span></span><br><span class="line">        <span class="string">&#x27;test&#x27;</span>: <span class="string">&#x27;/home/aistudio/test.txt&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_data</span>(<span class="params">self, mode, **kwargs</span>):</span><br><span class="line">        filename = self.SPLITS[mode]</span><br><span class="line">        <span class="keyword">return</span> filename</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_read</span>(<span class="params">self, filename</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;读取数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                <span class="keyword">if</span> line == <span class="string">&#x27;\n&#x27;</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                data = line.strip().split(<span class="string">&quot;\t&quot;</span>)    <span class="comment"># 以&#x27;\t&#x27;分隔各列</span></span><br><span class="line">                label, text_a = data</span><br><span class="line">                text_a = text_a.replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> label <span class="keyword">in</span> [<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>]:</span><br><span class="line">                    <span class="keyword">yield</span> &#123;<span class="string">&quot;text_a&quot;</span>: text_a, <span class="string">&quot;label&quot;</span>: label&#125;  <span class="comment"># 此次设置数据的格式为：text_a,label，可以根据具体情况进行修改</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_labels</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> label_list   <span class="comment"># 类别标签</span></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义数据集加载函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_dataset</span>(<span class="params">name=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 data_files=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 splits=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 lazy=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 **kwargs</span>):</span><br><span class="line">   </span><br><span class="line">    reader_cls = NewsData  <span class="comment"># 加载定义的数据集格式</span></span><br><span class="line">    <span class="built_in">print</span>(reader_cls)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> name:</span><br><span class="line">        reader_instance = reader_cls(lazy=lazy, **kwargs)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        reader_instance = reader_cls(lazy=lazy, name=name, **kwargs)</span><br><span class="line">    datasets = reader_instance.read_datasets(data_files=data_files, splits=splits)</span><br><span class="line">    <span class="keyword">return</span> datasets</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载训练和验证集</span></span><br><span class="line">label_list = [<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>]</span><br><span class="line">train_ds, dev_ds, text_t = load_dataset(splits=[<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;dev&#x27;</span>, <span class="string">&#x27;test&#x27;</span>])</span><br></pre></td></tr></table></figure>

<pre><code>&lt;class &#39;__main__.NewsData&#39;&gt;
</code></pre>
<h3 id="2-4-展示数据"><a href="#2-4-展示数据" class="headerlink" title="2.4 展示数据"></a>2.4 展示数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_ds[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>




<pre><code>[&#123;&#39;text_a&#39;: &#39;人有两颗心一颗是贪心一颗是不甘心&#39;, &#39;label&#39;: 0&#125;,
 &#123;&#39;text_a&#39;: &#39;一边张灯结彩一边天人永别太讽刺了&#39;, &#39;label&#39;: 0&#125;,
 &#123;&#39;text_a&#39;: &#39;C从我自己的观影感受里就可以感知到观众对于真正的中国犯罪电影有多么的渴望犯罪链条上每一个奇观展现都让我觉得抓眼带感这不是所谓的短视频猎奇而是我们真的想要看国内电影里存在这样的东西一些陆家嘴之狼CBD风云最大的问题当然是没有人物也没有主题为正的导向更是让它不可能具有任何的人性深度但值得肯定的是申奥还是一定程度上把人对金钱的狂热拍了出来&#39;,
  &#39;label&#39;: 0&#125;,
 &#123;&#39;text_a&#39;: &#39;暑期档继续发疯紧张刺激&#39;, &#39;label&#39;: 0&#125;,
 &#123;&#39;text_a&#39;: &#39;请不要在反诈宣传片里插播偶像剧&#39;, &#39;label&#39;: 1&#125;]
</code></pre>
<h2 id="三、RNIE-3-0文心大模型"><a href="#三、RNIE-3-0文心大模型" class="headerlink" title="三、RNIE 3.0文心大模型"></a>三、RNIE 3.0文心大模型</h2><p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.12731">ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation</a> 论文摘要：<code>经过预训练的语言模型在各种自然语言处理（NLP）任务中取得了最先进的结果。GPT-3已经表明，扩大预先训练的语言模型可以进一步开发它们的巨大潜力。最近提出了一个名为ERNIE3.0的统一框架，用于预训练大规模知识增强模型，并训练了一个具有100亿个参数的模型。ERNIE3.0在各种NLP任务上的表现优于最先进的模型。为了探索扩大ERNIE3.0的性能，我们在飞桨平台上训练了一个名为ERNIE3.0Titan的数百亿参数模型，其参数高达2600亿。此外，我们设计了一个自监督的对抗性损失和一个可控的语言建模损失，使ERNIE3.0 Titan生成可信和可控的文本。为了减少计算开销和碳排放，我们为ERNIE3.0 Titan提出了一个在线蒸馏框架，教师模型将同时教授学生和训练自己。ERNIE3.0泰坦是迄今为止中国最大的密集预训练模型。经验结果表明，ERNIE3.0 Titan在68个NLP数据集上的性能优于最先进的模型。</code><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/71e361e00b7f41a99710abe7537f54ccd77f9c56ebf34c36bb98499173465378"><br><code>两种生成机制的示意图（左）和预训练的数据策略（右）。绿色、橙色和蓝色的方块表示源文本、目标文本和人造符号。</code><br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/64da5eca8ed34b8ea38c04be2c0527211799a24565364f6a87c1ef66717958ba"></p>
<p><code>消融研究结果</code></p>
<h3 id="3-1-导入模型"><a href="#3-1-导入模型" class="headerlink" title="3.1 导入模型"></a>3.1 导入模型</h3><p>详细教程可以参考<a target="_blank" rel="noopener" href="https://paddlenlp.readthedocs.io/zh/latest/model_zoo/index.html">PaddleNLP Transformer预训练模型</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddlenlp</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddlenlp.transformers <span class="keyword">import</span> AutoModelForSequenceClassification, AutoTokenizer</span><br><span class="line">model_name = <span class="string">&quot;ernie-3.0-medium-zh&quot;</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=<span class="number">2</span>)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br></pre></td></tr></table></figure>

<pre><code>[2023-08-20 17:09:48,154] [    INFO] - We are using &lt;class &#39;paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification&#39;&gt; to load &#39;ernie-3.0-medium-zh&#39;.
[2023-08-20 17:09:48,159] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh
[2023-08-20 17:09:48,162] [    INFO] - Downloading ernie_3.0_medium_zh.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams
100%|██████████| 313M/313M [00:09&lt;00:00, 32.9MB/s] 
W0820 17:09:58.220381   204 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0820 17:09:58.224973   204 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.
[2023-08-20 17:10:01,278] [    INFO] - We are using &lt;class &#39;paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer&#39;&gt; to load &#39;ernie-3.0-medium-zh&#39;.
[2023-08-20 17:10:01,282] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh
[2023-08-20 17:10:01,285] [    INFO] - Downloading ernie_3.0_medium_zh_vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt
100%|██████████| 182k/182k [00:00&lt;00:00, 9.63MB/s]
[2023-08-20 17:10:01,391] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/tokenizer_config.json
[2023-08-20 17:10:01,394] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/special_tokens_map.json
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> paddlenlp.data <span class="keyword">import</span> Stack, <span class="type">Tuple</span>, Pad</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span>  convert_example, create_dataloader</span><br><span class="line"><span class="comment"># 模型运行批处理大小</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">max_seq_length = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">trans_func = partial(</span><br><span class="line">    convert_example,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    max_seq_length=max_seq_length)</span><br><span class="line">batchify_fn = <span class="keyword">lambda</span> samples, fn=<span class="type">Tuple</span>(</span><br><span class="line">    Pad(axis=<span class="number">0</span>, pad_val=tokenizer.pad_token_id),  <span class="comment"># input</span></span><br><span class="line">    Pad(axis=<span class="number">0</span>, pad_val=tokenizer.pad_token_type_id),  <span class="comment"># segment</span></span><br><span class="line">    Stack(dtype=<span class="string">&quot;int64&quot;</span>)  <span class="comment"># label</span></span><br><span class="line">): [data <span class="keyword">for</span> data <span class="keyword">in</span> fn(samples)]</span><br><span class="line">train_data_loader = create_dataloader(</span><br><span class="line">    train_ds,</span><br><span class="line">    mode=<span class="string">&#x27;train&#x27;</span>,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    batchify_fn=batchify_fn,</span><br><span class="line">    trans_fn=trans_func)</span><br><span class="line">dev_data_loader = create_dataloader(</span><br><span class="line">    dev_ds,</span><br><span class="line">    mode=<span class="string">&#x27;dev&#x27;</span>,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    batchify_fn=batchify_fn,</span><br><span class="line">    trans_fn=trans_func)</span><br></pre></td></tr></table></figure>

<h3 id="3-2-模型训练"><a href="#3-2-模型训练" class="headerlink" title="3.2 模型训练"></a>3.2 模型训练</h3><p>数据量太少了，很容易过拟合，这里的的</p>
<ul>
<li>epoch设置成20</li>
<li>weight_decay 设置成0.1</li>
<li>learning_rate 设置成 5e-6 </li>
<li>大概两分钟即可训练完成</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddlenlp <span class="keyword">as</span> ppnlp</span><br><span class="line"><span class="keyword">import</span> paddle</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddlenlp.transformers <span class="keyword">import</span> LinearDecayWithWarmup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练过程中的最大学习率</span></span><br><span class="line">learning_rate = <span class="number">5e-6</span> </span><br><span class="line"><span class="comment"># 训练轮次</span></span><br><span class="line">epochs = <span class="number">20</span> <span class="comment">#3</span></span><br><span class="line"><span class="comment"># 学习率预热比例</span></span><br><span class="line">warmup_proportion = <span class="number">0.3</span></span><br><span class="line"><span class="comment"># 权重衰减系数，类似模型正则项策略，避免模型过拟合</span></span><br><span class="line">weight_decay = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">num_training_steps = <span class="built_in">len</span>(train_data_loader) * epochs</span><br><span class="line">lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)</span><br><span class="line">optimizer = paddle.optimizer.AdamW(</span><br><span class="line">    learning_rate=lr_scheduler,</span><br><span class="line">    parameters=model.parameters(),</span><br><span class="line">    weight_decay=weight_decay,</span><br><span class="line">    apply_decay_param_fun=<span class="keyword">lambda</span> x: x <span class="keyword">in</span> [</span><br><span class="line">        p.name <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> [<span class="string">&quot;bias&quot;</span>, <span class="string">&quot;norm&quot;</span>])</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">criterion = paddle.nn.loss.CrossEntropyLoss()</span><br><span class="line">metric = paddle.metric.Accuracy()</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> evaluate</span><br><span class="line">all_train_loss=[]</span><br><span class="line">all_train_accs = []</span><br><span class="line">Batch=<span class="number">0</span></span><br><span class="line">Batchs=[]</span><br><span class="line">global_step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_data_loader, start=<span class="number">1</span>):</span><br><span class="line">        input_ids, segment_ids, labels = batch</span><br><span class="line">        logits = model(input_ids, segment_ids)</span><br><span class="line">        loss = criterion(logits, labels)</span><br><span class="line">        probs = F.softmax(logits, axis=<span class="number">1</span>)</span><br><span class="line">        correct = metric.compute(probs, labels)</span><br><span class="line">        metric.update(correct)</span><br><span class="line">        acc = metric.accumulate()</span><br><span class="line">        global_step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> global_step % <span class="number">10</span> == <span class="number">0</span> :</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f&quot;</span> % (global_step, epoch, step, loss, acc))</span><br><span class="line">            Batch += <span class="number">10</span> </span><br><span class="line">            Batchs.append(Batch)</span><br><span class="line">            all_train_loss.append(loss)</span><br><span class="line">            all_train_accs.append(acc)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        optimizer.clear_grad()</span><br><span class="line">    evaluate(model, criterion, metric, dev_data_loader)</span><br><span class="line"></span><br><span class="line">model.save_pretrained(<span class="string">&#x27;/home/aistudio/checkpoint&#x27;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&#x27;/home/aistudio/checkpoint&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>eval loss: 0.75054, accu: 0.43902
global step 10, epoch: 2, batch: 2, loss: 0.66468, acc: 0.59375
eval loss: 0.75193, accu: 0.43902
global step 20, epoch: 3, batch: 4, loss: 0.57682, acc: 0.64062
eval loss: 0.75422, accu: 0.43902
global step 30, epoch: 4, batch: 6, loss: 0.64896, acc: 0.56771
eval loss: 0.74524, accu: 0.43902
global step 40, epoch: 5, batch: 8, loss: 0.62321, acc: 0.62205
eval loss: 0.75564, accu: 0.43902
eval loss: 0.77395, accu: 0.43902
global step 50, epoch: 7, batch: 2, loss: 0.56548, acc: 0.65625
eval loss: 0.73238, accu: 0.43902
global step 60, epoch: 8, batch: 4, loss: 0.57789, acc: 0.67969
eval loss: 0.74135, accu: 0.46341
global step 70, epoch: 9, batch: 6, loss: 0.57494, acc: 0.70312
eval loss: 0.71202, accu: 0.51220
global step 80, epoch: 10, batch: 8, loss: 0.43934, acc: 0.76378
eval loss: 0.72221, accu: 0.53659
eval loss: 0.71013, accu: 0.57317
global step 90, epoch: 12, batch: 2, loss: 0.44184, acc: 0.87500
eval loss: 0.72470, accu: 0.57317
global step 100, epoch: 13, batch: 4, loss: 0.34039, acc: 0.90625
eval loss: 0.71655, accu: 0.63415
global step 110, epoch: 14, batch: 6, loss: 0.21924, acc: 0.93229
eval loss: 0.78495, accu: 0.62195
global step 120, epoch: 15, batch: 8, loss: 0.21976, acc: 0.95669
eval loss: 0.78816, accu: 0.64634
eval loss: 0.88699, accu: 0.59756
global step 130, epoch: 17, batch: 2, loss: 0.13201, acc: 0.95312
eval loss: 0.83912, accu: 0.64634
global step 140, epoch: 18, batch: 4, loss: 0.13333, acc: 0.97656
eval loss: 0.79599, accu: 0.65854
global step 150, epoch: 19, batch: 6, loss: 0.11692, acc: 0.98958
eval loss: 0.89906, accu: 0.63415
global step 160, epoch: 20, batch: 8, loss: 0.11152, acc: 0.96457
eval loss: 0.91676, accu: 0.63415


[2023-08-20 17:10:31,859] [    INFO] - tokenizer config file saved in /home/aistudio/checkpoint/tokenizer_config.json
[2023-08-20 17:10:31,863] [    INFO] - Special tokens file saved in /home/aistudio/checkpoint/special_tokens_map.json





(&#39;/home/aistudio/checkpoint/tokenizer_config.json&#39;,
 &#39;/home/aistudio/checkpoint/special_tokens_map.json&#39;,
 &#39;/home/aistudio/checkpoint/added_tokens.json&#39;)
</code></pre>
<h3 id="3-3-可视化训练曲线"><a href="#3-3-可视化训练曲线" class="headerlink" title="3.3 可视化训练曲线"></a>3.3 可视化训练曲线</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_train_acc</span>(<span class="params">Batchs, train_accs,train_loss</span>):</span><br><span class="line">    title=<span class="string">&quot;training accs&quot;</span></span><br><span class="line">    plt.title(title, fontsize=<span class="number">24</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;batch&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;acc&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.plot(Batchs, train_accs, color=<span class="string">&#x27;green&#x27;</span>, label=<span class="string">&#x27;training accs&#x27;</span>)</span><br><span class="line">    plt.plot(Batchs, train_loss, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;training loss&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line">draw_train_acc(Batchs,all_train_accs,all_train_loss)</span><br></pre></td></tr></table></figure>


<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="/output_34_0.png" alt="png"></p>
<h3 id="3-5-模型预测"><a href="#3-5-模型预测" class="headerlink" title="3.5 模型预测"></a>3.5 模型预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载模型参数</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line">params_path = <span class="string">&#x27;checkpoint/model_state.pdparams&#x27;</span></span><br><span class="line"><span class="keyword">if</span> params_path <span class="keyword">and</span> os.path.isfile(params_path):</span><br><span class="line">    state_dict = paddle.load(params_path)</span><br><span class="line">    model.set_dict(state_dict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Successful Loaded down!&quot;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Successful Loaded down!
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> predict</span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">data = text_t</span><br><span class="line">label_map = &#123;<span class="number">0</span>: <span class="string">&#x27;0&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;1&#x27;</span>,<span class="number">2</span>:<span class="string">&#x27;2&#x27;</span>&#125;</span><br><span class="line">results = predict(</span><br><span class="line">    model, data, tokenizer, label_map, batch_size=batch_size)</span><br><span class="line"><span class="keyword">for</span> idx, text <span class="keyword">in</span> <span class="built_in">enumerate</span>(data):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Data: &#123;&#125; \t Lable: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(text, results[idx]))</span><br></pre></td></tr></table></figure>

<pre><code>Data: &#123;&#39;text_a&#39;: &#39;阿才太帅了纯爱战神啊阿天那条线是最令人唏嘘的阿天母亲的演的太好了这边哭天抢地下一个镜头就是放鞭炮庆祝的转场戏剧性拉满&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;这种宣传片为啥不在电视或网络上免费普及给广大群众呢还让人民群众花银子受俩小时的教育把坏人往有血有肉有情有义里演成大活人把好人往假大空伟光正里演成稻草人真是的&#39;, &#39;label&#39;: 1&#125; 	 Lable: 1
Data: &#123;&#39;text_a&#39;: &#39;这个故事告诉我们只要长的好看有才华就算被拐卖到境外也可以被编剧老师眷顾这部片跟奈飞的距离差了3个陈思诚反诈宣传片从预告片就开始在诈骗&#39;, &#39;label&#39;: 1&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;反诈宣传片但是现实绝对比电影更残酷&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;母亲从门框伸出的手拉不回被贪心拖向地狱的儿荷官从屏幕伸出的手推下了想要上岸却坠落的人这边是关在牢笼里绑在石头上的动物那边是晒出来也会发霉刺进去不会流血的黑心我以为吞得下秘密你以为赚得到真金用筷子夹了一张纸钞从抽屉拿走了一块玉镯我用它来孤注一掷却满盘皆输&#39;, &#39;label&#39;: 1&#125; 	 Lable: 1
Data: &#123;&#39;text_a&#39;: &#39;很现实电信诈骗真的远远比我们想的恐怖就在前段时间我的朋友才刚刚被骗了几万块就渐渐被带进去了当突然意识到的时候已经晚了每个人物都很饱满很现实是因为结局并不是合家欢的这真的除不尽不仅要靠国家更要靠自己甄别并不是聪明就不会被骗全员演技在线算是这段时间让人眼前一亮的电影了&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;命题作文中表现较好的但现实里不会有坏人的仁慈&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;炸裂今年最牛最棒最赞最精彩国产片&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;开头很好后面就编得不行主次不分了不过7分没问题为了正常上映很多黄暴没有拍出来点到为止放在90年代的香港拍那就更好了&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;现实主义题材是目前国内适时应该出现的反诈电影本片用三分之一段落描述潘生和梁安娜被骗进诈骗团伙有用三分之一的段落完整揭示一个真实上当人生被毁的案例后三分之一是艰难反诈斗争的正能量宁浩在本片虽然之挂名监制但很明显给导演申奥的助力很多孤注一掷的节奏很好而且第二段真实诈骗段落的展开深入精彩有力而且孤在强调犯罪者的狡诈和阴险之外还保留了他们的人性让孤的结局更真实更有余味&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;潘生安娜阿天三条故事线都很有警示作用瓦里只会比电影中更残忍更癫狂推荐观看全民防诈少一点人间悲剧上一次看孙阳还是在过春天上一次看王传君还是无名所以阿才和陆经理又是怎么上的贼船呢很高兴这俩角色都没完全偏平化还有最后一个镜头脑袋发麻申奥导演可以的&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;看哭了咱就是说阿天的父母该有多么心痛啊&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;比较碎人物描摹和事件编排节奏都虎头蛇尾空有一个略显不伦不类的花架子几次视角的转换不如直接做成接力式的叙事结构暴力氛围也一般想想南车摩托车飞头的突然震撼最吃惊的是张艺兴这拉胯演技对标的竟是胡歌被抓前的一段妆造都是比着胡歌来的吧咏梅封后后的表演面瘫感更重了不能说演的不好就有种随它吧老娘想演就来一段不想演你也给我瞪着眼看着的感觉&#39;, &#39;label&#39;: 1&#125; 	 Lable: 1
Data: &#123;&#39;text_a&#39;: &#39;几个人物挺出彩的前半段远好于后半段教育意义远大于艺术价值&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;更像网剧一些剧作可以再顺畅一些张艺兴这人设在片头的动机太牵强了在线教育老总那条线也直接断了倒是任务片里的私货在线教育和传销作比民众围殴警察有点意思7&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;在网络世界里看着形形色色的人可能一直被锤炼一直不服输的张艺兴就是申奥导演最想要抓住的人物特质张艺兴也做到了演绎潘生不仅是把绝地求生的人物体现出来也是把希望送给了每一位观影的观众&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;和现实最大的区别就是阿才不会心软&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;16最恶劣的那种电影之一简单粗暴非常剥削在大旗下一步一步一段一段逼人接受请君入瓮仿佛新秩序式的那种缺点在看似复杂的行动中对观众的操纵性过强不留一点空间&#39;, &#39;label&#39;: 1&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;说不上哪里好但又不觉得差给五星觉得高但不给五星又觉得对不起我观看时不由自主的种种反应里面所有以前我认为演戏突兀尴尬的几位在里面表演都出奇的流畅和合适一点不出戏节奏把控也很好还真挺震撼的但不是因为血腥是因为心底的恐惧代入到自己身上的绝望美中不足阿才长太帅了要是个又丑又邋遢猥琐的放了顶多觉得良心发现或者还有后招但是这个演员太帅了放了的场景让我衍生出了几秒恋爱脑降低了本片的警示意味和严肃性真是不应该啊不应该是说我见缝插针恋爱脑不应该&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;前面还是电影后面就成宣传片了主角从受害人变成了咏梅关键破案过程也不好看神兵天降加反派降智叙事混乱加节奏仓促我不知道那个馒头是怎么如此精准地投递给张艺兴的而他又怎么瞬间就明白了火柴盒的用途还有个让我不满但也许观众会觉得很爽的地方就是影片有很多暴力与性暗示镜头这些更多是商业噱头看不出对这些受害者有什么人文关怀&#39;, &#39;label&#39;: 1&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;呃我就说一句能不能别把反派里的男人塑造的情深似海了逃出缅北靠爱情就真的不要这样好烦啊&#39;, &#39;label&#39;: 1&#125; 	 Lable: 1
Data: &#123;&#39;text_a&#39;: &#39;放走金晨那段纯属强行给反派降智&#39;, &#39;label&#39;: 1&#125; 	 Lable: 1
Data: &#123;&#39;text_a&#39;: &#39;为什么从广州去新加坡还需要转机这么离谱从一开始故事就不成立了槽点不胜枚举年度诈骗电影&#39;, &#39;label&#39;: 1&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;拍出了受害者的可恨拍出了诈骗者的迫不得已良心未泯反诈宣传片诈骗工厂宣传片&#39;, &#39;label&#39;: 1&#125; 	 Lable: 1
Data: &#123;&#39;text_a&#39;: &#39;看似反诈科普实则利用血腥和暴力场面恫吓国民让大家趁早打消出国念头把钱留给内循环这与中式家长动辄恐吓小孩的祖传教育思想如出一辙近年来国产商业片只要涉及异域必定要服膺一种外国即地狱风景这边独好的保守主义思潮这当然是一场属于部分民众和宣传工具的双向奔赴你甚至很难苛责一个背刺字幕组和靠抖音热门拍片的导演拍出这样一部前一半剥削电影后一半战狼出征的怪胎毕竟他最后会带着大几十亿的票房骄傲地反问你一句人民群众喜闻乐见你不喜欢你算老几&#39;, &#39;label&#39;: 1&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;王大陆演技不错&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;影片本身承担了很重的责任在这个框架内主创已经尽力拉高了影片的可看性在一切都为一个大的主题辅助的前提下角色符号化几乎是不可避免的看完影片观众记住电信诈骗的危害就行了关心不关心角色不是重点但我还是想呼吁适当的分级或者统一审查标准不要那边要求不能出现红色的血这边人脑袋上扎钉子&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;骗子太可恶了&#39;, &#39;label&#39;: 0&#125; 	 Lable: 1
Data: &#123;&#39;text_a&#39;: &#39;演员张艺兴值得信赖为了过审只能舍掉一些细节理想化一下结局&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;不开玩笑这个开分绝对偏低了不说剧情紧张刺激猎奇更多的是影片本身的普世价值和社会意义过审不容易目睹过身边的人赌博以及被骗的真实经历一点也不夸张真诚地推荐所有人以及带着家人一起看对小广告深恶痛绝反诈宣传从我做起&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;有教育意义诈骗戏份可大学生和警察戏份比较不好看喜欢里面的孙阳&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;极其扯淡的电影甚至骂都是浪费时间和人生大事一样浪费好题材整部电影一盘散沙从被骗到诈骗的经历再到受害者的故事再到破获案件的过程没有一个部分拍好的花钱去看电影就好比你花钱去看cctv的公益广告整部电影亮点只有王传君但如此傻逼的剧情把这个角色都搞得水泄不通诈骗犯有兄弟情有爱情TM来搞笑的伟光正男主真的全场尬住ok申奥可以拉进黑名单了&#39;, &#39;label&#39;: 1&#125; 	 Lable: 1
Data: &#123;&#39;text_a&#39;: &#39;我这辈子是不去东南亚了&#39;, &#39;label&#39;: 0&#125; 	 Lable: 1
Data: &#123;&#39;text_a&#39;: &#39;完成度一般演技也掉线叙事缺逻辑编剧不给力安娜和潘生出戏让人懵宁浩加申奥效果不太妙&#39;, &#39;label&#39;: 1&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;那么多国产片歌功颂德描绘盛世粉饰太平至少它直面了人生的恶人性的恶人的恶哪怕只是一小部分走出影院是夏日傍晚热浪蝉鸣车流人群街道路边摊即使裹挟着灰尘与嘈杂但一切都很真实充满烟火气仿佛自己也刚经历了一场暗夜之行而重返人间忽然好想去找家小店坐下来喝碗粉丝汤&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;烂&#39;, &#39;label&#39;: 1&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;七位主角和一众黄金配角的戏非常精彩让影片远超我预期逻辑硬漏洞不去想不去提单纯为看到周也开心也为看到咏梅孙阳王传君开心孙阳演技大进步&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;孙阳像辣椒炒肉油辣得刚好黄艺馨演受刑比金晨好500个张艺兴&#39;, &#39;label&#39;: 1&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;用一组狂派以暴制暴莫名想起王道吉&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;片子本身挺扎实作为半命题作文故事完整演员发挥OK除了某些不得不做的戏剧性设置如金晨被孙阳恋爱脑给救了基本拥有了与其宣传话题匹配的可看性抖音密集投放两个月的短视频宣传也被证明这是抓住大陆下沉市场以获得最大路人关注榨取最广大345678线城市票房的最优手段当然这样的宣传手段也得益于本片自身所拥有的优秀话题性即非常贴合时下缅北诈骗这一社会热点两相结合之下本片与最广大普通观众群体神奇地达成了双向奔赴那句最朴实的价值观念多一人观影少一人受骗的口号也发挥出了实实在在的作用个人看完之后听到身边很多人都在交流是被前期宣传吸引来的看完之后也确实得到了一点关于诈骗的小小震撼和警示私以为这就很不错了豆瓣这群文青们一个个自恃智商奇高不会受骗反而纷纷以观看此片为受诈也挺可笑&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
Data: &#123;&#39;text_a&#39;: &#39;社会热点自然会很火但确实把赌博境外诈骗这个产业链有好好表达了最重要是这就发生在我们每个人身边希望这更有社会现实意义的电影被更多人看到&#39;, &#39;label&#39;: 0&#125; 	 Lable: 0
</code></pre>
<p>可以看到有正确的也有错误的，整体来说还是正确的多一些，我觉得主要的问题在于数据量太少了，训练的数据量至少要上万，但是由于这是个小demo初体验项目，影刺没有爬取太多的数据，只有区区600条，用于训练的只用420条数据，很容易造成过拟合的情况，导致模型在测试集、验证集上面的效果并不好。<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/df71cd0ded03423b829b21befb467cc85979e7b478704cf88fac329c3afa96b6"></p>
<h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><ul>
<li>通过这个项目了解了文心大模型Ernie-3.0的使用方法</li>
<li>采用超小样本的预训练对现在非常火的孤注一掷电影影评进行分析</li>
<li>整体来说，效果还算不错</li>
<li>大多数人进了缅北的人，并没有成为潘生，多数是悲惨的一生</li>
<li><strong>珍爱生命，远离诈骗，远离赌博</strong>！<br><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://ai-studio-static-online.cdn.bcebos.com/c9b8752bcca84ca3be76bda889286bb1da194be4dc984261a318f56207915f63"></li>
</ul>
<h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul>
<li><a target="_blank" rel="noopener" href="https://aistudio.baidu.com/projectdetail/5125584?channelType=0&channel=0">三岁大佬的基于Ernie-3.0的电影评论情感分析</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2112.12731">ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation</a></li>
<li><a target="_blank" rel="noopener" href="https://paddlenlp.readthedocs.io/zh/latest/model_zoo/index.html">PaddleNLP Transformer预训练模型</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/PaddleNLP">PaddleNlp-Github</a></li>
</ul>
<h3 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h3><ul>
<li>作者为一名在校大三学生，<strong>人工智能专业</strong></li>
<li>学习方向：<strong>深度学习和计算机视觉</strong></li>
<li>百度飞桨PPDE，百度飞桨领航团成员，阿里云开发者社区博客专家，<strong>csdn人工智能领域新星创作者 万粉博主</strong></li>
</ul>
<ul>
<li><a target="_blank" rel="noopener" href="https://github.com/lzypython">Github主页</a>：<a target="_blank" rel="noopener" href="https://github.com/lzypython">https://github.com/lzypython</a></li>
<li><a href="https://www.lizhiyang.xyz/">个人博客主页</a>：<a href="https://www.lizhiyang.xyz/">https://www.lizhiyang.xyz/</a></li>
<li><a target="_blank" rel="noopener" href="https://lizhiyang.blog.csdn.net/">CSDN主页</a>：<a target="_blank" rel="noopener" href="https://lizhiyang.blog.csdn.net/">https://lizhiyang.blog.csdn.net/</a></li>
</ul>
<p><font size=5><strong>欢迎关注，交流学习！</strong></font></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://www.lizhiyang.xyz">咋</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://www.lizhiyang.xyz/2023/08/20/%E5%AD%A4%E6%B3%A8%E4%B8%80%E6%8E%B7%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E6%96%87%E5%BF%83Ernie-3-0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E8%AF%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/">https://www.lizhiyang.xyz/2023/08/20/%E5%AD%A4%E6%B3%A8%E4%B8%80%E6%8E%B7%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E6%96%87%E5%BF%83Ernie-3-0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E8%AF%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://www.lizhiyang.xyz" target="_blank">咋的个人博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://pic-bed-ar2.pages.dev/img/13.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-full"><a href="/2023/08/20/3-dataset%E4%B8%8Edatalodar/" title="3.dataset与datalodar"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic-bed-ar2.pages.dev/img/4.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">3.dataset与datalodar</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://pic-bed-ar2.pages.dev/img/12.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">咋</div><div class="author-info__description">咋的个人博客，记录自己的学习和生活</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">18</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lzypython"><i class="fab fa-github"></i><span>🚗前往主页...</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lzypython" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:a17730209318@163.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到我的博客</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AD%A4%E6%B3%A8%E4%B8%80%E6%8E%B7%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E6%96%87%E5%BF%83Ernie-3-0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E8%AF%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90"><span class="toc-number">1.</span> <span class="toc-text">孤注一掷——基于文心Ernie-3.0大模型的影评情感分析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E5%89%8D%E9%9D%A2"><span class="toc-number">1.1.</span> <span class="toc-text">写在前面</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81%E6%95%B0%E6%8D%AE%E7%9B%B4%E8%A7%82%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">1.2.</span> <span class="toc-text">一、数据直观可视化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E5%90%84%E8%AF%84%E4%BB%B7%E6%89%80%E5%8D%A0%E4%BA%BA%E6%95%B0"><span class="toc-number">1.2.1.</span> <span class="toc-text">1.1 各评价所占人数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E8%AF%8D%E4%BA%91%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-number">1.2.2.</span> <span class="toc-text">1.2 词云可视化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86"><span class="toc-number">1.3.</span> <span class="toc-text">二、数据处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%B8%85%E6%B4%97%E6%95%B0%E6%8D%AE"><span class="toc-number">1.3.1.</span> <span class="toc-text">2.1 清洗数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E5%88%92%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.3.2.</span> <span class="toc-text">2.2 划分数据集</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE"><span class="toc-number">1.4.</span> <span class="toc-text">2.3 加载数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E5%B1%95%E7%A4%BA%E6%95%B0%E6%8D%AE"><span class="toc-number">1.4.1.</span> <span class="toc-text">2.4 展示数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81RNIE-3-0%E6%96%87%E5%BF%83%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.5.</span> <span class="toc-text">三、RNIE 3.0文心大模型</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E5%AF%BC%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.5.1.</span> <span class="toc-text">3.1 导入模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83"><span class="toc-number">1.5.2.</span> <span class="toc-text">3.2 模型训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%AD%E7%BB%83%E6%9B%B2%E7%BA%BF"><span class="toc-number">1.5.3.</span> <span class="toc-text">3.3 可视化训练曲线</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-%E6%A8%A1%E5%9E%8B%E9%A2%84%E6%B5%8B"><span class="toc-number">1.5.4.</span> <span class="toc-text">3.5 模型预测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81%E6%80%BB%E7%BB%93"><span class="toc-number">1.6.</span> <span class="toc-text">四、总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%99%E5%9C%A8%E6%9C%80%E5%90%8E"><span class="toc-number">1.7.</span> <span class="toc-text">写在最后</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">1.7.1.</span> <span class="toc-text">参考文献</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E8%80%85%E7%AE%80%E4%BB%8B"><span class="toc-number">1.7.2.</span> <span class="toc-text">作者简介</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2023 By 咋</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"></div><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>