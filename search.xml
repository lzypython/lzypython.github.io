<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>1.准备工作</title>
      <link href="/2023/08/20/1-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C/"/>
      <url>/2023/08/20/1-%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="查看显卡信息"><a href="#查看显卡信息" class="headerlink" title="查看显卡信息"></a>查看显卡信息</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1687937841653-a28353c3-f372-41f2-b84f-3694205a50d7.png#averageHue=%23161514&clientId=u6482f305-a993-4&from=paste&height=440&id=ue59e05e1&originHeight=670&originWidth=1344&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=93147&status=done&style=none&taskId=ua47200f8-7485-472a-b92f-ebfc4a006f0&title=&width=882.2153846153847" alt="image.png"></p><h1 id="创建虚拟环境"><a href="#创建虚拟环境" class="headerlink" title="创建虚拟环境"></a>创建虚拟环境</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">conda create -n Pytorch python=3.8</span><br><span class="line">conda activate Pytorch</span><br><span class="line">pip list # 查看当前虚拟环境中的包</span><br><span class="line">conda env list # 查看虚拟环境有哪些</span><br><span class="line">where  python # 查看python解释器在哪里</span><br></pre></td></tr></table></figure><h1 id="将jupyter与创建的虚拟环境关联"><a href="#将jupyter与创建的虚拟环境关联" class="headerlink" title="将jupyter与创建的虚拟环境关联"></a>将jupyter与创建的虚拟环境关联</h1><ul><li>在base环境下安装Pytorch（不推荐）</li><li>在创建好的虚拟环境中安装jupyter<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">conda activate pytorch</span><br><span class="line">pip install nb_conda </span><br><span class="line">jupyter notebook</span><br></pre></td></tr></table></figure></li></ul><h1 id="查看pytorch是否可用"><a href="#查看pytorch是否可用" class="headerlink" title="查看pytorch是否可用"></a>查看pytorch是否可用</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">print(torch.cuda.is_available())</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1687937158193-94158a1d-5809-476c-b36e-0d6654244a0b.png#averageHue=%23141212&clientId=u6482f305-a993-4&from=paste&height=440&id=u0591a89b&originHeight=670&originWidth=1344&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=80578&status=done&style=none&taskId=u81d1c624-6a78-41fc-996e-354323bdc7d&title=&width=882.2153846153847" alt="image.png"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>10.现有模型使用和修改</title>
      <link href="/2023/08/20/10-%E7%8E%B0%E6%9C%89%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E5%92%8C%E4%BF%AE%E6%94%B9/"/>
      <url>/2023/08/20/10-%E7%8E%B0%E6%9C%89%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E5%92%8C%E4%BF%AE%E6%94%B9/</url>
      
        <content type="html"><![CDATA[<p>首先加载模型结构，可以设置pretrained参数设置成是否是在特定数据集上训练好的预训练模型。<br>通过add_module添加模型结构<br>可以根据索引去修改模型结构</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：vgg16.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 12:53 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Linear</span><br><span class="line"></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">True</span>)  <span class="comment"># 设置成True即代表是在ImageNet上训练好的预训练模型</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加模型结构</span></span><br><span class="line">vgg16.classifier.add_module(<span class="string">&quot;7&quot;</span>,Linear(<span class="number">1000</span>,<span class="number">10</span>))</span><br><span class="line"><span class="comment"># print(vgg16)</span></span><br><span class="line"><span class="comment"># 修改现在的模型结构</span></span><br><span class="line">vgg16.classifier[<span class="number">0</span>] = Linear(<span class="number">25088</span>,<span class="number">1000</span>)</span><br><span class="line"><span class="built_in">print</span>(vgg16)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">VGG(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">3</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">5</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">6</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">7</span>): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">8</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">9</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">10</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">11</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">12</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">13</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">14</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">15</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">16</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">17</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">18</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">19</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">20</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">21</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">22</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">23</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">24</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">25</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">26</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">27</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">28</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">29</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">30</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">25088</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">3</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">4</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">5</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">6</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">1000</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">D:\anaconda\envs\Gpu-Pytorch\python.exe D:/Pytorch_learn/vgg16.py</span><br><span class="line">D:\anaconda\envs\Gpu-Pytorch\lib\site-packages\torchvision\io\image.py:<span class="number">11</span>: UserWarning: Failed to load image Python extension: Could <span class="keyword">not</span> find module <span class="string">&#x27;D:\anaconda\envs\Gpu-Pytorch\Lib\site-packages\torchvision\image.pyd&#x27;</span> (<span class="keyword">or</span> one of its dependencies). Try using the full path <span class="keyword">with</span> constructor syntax.</span><br><span class="line">  warn(<span class="string">f&quot;Failed to load image Python extension: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">VGG(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">3</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">5</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">6</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">7</span>): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">8</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">9</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">10</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">11</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">12</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">13</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">14</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">15</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">16</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">17</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">18</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">19</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">20</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">21</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">22</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">23</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">24</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">25</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">26</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">27</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">28</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">29</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">30</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">25088</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">3</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">4</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">5</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">6</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">1000</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">7</span>): Linear(in_features=<span class="number">1000</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">进程已结束,退出代码<span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line">VGG(</span><br><span class="line">  (features): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">3</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">5</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">6</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">7</span>): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">8</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">9</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">10</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">11</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">12</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">13</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">14</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">15</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">16</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">17</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">18</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">19</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">20</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">21</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">22</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">23</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">24</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">25</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">26</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">27</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">28</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">    (<span class="number">29</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">30</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  )</span><br><span class="line">  (avgpool): AdaptiveAvgPool2d(output_size=(<span class="number">7</span>, <span class="number">7</span>))</span><br><span class="line">  (classifier): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Linear(in_features=<span class="number">25088</span>, out_features=<span class="number">1000</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">1</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">2</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">3</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">4096</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">4</span>): ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">5</span>): Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">6</span>): Linear(in_features=<span class="number">4096</span>, out_features=<span class="number">1000</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">7</span>): Linear(in_features=<span class="number">1000</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>11.模型保存和加载</title>
      <link href="/2023/08/20/11-%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/"/>
      <url>/2023/08/20/11-%E6%A8%A1%E5%9E%8B%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BD/</url>
      
        <content type="html"><![CDATA[<h1 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h1><p>模型保存和加载有两套方法，分别为<br>方法一</p><ol><li>torch.save(vgg16,”vgg_1.pth”) 直接保存模型结构和模型参数，内存占用比较大</li><li>model &#x3D; torch.load(“vgg_1.pth”)</li></ol><p>方法二</p><ol><li>torch.save(vgg16.state_dict(),”vgg_2.pth”) 以键值对的形式只保存模型参数，节省内存</li><li>vgg16.load_state_dict(torch.load(“vgg_2.pth”)) #加载时需要先知道模型结构，再和模型参数匹配</li></ol><h1 id="一、以vgg模型保存和加载为例"><a href="#一、以vgg模型保存和加载为例" class="headerlink" title="一、以vgg模型保存和加载为例"></a>一、以vgg模型保存和加载为例</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：model_save.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 13:19 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型保存方式1 保存模型结构+模型参数</span></span><br><span class="line">torch.save(vgg16,<span class="string">&quot;vgg_1.pth&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模型保存方式2 以字典的形式保存模型参数</span></span><br><span class="line">torch.save(vgg16.state_dict(),<span class="string">&quot;vgg_2.pth&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：model_load.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 13:30 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">第一种方式保存模型时，加载模型</span></span><br><span class="line"><span class="string">model = torch.load(&quot;vgg_1.pth&quot;)</span></span><br><span class="line"><span class="string">print(model)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种方式保存模型时，加载模型</span></span><br><span class="line"><span class="comment"># 首先要获取模型结构</span></span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 讲模型结构和读取的键值对型的模型参数匹配在一起</span></span><br><span class="line">vgg16.load_state_dict(torch.load(<span class="string">&quot;vgg_2.pth&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(vgg16)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="二、以自己定义的模型保存和加载为例"><a href="#二、以自己定义的模型保存和加载为例" class="headerlink" title="二、以自己定义的模型保存和加载为例"></a>二、以自己定义的模型保存和加载为例</h1><p>为方便管理，将自己的模型单独放置在一个文件中，其他地方需要时，只需要导入即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：Mymodel.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 13:24 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader,Dataset</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Module,Conv2d,MaxPool2d,Sequential,Flatten,Linear</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModule, self).__init__()</span><br><span class="line">        self.model = Sequential(</span><br><span class="line">        Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Flatten(),</span><br><span class="line">        Linear(<span class="number">1024</span>,<span class="number">64</span>),</span><br><span class="line">        Linear(<span class="number">64</span>,<span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：model_save_my_model.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 13:23 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> Mymodel <span class="keyword">import</span> MyModule</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MyModule()</span><br><span class="line"><span class="comment"># 第一种方式保存</span></span><br><span class="line">torch.save(model,<span class="string">&quot;model1.pth&quot;</span>)</span><br><span class="line"><span class="comment"># 第二种方式保存</span></span><br><span class="line">torch.save(model.state_dict(),<span class="string">&quot;model2.pth&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;保存完毕&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：model_load_my_model.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 13:50 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> Mymodel <span class="keyword">import</span> *</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">第一种方式加载模型</span></span><br><span class="line"><span class="string">model = torch.load(&quot;model1.pth&quot;)</span></span><br><span class="line"><span class="string">print(model)</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二种方式加载模型</span></span><br><span class="line">model = MyModule()</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&quot;model2.pth&quot;</span>))</span><br><span class="line"><span class="built_in">print</span>(model)</span><br></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">D:\anaconda\envs\Gpu-Pytorch\python.exe D:/Pytorch_learn/model_load_my_model.py</span><br><span class="line">D:\anaconda\envs\Gpu-Pytorch\lib\site-packages\torchvision\io\image.py:<span class="number">11</span>: UserWarning: Failed to load image Python extension: Could <span class="keyword">not</span> find module <span class="string">&#x27;D:\anaconda\envs\Gpu-Pytorch\Lib\site-packages\torchvision\image.pyd&#x27;</span> (<span class="keyword">or</span> one of its dependencies). Try using the full path <span class="keyword">with</span> constructor syntax.</span><br><span class="line">  warn(<span class="string">f&quot;Failed to load image Python extension: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">MyModule(</span><br><span class="line">  (model): Sequential(</span><br><span class="line">    (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">32</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    (<span class="number">1</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">2</span>): Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    (<span class="number">3</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">4</span>): Conv2d(<span class="number">32</span>, <span class="number">64</span>, kernel_size=(<span class="number">5</span>, <span class="number">5</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    (<span class="number">5</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">    (<span class="number">6</span>): Flatten(start_dim=<span class="number">1</span>, end_dim=-<span class="number">1</span>)</span><br><span class="line">    (<span class="number">7</span>): Linear(in_features=<span class="number">1024</span>, out_features=<span class="number">64</span>, bias=<span class="literal">True</span>)</span><br><span class="line">    (<span class="number">8</span>): Linear(in_features=<span class="number">64</span>, out_features=<span class="number">10</span>, bias=<span class="literal">True</span>)</span><br><span class="line">  )</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">进程已结束,退出代码<span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>加载自己的模型时，要从文件中提前导入自己的模型类，并进行实例化。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>孤注一掷——基于文心Ernie-3.0大模型的影评情感分析</title>
      <link href="/2023/08/20/12-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/"/>
      <url>/2023/08/20/12-%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/</url>
      
        <content type="html"><![CDATA[<p>模型训练可以分为以下几步</p><ol><li>数据集准备</li><li>数据集加载</li><li>模型定义及实例化</li><li>损失函数定义</li><li>参数更新方式定义</li><li>模型必要参数设置</li><li>模型训练逻辑及一些提示信息、可视化编写</li><li>开始训练模型<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：train.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 15:38 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> Mymodel <span class="keyword">import</span> MyModule</span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># 0.设置参数</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">epochs = <span class="number">20</span></span><br><span class="line">savetime = <span class="number">5</span></span><br><span class="line"><span class="comment"># 1.准备数据集</span></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(<span class="string">&quot;CIFAR10&quot;</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                          download=<span class="literal">True</span>)</span><br><span class="line">test_data = torchvision.datasets.CIFAR10(<span class="string">&quot;CIFAR10&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                         download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.加载数据集</span></span><br><span class="line">train_loader = data.DataLoader(dataset=train_data,batch_size=batch_size)</span><br><span class="line">test_loader = data.DataLoader(dataset=test_data,batch_size=batch_size)</span><br><span class="line">train_len = <span class="built_in">len</span>(train_loader)</span><br><span class="line">test_len = <span class="built_in">len</span>(test_loader)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_len))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_len))</span><br><span class="line"><span class="comment"># 3.定义网络结构，实例化模型</span></span><br><span class="line">model = MyModule()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4.定义损失函数</span></span><br><span class="line">loss_F = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.定义参数更新方式</span></span><br><span class="line">optim = torch.optim.SGD(model.parameters(),lr=lr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.开始训练和评估</span></span><br><span class="line">model.train()</span><br><span class="line">write = SummaryWriter(<span class="string">&quot;log_6&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-------开始第&#123;&#125;轮训练，总共&#123;&#125;轮-------&quot;</span>.<span class="built_in">format</span>(epoch,epochs))</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> train_time,train_item <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        train_img,train_label = train_item</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        result = model(train_img)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = loss_F(result,train_label)</span><br><span class="line">        <span class="comment"># 反向传播更新参数</span></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line">        train_loss += loss</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    right =<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> test_time,test_item <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">            test_img,test_label = test_item</span><br><span class="line">            test_result = model(test_img)</span><br><span class="line">            <span class="comment"># 获取测试集上的loss</span></span><br><span class="line">            loss = loss_F(test_result,test_label)</span><br><span class="line">            test_loss += loss</span><br><span class="line">            <span class="comment"># 获取测试集上的准确率</span></span><br><span class="line">            right += (test_result.argmax(<span class="number">1</span>) == test_label).<span class="built_in">sum</span>()</span><br><span class="line">    accuracy = right/test_len</span><br><span class="line">    write.add_scalar(<span class="string">&quot;train_loss&quot;</span>,train_loss,epoch)</span><br><span class="line">    write.add_scalar(<span class="string">&quot;test_loss&quot;</span>,test_loss,epoch)</span><br><span class="line">    write.add_scalar(<span class="string">&quot;accuracy&quot;</span>,accuracy,epoch)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练集上的损失为:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;测试集上的损失为:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;测试集上的准确率为:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(accuracy))</span><br><span class="line">    <span class="keyword">if</span> epoch % savetime ==<span class="number">0</span>:</span><br><span class="line">        torch.save(model,<span class="string">&quot;./model/model&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练完成！&quot;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">D:\anaconda\envs\Gpu-Pytorch\python.exe D:/Pytorch_learn/train.py</span><br><span class="line">D:\anaconda\envs\Gpu-Pytorch\lib\site-packages\torchvision\io\image.py:<span class="number">11</span>: UserWarning: Failed to load image Python extension: Could <span class="keyword">not</span> find module <span class="string">&#x27;D:\anaconda\envs\Gpu-Pytorch\Lib\site-packages\torchvision\image.pyd&#x27;</span> (<span class="keyword">or</span> one of its dependencies). Try using the full path <span class="keyword">with</span> constructor syntax.</span><br><span class="line">  warn(<span class="string">f&quot;Failed to load image Python extension: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">Files already downloaded <span class="keyword">and</span> verified</span><br><span class="line">Files already downloaded <span class="keyword">and</span> verified</span><br><span class="line">训练集长度为：<span class="number">782</span></span><br><span class="line">测试集长度为：<span class="number">157</span></span><br><span class="line">-------开始第<span class="number">0</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">1692.0927734375</span></span><br><span class="line">测试集上的损失为:<span class="number">318.7899475097656</span></span><br><span class="line">测试集上的准确率为:<span class="number">17.171974182128906</span></span><br><span class="line">-------开始第<span class="number">1</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">1462.9697265625</span></span><br><span class="line">测试集上的损失为:<span class="number">302.61761474609375</span></span><br><span class="line">测试集上的准确率为:<span class="number">19.770700454711914</span></span><br><span class="line">-------开始第<span class="number">2</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">1305.275390625</span></span><br><span class="line">测试集上的损失为:<span class="number">266.6638488769531</span></span><br><span class="line">测试集上的准确率为:<span class="number">23.980892181396484</span></span><br><span class="line">-------开始第<span class="number">3</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">1211.9080810546875</span></span><br><span class="line">测试集上的损失为:<span class="number">264.86248779296875</span></span><br><span class="line">测试集上的准确率为:<span class="number">24.78343963623047</span></span><br><span class="line">-------开始第<span class="number">4</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">1148.6689453125</span></span><br><span class="line">测试集上的损失为:<span class="number">258.8547058105469</span></span><br><span class="line">测试集上的准确率为:<span class="number">25.93630599975586</span></span><br><span class="line">-------开始第<span class="number">5</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">1094.395751953125</span></span><br><span class="line">测试集上的损失为:<span class="number">245.91709899902344</span></span><br><span class="line">测试集上的准确率为:<span class="number">27.719745635986328</span></span><br><span class="line">-------开始第<span class="number">6</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">1043.458984375</span></span><br><span class="line">测试集上的损失为:<span class="number">231.48187255859375</span></span><br><span class="line">测试集上的准确率为:<span class="number">29.585987091064453</span></span><br><span class="line">-------开始第<span class="number">7</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">993.9429321289062</span></span><br><span class="line">测试集上的损失为:<span class="number">216.33401489257812</span></span><br><span class="line">测试集上的准确率为:<span class="number">32.070064544677734</span></span><br><span class="line">-------开始第<span class="number">8</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">947.3882446289062</span></span><br><span class="line">测试集上的损失为:<span class="number">203.79718017578125</span></span><br><span class="line">测试集上的准确率为:<span class="number">34.248409271240234</span></span><br><span class="line">-------开始第<span class="number">9</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">905.7017822265625</span></span><br><span class="line">测试集上的损失为:<span class="number">194.99539184570312</span></span><br><span class="line">测试集上的准确率为:<span class="number">35.828025817871094</span></span><br><span class="line">-------开始第<span class="number">10</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">868.5162963867188</span></span><br><span class="line">测试集上的损失为:<span class="number">187.56068420410156</span></span><br><span class="line">测试集上的准确率为:<span class="number">37.08917236328125</span></span><br><span class="line">-------开始第<span class="number">11</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">835.2941284179688</span></span><br><span class="line">测试集上的损失为:<span class="number">181.5903778076172</span></span><br><span class="line">测试集上的准确率为:<span class="number">37.840763092041016</span></span><br><span class="line">-------开始第<span class="number">12</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">805.2085571289062</span></span><br><span class="line">测试集上的损失为:<span class="number">177.99606323242188</span></span><br><span class="line">测试集上的准确率为:<span class="number">38.445858001708984</span></span><br><span class="line">-------开始第<span class="number">13</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">777.8590698242188</span></span><br><span class="line">测试集上的损失为:<span class="number">175.87742614746094</span></span><br><span class="line">测试集上的准确率为:<span class="number">38.904457092285156</span></span><br><span class="line">-------开始第<span class="number">14</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">752.6644287109375</span></span><br><span class="line">测试集上的损失为:<span class="number">174.36672973632812</span></span><br><span class="line">测试集上的准确率为:<span class="number">39.25477600097656</span></span><br><span class="line">-------开始第<span class="number">15</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">729.43798828125</span></span><br><span class="line">测试集上的损失为:<span class="number">173.59202575683594</span></span><br><span class="line">测试集上的准确率为:<span class="number">39.48407745361328</span></span><br><span class="line">-------开始第<span class="number">16</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">707.3736572265625</span></span><br><span class="line">测试集上的损失为:<span class="number">173.00869750976562</span></span><br><span class="line">测试集上的准确率为:<span class="number">39.56687927246094</span></span><br><span class="line">-------开始第<span class="number">17</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">686.6292114257812</span></span><br><span class="line">测试集上的损失为:<span class="number">172.45094299316406</span></span><br><span class="line">测试集上的准确率为:<span class="number">39.8216552734375</span></span><br><span class="line">-------开始第<span class="number">18</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">667.0374755859375</span></span><br><span class="line">测试集上的损失为:<span class="number">172.76763916015625</span></span><br><span class="line">测试集上的准确率为:<span class="number">39.77070236206055</span></span><br><span class="line">-------开始第<span class="number">19</span>轮训练，总共<span class="number">20</span>轮-------</span><br><span class="line">训练集上的损失为:<span class="number">648.382568359375</span></span><br><span class="line">测试集上的损失为:<span class="number">172.2664794921875</span></span><br><span class="line">测试集上的准确率为:<span class="number">40.08917236328125</span></span><br><span class="line">训练完成！</span><br><span class="line"></span><br><span class="line">进程已结束,退出代码<span class="number">0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>tensorboard可视化：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689238509115-0eb7073a-bc9c-4333-b22d-8c674d09c432.png#averageHue=%23fcfcfc&clientId=uca85b293-4788-4&from=paste&height=388&id=uddd68540&originHeight=544&originWidth=560&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=23107&status=done&style=none&taskId=ub70402f9-10c0-4458-a03d-34faf75fdea&title=&width=399.5540827128461" alt="image.png"><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689238523784-1f4d46eb-5929-4b91-9a9c-ed1c079bbb44.png#averageHue=%23fcfcfc&clientId=uca85b293-4788-4&from=paste&height=362&id=uc4cfe88b&originHeight=507&originWidth=580&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=20010&status=done&style=none&taskId=ub403e638-48c1-4550-860a-89e8f8913c3&title=&width=413.823871381162" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689238532237-a56e0ff2-e665-4dfb-99ff-a1d3efd71532.png#averageHue=%23fcfcfc&clientId=uca85b293-4788-4&from=paste&height=396&id=uc175d01e&originHeight=555&originWidth=572&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=21564&status=done&style=none&taskId=u51fb7012-819b-4da9-b380-10be4a69d5b&title=&width=408.11595591383565" alt="image.png"></li></ol>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>13.用Gpu训练</title>
      <link href="/2023/08/20/13-%E7%94%A8Gpu%E8%AE%AD%E7%BB%83/"/>
      <url>/2023/08/20/13-%E7%94%A8Gpu%E8%AE%AD%E7%BB%83/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257370054-16027114-a607-4264-8a4f-4ed7cc73b502.png#averageHue=%23404138&clientId=u17bb579b-6d2b-4&from=paste&id=u78f34584&originHeight=410&originWidth=1037&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=263558&status=done&style=none&taskId=u9091ba39-ac84-4d83-80d6-e8498c56dec&title=" alt="image.png"></p><h3 id="文章目录"><a href="#文章目录" class="headerlink" title="文章目录"></a>文章目录</h3><ul><li><a href="https://editor.csdn.net/md/?articleId=131711411#Pycharm_5">一、Pycharm连接远程服务器</a></li><li><a href="https://editor.csdn.net/md/?articleId=131711411#xshell7xrtp7_60">二、xshell7和xrtp7配合使用</a></li><li><a href="https://editor.csdn.net/md/?articleId=131711411#_65">三、总结</a></li></ul><h1 id="一、Pycharm连接远程服务器"><a href="#一、Pycharm连接远程服务器" class="headerlink" title="一、Pycharm连接远程服务器"></a>一、Pycharm连接远程服务器</h1><p>首先要确定自己的Pycharm是专业版的，平时我们用的基本上都是社区版的Pycharm，社区版的Pycharm不带远程连接的功能，所以需要用专业版的Pycharm。给大家推一篇专业版Pycharm的安装教程，只要按照这个教程进行安装即可：<a href="https://blog.csdn.net/Feng512275/article/details/83548341?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522168925309116800184142759%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=168925309116800184142759&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-2-83548341-null-null.142%5Ev88%5Econtrol_2,239%5Ev2%5Einsert_chatgpt&utm_term=pycharm%E4%B8%93%E4%B8%9A%E7%89%88%E7%A0%B4%E8%A7%A3&spm=1018.2226.3001.4187">Pycharm专业版安装</a>。<br>打开界面，点击工具箱下的deployment下的configuration。<img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257370108-fce0562c-0ff2-441b-a4b6-d5156eb49d92.png#averageHue=%2381bb8d&clientId=u17bb579b-6d2b-4&from=paste&id=u7d7d76ee&originHeight=1023&originWidth=1921&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=189304&status=done&style=none&taskId=ufa099e15-ff31-4889-a4ae-b24fc9e8bf2&title=" alt="image.png"><br>点击加号添加服务器信息，选择SFTP，点击右边的…添加信息：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257369964-c8ee8a54-32cf-4a8c-b0c3-97ca8902d655.png#averageHue=%233d4043&clientId=u17bb579b-6d2b-4&from=paste&id=ua319863c&originHeight=810&originWidth=961&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=49836&status=done&style=none&taskId=u8c3cabac-014b-4a01-9ed6-cbb7a326632&title=" alt="image.png"><br>依次输入IP，端口号（默认是22），用户名（注意大小写），密码。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257369907-9362c7ce-9a62-4b32-ac47-6e5a097c1cdd.png#averageHue=%233d4042&clientId=u17bb579b-6d2b-4&from=paste&id=u8046223f&originHeight=843&originWidth=1000&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=45822&status=done&style=none&taskId=u6976a25a-3322-4ee9-a7fb-48d3f45f0a7&title=" alt="image.png"><br>点击确定后返回上一个界面，可以点击Test_connection尝试连接，successful connect说明可以正常连接服务器了。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257369988-a60b579e-41d2-485f-a536-5cc4af92c0b3.png#averageHue=%233c4042&clientId=u17bb579b-6d2b-4&from=paste&id=u3c3cee81&originHeight=810&originWidth=961&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=65456&status=done&style=none&taskId=ue2c71793-7e25-4605-afbe-20474c73043&title=" alt="image.png"><br><strong>关键一步来了！</strong>-——配置文件映射信息。点击mappings，local path即为本地文件夹的路径，用的是\斜杠，deployment path是远程服务器对应的路径，<strong>重点!</strong>,服务器最后的文件夹名称一定要和本地的文件夹名称一样，我这里本地是lzy，服务器也要创建一个lzy<strong>同名文件夹</strong>，否则后面运行文件时，<strong>会报找不到文件的错误！</strong><br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257370920-7bbe2896-9bfd-4133-bbce-2363057ab59f.png#averageHue=%233d4042&clientId=u17bb579b-6d2b-4&from=paste&id=u00fd9f8e&originHeight=810&originWidth=961&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=45924&status=done&style=none&taskId=ue4ae7009-c6d6-4ff0-aad2-1212701691f&title=" alt="image.png"><br>然后创建虚拟环境，选择ssh创建，选择我们之前创建好的服务器连接：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257371208-e9ce7645-800a-484f-aa2d-3fb9625b522d.png#averageHue=%233c4043&clientId=u17bb579b-6d2b-4&from=paste&id=ub9026781&originHeight=684&originWidth=1006&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=47144&status=done&style=none&taskId=u81f4824f-a5cd-4916-846d-1ccba53c12a&title=" alt="image.png"><br>选择远程服务器中conda的虚拟环境，然后把之前的文件的映射关系填到这上面来。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257371291-5dfe6d99-6d87-4d6e-949c-60b8c057f8ff.png#averageHue=%233c4042&clientId=u17bb579b-6d2b-4&from=paste&id=uc199ac42&originHeight=684&originWidth=1006&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=39724&status=done&style=none&taskId=ua97bbc85-7372-4728-9081-eb02c6b1a1e&title=" alt="image.png"><br>点击finish，点击右侧的齿轮然后showall，找到远程服务器的环境，点击右侧的编辑。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257371293-955dd98d-65e7-49c9-bca1-a9c0d798ea56.png#averageHue=%233f4347&clientId=u17bb579b-6d2b-4&from=paste&id=uf3b1a48c&originHeight=701&originWidth=783&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=56147&status=done&style=none&taskId=ub88c9862-bf0a-4479-92d0-3cf4209336f&title=" alt="image.png"><br>改为SSH连接，修改SSH configuration和解释器路径，修改成自己的就可以。然后点击OK。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257372074-7640a3bb-bd51-403a-bae4-50b54ffc7e4c.png#averageHue=%2340454a&clientId=u17bb579b-6d2b-4&from=paste&id=ub7f38a4a&originHeight=347&originWidth=684&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=31815&status=done&style=none&taskId=u63c4af50-cf27-493c-95d3-da2a36d9e57&title=" alt="image.png"><br>可以看到远程服务器上的虚拟环境中的库。我已经提前安装了Pytorch和torchvision和torchaudio，并且是GPU版本的。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257372696-3eaea03a-4804-42e1-b464-549d0da5d48d.png#averageHue=%233e4246&clientId=u17bb579b-6d2b-4&from=paste&id=u211106af&originHeight=843&originWidth=1180&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=79616&status=done&style=none&taskId=u917ef1e9-c0bc-4e74-a939-c92052975c1&title=" alt="image.png"><br>将文件自动上传打开，也可以手动上传文件，在上传时，点击整个目录夹，然后上传。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257372677-94a72cb1-56be-4190-bfcd-97f1b72b787c.png#averageHue=%237ebc8c&clientId=u17bb579b-6d2b-4&from=paste&id=u4a58018f&originHeight=576&originWidth=1921&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=137046&status=done&style=none&taskId=u297f2cf8-7c69-4d30-86fb-9d95d17bc9b&title=" alt="image.png"><br>写个脚本测试一下，服务器上的Gpu有没有成功连接：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257372755-8e38a3f4-dfa9-4fae-add9-4002fc3d7a6a.png#averageHue=%23f0e9cb&clientId=u17bb579b-6d2b-4&from=paste&id=u13617293&originHeight=1023&originWidth=1921&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=209716&status=done&style=none&taskId=u28e63fb8-6dc4-43eb-8567-ce9a253437d&title=" alt="image.png"><br>输出：</p><p>现在代码就是在远程服务器上跑的了，用的是服务器上的GPU，至此Pycharm连接远程服务器就结束了，<strong>开始愉快的使用服务器上的显卡吧！</strong>下面给大家推荐两个很实用的工具，xshell和xftp。</p><h1 id="二、xshell7和xrtp7配合使用"><a href="#二、xshell7和xrtp7配合使用" class="headerlink" title="二、xshell7和xrtp7配合使用"></a>二、xshell7和xrtp7配合使用</h1><p>xshell是用连接远程服务器的，xrtp是用来传输文件的。xshell连接之后就相当于linux的命令窗口，可以使用各种linux的指令来控制远程服务器的动作。xrtp是在xshell连接上之后，和远程服务器进行文件互传的工作，它有可视化界面，非常方便。xshell和xrtp免费版下载地址：<a href="https://www.xshell.com/zh/free-for-home-school/">xshell和xrtp免费版下载地址</a>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257372694-b482a589-79ca-4f9e-9928-8a01451e75b6.png#averageHue=%23646362&clientId=u17bb579b-6d2b-4&from=paste&id=u72d1dbff&originHeight=765&originWidth=984&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=84415&status=done&style=none&taskId=u45a3b815-fc0d-45b7-a4a8-5368c044140&title=" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689257373240-14988cdb-37eb-4366-b2b4-bbdf6ede34ee.png#averageHue=%23f3f2f0&clientId=u17bb579b-6d2b-4&from=paste&id=uc35e914e&originHeight=1067&originWidth=1388&originalType=url&ratio=1.4015624523162842&rotation=0&showTitle=false&size=176696&status=done&style=none&taskId=u0828ec20-6437-4e4e-a8cf-32a773dab81&title=" alt="image.png"><br>填ip和端口号，用户名和密码就可以直接连接了，下一次可以不用输密码直接连接了。主要网络问题，如果挂着代理，要把代理关掉，确保当前网络是适合连接当前服务器的。</p><h1 id="三、总结"><a href="#三、总结" class="headerlink" title="三、总结"></a>三、总结</h1><p>之前觉得配置远程服务器和本地的Pycharm连接非常麻烦，随着这篇博客的完成，感觉也不是很麻烦了。思路很清晰，之前踩的坑都帮大家一一说明了，如果大家还遇到了其他问题也欢迎在下方评论！</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：628test </span></span><br><span class="line"><span class="string">@File    ：test.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/6/28 23:24 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="built_in">print</span>(torch.cuda.is_available())</span><br><span class="line"><span class="built_in">print</span>(torch.__version__)</span><br><span class="line">cuda_version = torch.version.cuda</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;CUDA 版本:&quot;</span>, cuda_version)</span><br><span class="line">device = torch.cuda.get_device_name()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;名称:&quot;</span>, device)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="number">1.10</span><span class="number">.2</span>+cu111</span><br><span class="line">CUDA 版本: <span class="number">11.1</span></span><br><span class="line">名称: NVIDIA GeForce RTX <span class="number">3090</span></span><br></pre></td></tr></table></figure><p>将device设置成GPU</p><ul><li>device &#x3D; torch.device(“cuda” if torch.cuda.is_available() else “cpu”) # 三目判断</li><li>model &#x3D; model.to(device)</li><li>loss_F &#x3D; loss_F.to(device)</li><li>train_img &#x3D; train_img.to(device)</li><li>train_label &#x3D; train_label.to(device)<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：train_GPU.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 22:12 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> data</span><br><span class="line"><span class="keyword">from</span> Mymodel <span class="keyword">import</span> MyModule</span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># 0.设置参数</span></span><br><span class="line">batch_size = <span class="number">64</span></span><br><span class="line">lr = <span class="number">0.01</span></span><br><span class="line">epochs = <span class="number">20</span></span><br><span class="line">savetime = <span class="number">5</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># 1.准备数据集</span></span><br><span class="line">train_data = torchvision.datasets.CIFAR10(<span class="string">&quot;CIFAR10&quot;</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                          download=<span class="literal">True</span>)</span><br><span class="line">test_data = torchvision.datasets.CIFAR10(<span class="string">&quot;CIFAR10&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                         download=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2.加载数据集</span></span><br><span class="line">train_loader = data.DataLoader(dataset=train_data,batch_size=batch_size)</span><br><span class="line">test_loader = data.DataLoader(dataset=test_data,batch_size=batch_size)</span><br><span class="line">train_len = <span class="built_in">len</span>(train_loader)</span><br><span class="line">test_len = <span class="built_in">len</span>(test_loader)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练集长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_len))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试集长度为：&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_len))</span><br><span class="line"><span class="comment"># 3.定义网络结构，实例化模型</span></span><br><span class="line">model = MyModule()</span><br><span class="line">model = model.to(device)</span><br><span class="line"><span class="comment"># 4.定义损失函数</span></span><br><span class="line">loss_F = torch.nn.CrossEntropyLoss()</span><br><span class="line">loss_F = loss_F.to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5.定义参数更新方式</span></span><br><span class="line">optim = torch.optim.SGD(model.parameters(),lr=lr)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.开始训练和评估</span></span><br><span class="line">model.train()</span><br><span class="line">write = SummaryWriter(<span class="string">&quot;log_6&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;-------开始第&#123;&#125;轮训练，总共&#123;&#125;轮-------&quot;</span>.<span class="built_in">format</span>(epoch,epochs))</span><br><span class="line">    train_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> train_time,train_item <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        train_img,train_label = train_item</span><br><span class="line">        train_img = train_img.to(device)</span><br><span class="line">        train_label = train_label.to(device)</span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        result = model(train_img)</span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = loss_F(result,train_label)</span><br><span class="line">        <span class="comment"># 反向传播更新参数</span></span><br><span class="line">        optim.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optim.step()</span><br><span class="line">        train_loss += loss</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    right =<span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> test_time,test_item <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_loader):</span><br><span class="line">            test_img,test_label = test_item</span><br><span class="line">            test_img = test_img.to(device)</span><br><span class="line">            test_label = test_label.to(device)</span><br><span class="line">            test_result = model(test_img)</span><br><span class="line">            <span class="comment"># 获取测试集上的loss</span></span><br><span class="line">            loss = loss_F(test_result,test_label)</span><br><span class="line">            test_loss += loss</span><br><span class="line">            <span class="comment"># 获取测试集上的准确率</span></span><br><span class="line">            right += (test_result.argmax(<span class="number">1</span>) == test_label).<span class="built_in">sum</span>()</span><br><span class="line">    accuracy = right/test_len</span><br><span class="line">    write.add_scalar(<span class="string">&quot;train_loss&quot;</span>,train_loss,epoch)</span><br><span class="line">    write.add_scalar(<span class="string">&quot;test_loss&quot;</span>,test_loss,epoch)</span><br><span class="line">    write.add_scalar(<span class="string">&quot;accuracy&quot;</span>,accuracy,epoch)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练集上的损失为:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(train_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;测试集上的损失为:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(test_loss))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;测试集上的准确率为:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(accuracy))</span><br><span class="line">    <span class="keyword">if</span> epoch % savetime ==<span class="number">0</span>:</span><br><span class="line">        torch.save(model,<span class="string">&quot;./model/model&#123;&#125;.pth&quot;</span>.<span class="built_in">format</span>(epoch))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练完成！&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>14.Dropout</title>
      <link href="/2023/08/20/14-Dropout/"/>
      <url>/2023/08/20/14-Dropout/</url>
      
        <content type="html"><![CDATA[<p>在训练过程中，dropout会以概率p随机地将一些神经元的输出设置为0，防止过拟合。在测试过程中，dropout不会被应用，而是通过将每个神经元的输出乘以保留概率（通常为0.5）来进行缩放。这是因为测试时，我们希望利用所有的神经元来获得更好的预测结果。<br>dropout的工作原理是，在每个训练批次中，随机选择一些神经元，并将它们的输出设置为0。这样做的结果是，网络不再依赖于特定的神经元，而是强迫网络学习多个独立的特征子集，从而减少了过拟合的风险。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Dropout(p=<span class="number">0.5</span>, inplace=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689312331805-3c5dde65-c415-4962-9e2d-fd61b0d3c4fa.png#averageHue=%23fefefe&clientId=ubcf07a11-b406-4&from=paste&height=290&id=u581be1e2&originHeight=407&originWidth=794&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=135581&status=done&style=none&taskId=uf2cae1c8-b21c-4837-a9b1-039306aa440&title=&width=566.5106101321425" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689312358007-5ba99320-af05-4612-9402-1ca40bd8f654.png#averageHue=%23fefefe&clientId=ubcf07a11-b406-4&from=paste&height=320&id=u5911c6f0&originHeight=448&originWidth=886&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=132633&status=done&style=none&taskId=udddc6bdf-15dd-46fc-bd5b-0e2603cd771&title=&width=632.1516380063957" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689312344337-aa8df863-f589-41da-b6c5-26c0bd192d8f.png#averageHue=%23fefefe&clientId=ubcf07a11-b406-4&from=paste&height=352&id=ud6112dd0&originHeight=493&originWidth=906&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=126219&status=done&style=none&taskId=u837fe9fe-a4f1-42ad-a606-2c7557d043f&title=&width=646.4214266747117" alt="image.png"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>15.SA和CA注意力机制</title>
      <link href="/2023/08/20/15-SA%E5%92%8CCA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/"/>
      <url>/2023/08/20/15-SA%E5%92%8CCA%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689328067114-50533b38-cf3e-4b52-8b2f-90eefa7ba13f.png#averageHue=%23eeedec&clientId=u27724aa6-6d23-4&from=paste&height=366&id=ue5cb5826&originHeight=513&originWidth=971&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=152709&status=done&style=none&taskId=u5a5f4251-7500-4c13-ba12-ff608bd128e&title=&width=692.7982398467385" alt="image.png"></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/env python</span><br><span class="line"># -*- coding: UTF-8 -*-</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">@Project ：Pytorch_learn </span><br><span class="line">@File    ：Myattention.py</span><br><span class="line">@IDE     ：PyCharm </span><br><span class="line">@Author  ：咋</span><br><span class="line">@Date    ：2023/7/14 17:42 </span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">from torch.nn import Conv2d</span><br><span class="line"></span><br><span class="line">class Channel_attention(nn.Module):</span><br><span class="line">    def __init__(self,channel,ratio=16):</span><br><span class="line">        super(Channel_attention, self).__init__()</span><br><span class="line">        self.max_pool = nn.AdaptiveMaxPool2d(1)</span><br><span class="line">        self.avg_pool = nn.AdaptiveAvgPool2d(1)</span><br><span class="line">        self.fc = nn.Sequential(</span><br><span class="line">            nn.Linear(channel,channel//ratio,False),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(channel//ratio,channel,False),</span><br><span class="line">        )</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line">    def forward(self,x):</span><br><span class="line">        b,c,h,w = x.size()</span><br><span class="line">        maxpool = self.max_pool(x).view([b,c])</span><br><span class="line">        avgpool = self.avg_pool(x).view([b,c])</span><br><span class="line">        maxpool_fc = self.fc(maxpool)</span><br><span class="line">        avgpool_fc = self.fc(avgpool)</span><br><span class="line">        out =maxpool_fc+avgpool_fc</span><br><span class="line">        out = self.sigmoid(out).view([b,c,1,1])</span><br><span class="line">        return out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class Spacial_attention(nn.Module):</span><br><span class="line">    def __init__(self,kernel_size=7):</span><br><span class="line">        super(Spacial_attention, self).__init__()</span><br><span class="line">        self.conv1 = Conv2d(2,1,kernel_size,1,padding=3,bias=False)</span><br><span class="line">        self.sigmoid = nn.Sigmoid()</span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        max_pool_out,_ = torch.max(x,dim=1,keepdim=True)</span><br><span class="line">        avg_pool_out = torch.mean(x,dim=1,keepdim=True)</span><br><span class="line">        pool_out = torch.cat([max_pool_out,avg_pool_out],dim=1)</span><br><span class="line">        out = self.conv1(pool_out)</span><br><span class="line">        out = self.sigmoid(out)</span><br><span class="line">        return out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class My_attention(nn.Module):</span><br><span class="line">    def __init__(self,channel,ratio=16,kernel_size=7):</span><br><span class="line">        super(My_attention, self).__init__()</span><br><span class="line">        self.channel_attention = Channel_attention(channel)</span><br><span class="line">        self.spacial_attention = Spacial_attention()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    def forward(self,x):</span><br><span class="line">        SA_x = self.spacial_attention(x)*x   # 空间注意力机制求的结果</span><br><span class="line">        CA_x = self.channel_attention(x)*x   # 通道注意力机制求的结果</span><br><span class="line">        output = SA_x+CA_x+x    # 将三个特征图加在一起</span><br><span class="line">        return output</span><br><span class="line"></span><br><span class="line">myattention = My_attention(512)</span><br><span class="line">print(myattention)</span><br><span class="line">inputs = torch.ones([2,512,26,26])</span><br><span class="line">outputs = myattention(inputs)</span><br><span class="line">print(outputs)</span><br><span class="line">print(outputs.size())</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>16.Unet</title>
      <link href="/2023/08/20/16-Unet/"/>
      <url>/2023/08/20/16-Unet/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689328149107-2b62a4a4-ffba-4c0b-be7c-5cb9c4837ef1.png#averageHue=%23fefdfd&clientId=ue79d56f7-95fb-4&from=paste&height=542&id=u8e034505&originHeight=760&originWidth=1195&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=209951&status=done&style=none&taskId=uea74b23c-d625-449d-a108-564b35090dc&title=&width=852.6198729318769" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：unet_parts.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/14 17:47 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Conv_Block</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_channel,out_channel</span>):</span><br><span class="line">        <span class="built_in">super</span>(Conv_Block, self).__init__()</span><br><span class="line">        self.layer = nn.Sequential(</span><br><span class="line">            nn.Conv2d(in_channel,out_channel,kernel_size=<span class="number">3</span>,stride=<span class="number">1</span>,padding=<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channel),</span><br><span class="line">            nn.Relu(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(out_channel,out_channel,<span class="number">3</span>,<span class="number">1</span>,<span class="number">1</span>,bias=<span class="literal">False</span>),</span><br><span class="line">            nn.BatchNorm2d(out_channel),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>)</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.layer(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Down</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_channel,out_channel</span>):</span><br><span class="line">        <span class="built_in">super</span>(Down, self).__init__()</span><br><span class="line">        self.maxpool_conv = nn.Sequential(</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            Conv_Block(in_channel,out_channel)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.maxpool_conv(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Up</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_channel,out_channel,bilinear=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Up, self).__init__()</span><br><span class="line">        self.up = nn.Upsample(scale_factor=<span class="number">2</span>,mode=<span class="string">&quot;bilinear&quot;</span>,align_corners=<span class="literal">True</span>)</span><br><span class="line">        self.conv = Conv_Block(in_channel,out_channel)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x1,x2</span>):</span><br><span class="line">        x1 = self.up(x1)</span><br><span class="line">        <span class="comment"># 下面这里有点不大懂，GPT给的解释是</span></span><br><span class="line">        <span class="comment"># 这样的填充操作是为了保持x1和x2在高度和宽度上的尺寸一致。通过计算尺寸差异并进行填充，可以将x1的尺寸调整为与x2相同，以便进行后续的拼接操作。</span></span><br><span class="line">        diffY = x2.size()[<span class="number">2</span>]-x1.size()[<span class="number">2</span>]</span><br><span class="line">        diffX = x2.size()[<span class="number">3</span>]-x1.size()[<span class="number">3</span>]</span><br><span class="line">        x1 = F.pad(x1,[diffX//<span class="number">2</span>,diffX-diffX//<span class="number">2</span>,</span><br><span class="line">                       diffY//<span class="number">2</span>,diffY-diffY//<span class="number">2</span>])</span><br><span class="line">        x = torch.cat([x2,x1],dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">OutConv</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,in_channel,out_channel</span>):</span><br><span class="line">        <span class="built_in">super</span>(OutConv, self).__init__()</span><br><span class="line">        self.conv = nn.Conv2d(in_channel,out_channel,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        <span class="keyword">return</span> self.conv(x)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：unet.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/15 15:37 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> unet_parts <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Unet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,n_channels,n_classes,bilinear=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Unet, self).__init__()</span><br><span class="line">        self.n_channels = n_channels</span><br><span class="line">        self.n_classes = n_classes</span><br><span class="line">        self.bilinear = bilinear</span><br><span class="line"></span><br><span class="line">        self.inc = (Conv_Block(n_channels, <span class="number">64</span>))</span><br><span class="line">        self.down1 = (Down(<span class="number">64</span>, <span class="number">128</span>))</span><br><span class="line">        self.down2 = (Down(<span class="number">128</span>, <span class="number">256</span>))</span><br><span class="line">        self.down3 = (Down(<span class="number">256</span>, <span class="number">512</span>))</span><br><span class="line">        factor = <span class="number">2</span> <span class="keyword">if</span> bilinear <span class="keyword">else</span> <span class="number">1</span></span><br><span class="line">        self.down4 = (Down(<span class="number">512</span>, <span class="number">1024</span> // factor))</span><br><span class="line">        self.up1 = (Up(<span class="number">1024</span>, <span class="number">512</span> // factor, bilinear))</span><br><span class="line">        self.up2 = (Up(<span class="number">512</span>, <span class="number">256</span> // factor, bilinear))</span><br><span class="line">        self.up3 = (Up(<span class="number">256</span>, <span class="number">128</span> // factor, bilinear))</span><br><span class="line">        self.up4 = (Up(<span class="number">128</span>, <span class="number">64</span>, bilinear))</span><br><span class="line">        self.outc = (OutConv(<span class="number">64</span>, n_classes))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x1 = self.inc(x)</span><br><span class="line">        x2 = self.down1(x1)</span><br><span class="line">        x3 = self.down2(x2)</span><br><span class="line">        x4 = self.down3(x3)</span><br><span class="line">        x5 = self.down4(x4)</span><br><span class="line">        x = self.up1(x5, x4)</span><br><span class="line">        x = self.up2(x, x3)</span><br><span class="line">        x = self.up3(x, x2)</span><br><span class="line">        x = self.up4(x, x1)</span><br><span class="line">        logits = self.outc(x)</span><br><span class="line">        <span class="keyword">return</span> logits</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>2.dir与help函数</title>
      <link href="/2023/08/20/2-dir%E4%B8%8Ehelp%E5%87%BD%E6%95%B0/"/>
      <url>/2023/08/20/2-dir%E4%B8%8Ehelp%E5%87%BD%E6%95%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="dir函数"><a href="#dir函数" class="headerlink" title="dir函数"></a>dir函数</h1><p>查看一个大类里面有什么小类</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">print(dir(torch.cuda))</span><br><span class="line"></span><br><span class="line"># return</span><br><span class="line">[&#x27;Any&#x27;, &#x27;BFloat16Storage&#x27;, &#x27;BFloat16Tensor&#x27;, &#x27;BoolStorage&#x27;, &#x27;BoolTensor&#x27;, &#x27;ByteStorage&#x27;, &#x27;ByteTensor&#x27;, &#x27;CUDAGraph&#x27;, &#x27;CharStorage&#x27;, &#x27;CharTensor&#x27;, &#x27;ComplexDoubleStorage&#x27;, &#x27;ComplexFloatStorage&#x27;, &#x27;CudaError&#x27;, &#x27;DeferredCudaCallError&#x27;, &#x27;Device&#x27;, &#x27;Dict&#x27;, &#x27;DoubleStorage&#x27;, &#x27;DoubleTensor&#x27;, &#x27;Event&#x27;, &#x27;FloatStorage&#x27;, &#x27;FloatTensor&#x27;, &#x27;HalfStorage&#x27;, &#x27;HalfTensor&#x27;, &#x27;IntStorage&#x27;, &#x27;IntTensor&#x27;, &#x27;List&#x27;, &#x27;LongStorage&#x27;, &#x27;LongTensor&#x27;, &#x27;Optional&#x27;, &#x27;ShortStorage&#x27;, &#x27;ShortTensor&#x27;, &#x27;Stream&#x27;, &#x27;StreamContext&#x27;, &#x27;Tuple&#x27;, &#x27;Union&#x27;, &#x27;_CudaBase&#x27;, &#x27;_CudaDeviceProperties&#x27;, &#x27;_LazySeedTracker&#x27;, &#x27;_StorageBase&#x27;, &#x27;__annotations__&#x27;, &#x27;__builtins__&#x27;, &#x27;__cached__&#x27;, &#x27;__doc__&#x27;, &#x27;__file__&#x27;, &#x27;__loader__&#x27;, &#x27;__name__&#x27;, &#x27;__package__&#x27;, &#x27;__path__&#x27;, &#x27;__spec__&#x27;, &#x27;_check_capability&#x27;, &#x27;_check_cubins&#x27;, &#x27;_cudart&#x27;, &#x27;_device&#x27;, &#x27;_device_t&#x27;, &#x27;_dummy_type&#x27;, &#x27;_get_device_index&#x27;, &#x27;_initialization_lock&#x27;, &#x27;_initialized&#x27;, &#x27;_is_in_bad_fork&#x27;, &#x27;_lazy_call&#x27;, &#x27;_lazy_init&#x27;, &#x27;_lazy_new&#x27;, &#x27;_lazy_seed_tracker&#x27;, &#x27;_queued_calls&#x27;, &#x27;_sleep&#x27;, &#x27;_tls&#x27;, &#x27;_utils&#x27;, &#x27;amp&#x27;, &#x27;caching_allocator_alloc&#x27;, &#x27;caching_allocator_delete&#x27;, &#x27;can_device_access_peer&#x27;, &#x27;check_error&#x27;, &#x27;collections&#x27;, &#x27;contextlib&#x27;, &#x27;cudaStatus&#x27;, &#x27;cudart&#x27;, &#x27;current_blas_handle&#x27;, &#x27;current_device&#x27;, &#x27;current_stream&#x27;, &#x27;default_generators&#x27;, &#x27;default_stream&#x27;, &#x27;device&#x27;, &#x27;device_count&#x27;, &#x27;device_of&#x27;, &#x27;empty_cache&#x27;, &#x27;get_arch_list&#x27;, &#x27;get_device_capability&#x27;, &#x27;get_device_name&#x27;, &#x27;get_device_properties&#x27;, &#x27;get_gencode_flags&#x27;, &#x27;get_rng_state&#x27;, &#x27;get_rng_state_all&#x27;, &#x27;get_sync_debug_mode&#x27;, &#x27;graph&#x27;, &#x27;graph_pool_handle&#x27;, &#x27;graphs&#x27;, &#x27;has_half&#x27;, &#x27;has_magma&#x27;, &#x27;init&#x27;, &#x27;initial_seed&#x27;, &#x27;ipc_collect&#x27;, &#x27;is_available&#x27;, &#x27;is_bf16_supported&#x27;, &#x27;is_initialized&#x27;, &#x27;list_gpu_processes&#x27;, &#x27;make_graphed_callables&#x27;, &#x27;manual_seed&#x27;, &#x27;manual_seed_all&#x27;, &#x27;max_memory_allocated&#x27;, &#x27;max_memory_cached&#x27;, &#x27;max_memory_reserved&#x27;, &#x27;mem_get_info&#x27;, &#x27;memory&#x27;, &#x27;memory_allocated&#x27;, &#x27;memory_cached&#x27;, &#x27;memory_reserved&#x27;, &#x27;memory_snapshot&#x27;, &#x27;memory_stats&#x27;, &#x27;memory_stats_as_nested_dict&#x27;, &#x27;memory_summary&#x27;, &#x27;nccl&#x27;, &#x27;nvtx&#x27;, &#x27;os&#x27;, &#x27;profiler&#x27;, &#x27;random&#x27;, &#x27;reset_accumulated_memory_stats&#x27;, &#x27;reset_max_memory_allocated&#x27;, &#x27;reset_max_memory_cached&#x27;, &#x27;reset_peak_memory_stats&#x27;, &#x27;seed&#x27;, &#x27;seed_all&#x27;, &#x27;set_device&#x27;, &#x27;set_per_process_memory_fraction&#x27;, &#x27;set_rng_state&#x27;, &#x27;set_rng_state_all&#x27;, &#x27;set_stream&#x27;, &#x27;set_sync_debug_mode&#x27;, &#x27;sparse&#x27;, &#x27;stream&#x27;, &#x27;streams&#x27;, &#x27;synchronize&#x27;, &#x27;threading&#x27;, &#x27;torch&#x27;, &#x27;traceback&#x27;, &#x27;warnings&#x27;]</span><br><span class="line"># 如果出现__xx__说明这个函数已经分到底了，无法再继续细分，这里面双下划线其实是这个函数的变量，无法修改</span><br></pre></td></tr></table></figure><h1 id="help"><a href="#help" class="headerlink" title="help"></a>help</h1><p>查看函数什么作用</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="comment"># print(dir(torch.cuda))</span></span><br><span class="line"><span class="built_in">help</span>(torch.cuda.is_available)  <span class="comment"># 记得去掉括号</span></span><br><span class="line"><span class="comment"># return</span></span><br><span class="line">is_available() -&gt; <span class="built_in">bool</span></span><br><span class="line">    Returns a <span class="built_in">bool</span> indicating <span class="keyword">if</span> CUDA <span class="keyword">is</span> currently available.</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>17.Resnet</title>
      <link href="/2023/08/20/17-Resnet/"/>
      <url>/2023/08/20/17-Resnet/</url>
      
        <content type="html"><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：moban.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/15 21:19 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6.9定稿版本</span></span><br><span class="line"><span class="comment"># 参考：</span></span><br><span class="line"><span class="comment"># arxiv 1505.04597</span></span><br><span class="line"><span class="comment"># arxiv 1801.05746，官方实现：https://github.com/ternaus/TernausNet</span></span><br><span class="line"><span class="comment"># https://blog.csdn.net/github_36923418/article/details/83273107</span></span><br><span class="line"><span class="comment"># pixelshuffle参考: arxiv 1609.05158</span></span><br><span class="line"></span><br><span class="line">backbone = <span class="string">&#x27;resnet50&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderBlock</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    U-Net中的解码模块</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    采用每个模块一个stride为1的3*3卷积加一个上采样层的形式</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    上采样层可使用&#x27;deconv&#x27;、&#x27;pixelshuffle&#x27;, 其中pixelshuffle必须要mid_channels=4*out_channles</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    定稿采用pixelshuffle</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    BN_enable控制是否存在BN，定稿设置为True</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_channels, mid_channels, out_channels, upsample_mode=<span class="string">&#x27;pixelshuffle&#x27;</span>, BN_enable=<span class="literal">True</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.in_channels = in_channels</span><br><span class="line">        self.mid_channels = mid_channels</span><br><span class="line">        self.out_channels = out_channels</span><br><span class="line">        self.upsample_mode = upsample_mode</span><br><span class="line">        self.BN_enable = BN_enable</span><br><span class="line"></span><br><span class="line">        self.conv = nn.Conv2d(in_channels=in_channels, out_channels=mid_channels, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>,</span><br><span class="line">                              bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.BN_enable:</span><br><span class="line">            self.norm1 = nn.BatchNorm2d(mid_channels)</span><br><span class="line">        self.relu1 = nn.ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line">        self.relu2 = nn.ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> self.upsample_mode == <span class="string">&#x27;deconv&#x27;</span>:</span><br><span class="line">            self.upsample = nn.ConvTranspose2d(in_channels=mid_channels, out_channels=out_channels,</span><br><span class="line"></span><br><span class="line">                                               kernel_size=<span class="number">3</span>, stride=<span class="number">2</span>, padding=<span class="number">1</span>, output_padding=<span class="number">1</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">elif</span> self.upsample_mode == <span class="string">&#x27;pixelshuffle&#x27;</span>:</span><br><span class="line">            self.upsample = nn.PixelShuffle(upscale_factor=<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">if</span> self.BN_enable:</span><br><span class="line">            self.norm2 = nn.BatchNorm2d(out_channels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.conv(x)</span><br><span class="line">        <span class="keyword">if</span> self.BN_enable:</span><br><span class="line">            x = self.norm1(x)</span><br><span class="line">        x = self.relu1(x)</span><br><span class="line">        x = self.upsample(x)</span><br><span class="line">        <span class="keyword">if</span> self.BN_enable:</span><br><span class="line">            x = self.norm2(x)</span><br><span class="line">        x = self.relu2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Resnet_Unet</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    定稿使用resnet50作为backbone</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    BN_enable控制是否存在BN，定稿设置为True</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, BN_enable=<span class="literal">True</span>, resnet_pretrain=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.BN_enable = BN_enable</span><br><span class="line">        <span class="comment"># encoder部分</span></span><br><span class="line">        <span class="comment"># 使用resnet34或50预定义模型，由于单通道入，因此自定义第一个conv层，同时去掉原fc层</span></span><br><span class="line">        <span class="comment"># 剩余网络各部分依次继承</span></span><br><span class="line">        <span class="comment"># 经过测试encoder取三层效果比四层更佳，因此降采样、升采样各取4次</span></span><br><span class="line">        <span class="keyword">if</span> backbone == <span class="string">&#x27;resnet34&#x27;</span>:</span><br><span class="line">            resnet = models.resnet34(pretrained=resnet_pretrain)</span><br><span class="line">            filters = [<span class="number">64</span>, <span class="number">64</span>, <span class="number">128</span>, <span class="number">256</span>, <span class="number">512</span>]</span><br><span class="line">        <span class="keyword">elif</span> backbone == <span class="string">&#x27;resnet50&#x27;</span>:</span><br><span class="line">            resnet = models.resnet50(pretrained=resnet_pretrain)</span><br><span class="line">            filters = [<span class="number">64</span>, <span class="number">256</span>, <span class="number">512</span>, <span class="number">1024</span>, <span class="number">2048</span>]</span><br><span class="line">        self.firstconv = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=<span class="number">64</span>, kernel_size=<span class="number">7</span>, stride=<span class="number">2</span>, padding=<span class="number">3</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.firstbn = resnet.bn1</span><br><span class="line">        self.firstrelu = resnet.relu</span><br><span class="line">        self.firstmaxpool = resnet.maxpool</span><br><span class="line">        self.encoder1 = resnet.layer1</span><br><span class="line">        self.encoder2 = resnet.layer2</span><br><span class="line">        self.encoder3 = resnet.layer3</span><br><span class="line"></span><br><span class="line">        <span class="comment"># decoder部分</span></span><br><span class="line">        self.center = DecoderBlock(in_channels=filters[<span class="number">3</span>], mid_channels=filters[<span class="number">3</span>] * <span class="number">4</span>, out_channels=filters[<span class="number">3</span>],</span><br><span class="line">                                   BN_enable=self.BN_enable)</span><br><span class="line">        self.decoder1 = DecoderBlock(in_channels=filters[<span class="number">3</span>] + filters[<span class="number">2</span>], mid_channels=filters[<span class="number">2</span>] * <span class="number">4</span>,</span><br><span class="line">                                     out_channels=filters[<span class="number">2</span>], BN_enable=self.BN_enable)</span><br><span class="line">        self.decoder2 = DecoderBlock(in_channels=filters[<span class="number">2</span>] + filters[<span class="number">1</span>], mid_channels=filters[<span class="number">1</span>] * <span class="number">4</span>,</span><br><span class="line">                                     out_channels=filters[<span class="number">1</span>], BN_enable=self.BN_enable)</span><br><span class="line">        self.decoder3 = DecoderBlock(in_channels=filters[<span class="number">1</span>] + filters[<span class="number">0</span>], mid_channels=filters[<span class="number">0</span>] * <span class="number">4</span>,</span><br><span class="line">                                     out_channels=filters[<span class="number">0</span>], BN_enable=self.BN_enable)</span><br><span class="line">        <span class="keyword">if</span> self.BN_enable:</span><br><span class="line">            self.final = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=filters[<span class="number">0</span>], out_channels=<span class="number">32</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">False</span>),</span><br><span class="line">                nn.Conv2d(in_channels=<span class="number">32</span>, out_channels=<span class="number">1</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.Sigmoid()</span><br><span class="line">            )</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.final = nn.Sequential(</span><br><span class="line">                nn.Conv2d(in_channels=filters[<span class="number">0</span>], out_channels=<span class="number">32</span>, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                nn.ReLU(inplace=<span class="literal">False</span>),</span><br><span class="line">                nn.Conv2d(in_channels=<span class="number">32</span>, out_channels=<span class="number">1</span>, kernel_size=<span class="number">1</span>),</span><br><span class="line">                nn.Sigmoid()</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.firstconv(x)</span><br><span class="line">        x = self.firstbn(x)</span><br><span class="line">        x = self.firstrelu(x)</span><br><span class="line">        x_ = self.firstmaxpool(x)</span><br><span class="line"></span><br><span class="line">        e1 = self.encoder1(x_)</span><br><span class="line">        e2 = self.encoder2(e1)</span><br><span class="line">        e3 = self.encoder3(e2)</span><br><span class="line"></span><br><span class="line">        center = self.center(e3)</span><br><span class="line"></span><br><span class="line">        d2 = self.decoder1(torch.cat([center, e2], dim=<span class="number">1</span>))</span><br><span class="line">        d3 = self.decoder2(torch.cat([d2, e1], dim=<span class="number">1</span>))</span><br><span class="line">        d4 = self.decoder3(torch.cat([d3, x], dim=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> self.final(d4)</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>4.TensorBoard</title>
      <link href="/2023/08/20/4-TensorBoard/"/>
      <url>/2023/08/20/4-TensorBoard/</url>
      
        <content type="html"><![CDATA[<p>作用：用于展示某个值或者图像的变换过程</p><h2 id="用于展示值的变化"><a href="#用于展示值的变化" class="headerlink" title="用于展示值的变化"></a>用于展示值的变化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch学习 </span></span><br><span class="line"><span class="string">@File    ：tensorboard.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/6/29 15:59 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">from torch.utils.tensorboard.writer import SummaryWriter 报错</span></span><br><span class="line"><span class="string">解决方法:</span></span><br><span class="line"><span class="string">pip install  -i https://mirrors.aliyun.com/pypi/simple/ tensorboardX</span></span><br><span class="line"><span class="string">from tensorboardX import SummaryWriter</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="comment"># from torch.utils.tensorboard.writer import SummaryWriter</span></span><br><span class="line"></span><br><span class="line">writer = SummaryWriter(<span class="string">&quot;logs&quot;</span>)</span><br><span class="line"><span class="comment"># writer.add_image()</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    writer.add_scalar(<span class="string">&quot;y=2x&quot;</span>,<span class="number">2</span>*i,i)</span><br><span class="line">writer.close()</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">开启指令：</span></span><br><span class="line"><span class="string">tensorboard --logdir=logs --port=6007 # port指定端口号，防止冲突  # 使用anaconda powershell 打开</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688027885696-517c997b-7cf1-4029-9136-e261490520a5.png#averageHue=%23deddad&clientId=u2a0bc918-fafe-4&from=paste&height=906&id=u72fab822&originHeight=1380&originWidth=2160&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=201652&status=done&style=none&taskId=udb6c123b-ee84-40f7-8128-a7942d5d736&title=&width=1417.8461538461538" alt="image.png"></p><h2 id="用于展示图像的变化"><a href="#用于展示图像的变化" class="headerlink" title="用于展示图像的变化"></a>用于展示图像的变化</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch学习 </span></span><br><span class="line"><span class="string">@File    ：tensorboard_2.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/6/29 16:48 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">write = SummaryWriter(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">image = cv2.imread(<span class="string">&quot;data\\train\\ants_image\\5650366_e22b7e1065.jpg&quot;</span>)</span><br><span class="line"><span class="comment"># write.add_image(&quot;test&quot;,image,1,dataformats=&#x27;HWC&#x27;)</span></span><br><span class="line">write.add_image(<span class="string">&quot;test&quot;</span>,image,<span class="number">2</span>,dataformats=<span class="string">&#x27;HWC&#x27;</span>)</span><br><span class="line">write.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688032249682-9106d709-7655-49af-953c-5ff4390acb09.png#averageHue=%23eb9c55&clientId=u7be588cf-d23b-4&from=paste&height=303&id=u53e4ef85&originHeight=462&originWidth=473&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=127369&status=done&style=none&taskId=u8456c2ef-b9a8-4bb5-9bcd-940361502c8&title=&width=310.48205128205126" alt="image.png"><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688032259574-aa3590f0-3db4-4ebf-a335-ff9e8ccfb33c.png#averageHue=%23827e2e&clientId=u7be588cf-d23b-4&from=paste&height=326&id=uce621bca&originHeight=496&originWidth=555&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=136317&status=done&style=none&taskId=udda35877-4870-456b-aa47-b486ab3dfec&title=&width=364.3076923076923" alt="image.png"><br>上面有一个滑动条，可以拖动滑动条展示图片的变化过程，这个方法可以用在pytorch模型训练时，可视化出特征图的变化。<br>ps：奇怪的是用pycharm的终端和本地的终端tensorboard –logdir&#x3D;logs –port&#x3D;6007都进不去，anaconda powershell 能进去，而且本地的终端，社区版还有jupyter notebook的终端一运行就会跳转到专业版的pycharm，就很奇怪。没有报错，但是没有给连接地址，之后用tensorboard的话就用anaconda自带的终端进入。</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>5.Transforms</title>
      <link href="/2023/08/20/5-Transforms/"/>
      <url>/2023/08/20/5-Transforms/</url>
      
        <content type="html"><![CDATA[<p>question?</p><ul><li>为什么要使用transform？</li><li>怎么使用transform？</li></ul><h1 id="question1"><a href="#question1" class="headerlink" title="question1"></a>question1</h1><p>加快运算，使用GPU运算，加快计算速度！</p><h1 id="question2"><a href="#question2" class="headerlink" title="question2"></a>question2</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：transform_1.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/6/29 18:16 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">image_path = <span class="string">&quot;data\\train\\ants_image\\5650366_e22b7e1065.jpg&quot;</span></span><br><span class="line"></span><br><span class="line">image = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line">transform_tool = transforms.ToTensor()  <span class="comment"># 创建一个transform工具</span></span><br><span class="line">image_tensor = transform_tool(image)</span><br><span class="line"><span class="built_in">print</span>(image_tensor)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># output</span></span><br><span class="line"><span class="comment"># tensor([[[0.3804, 0.3804, 0.3843,  ..., 0.3412, 0.3373, 0.3333],</span></span><br><span class="line"><span class="comment">#          [0.3765, 0.3804, 0.3843,  ..., 0.3529, 0.3490, 0.3451],</span></span><br><span class="line"><span class="comment">#          [0.3804, 0.3804, 0.3843,  ..., 0.3725, 0.3686, 0.3647],</span></span><br><span class="line"><span class="comment">#          ...,</span></span><br><span class="line"><span class="comment">#          [0.6078, 0.6078, 0.6118,  ..., 0.4627, 0.4627, 0.4627],</span></span><br><span class="line"><span class="comment">#          [0.5882, 0.5922, 0.5922,  ..., 0.4588, 0.4588, 0.4588],</span></span><br><span class="line"><span class="comment">#          [0.5804, 0.5804, 0.5843,  ..., 0.4549, 0.4549, 0.4549]],</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#         [[0.4667, 0.4667, 0.4706,  ..., 0.4039, 0.4000, 0.3961],</span></span><br><span class="line"><span class="comment">#          [0.4706, 0.4667, 0.4706,  ..., 0.3922, 0.3882, 0.3843],</span></span><br><span class="line"><span class="comment">#          [0.4745, 0.4745, 0.4784,  ..., 0.3804, 0.3765, 0.3725],</span></span><br><span class="line"><span class="comment">#          ...,</span></span><br><span class="line"><span class="comment">#          [0.5961, 0.5961, 0.6000,  ..., 0.4588, 0.4588, 0.4588],</span></span><br><span class="line"><span class="comment">#          [0.5882, 0.5922, 0.5922,  ..., 0.4549, 0.4549, 0.4549],</span></span><br><span class="line"><span class="comment">#          [0.5804, 0.5804, 0.5804,  ..., 0.4510, 0.4510, 0.4510]],</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#         [[0.4157, 0.4157, 0.4196,  ..., 0.3608, 0.3569, 0.3529],</span></span><br><span class="line"><span class="comment">#          [0.4196, 0.4157, 0.4196,  ..., 0.3569, 0.3529, 0.3490],</span></span><br><span class="line"><span class="comment">#          [0.4235, 0.4235, 0.4235,  ..., 0.3608, 0.3569, 0.3529],</span></span><br><span class="line"><span class="comment">#          ...,</span></span><br><span class="line"><span class="comment">#          [0.5608, 0.5608, 0.5647,  ..., 0.4392, 0.4392, 0.4392],</span></span><br><span class="line"><span class="comment">#          [0.5412, 0.5529, 0.5608,  ..., 0.4353, 0.4353, 0.4353],</span></span><br><span class="line"><span class="comment">#          [0.5333, 0.5412, 0.5608,  ..., 0.4314, 0.4314, 0.4314]]])</span></span><br></pre></td></tr></table></figure><p>transform其实就是一个工具箱，我们可以用transform提供的工具制造我们自己的工具。</p><h1 id="常见的transform"><a href="#常见的transform" class="headerlink" title="常见的transform"></a>常见的transform</h1><h2 id="1-tosensor"><a href="#1-tosensor" class="headerlink" title="1.tosensor"></a>1.tosensor</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line">image_path = <span class="string">&quot;test.jpg&quot;</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(image_path)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># totensor</span></span><br><span class="line">tran_tensor = transforms.ToTensor()</span><br><span class="line">image_tensor = tran_tensor(image)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(image))</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(image_tensor))</span><br></pre></td></tr></table></figure><p>将opencv读取的numpy对象，PIL读入的Image对象转成tensor对象。</p><h2 id="2-normalize"><a href="#2-normalize" class="headerlink" title="2.normalize"></a>2.normalize</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># normalize</span></span><br><span class="line">tran_norm = transforms.Normalize([<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>],[<span class="number">0.5</span>,<span class="number">0.5</span>,<span class="number">0.5</span>])</span><br><span class="line">image_norm = tran_norm(image_tensor)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(image)</span><br><span class="line"><span class="built_in">print</span>(image_norm)</span><br></pre></td></tr></table></figure><p>标准化为了使数据具有相似的尺度和分布，以便更好地进行模型训练。通过规范化，可以减少数据之间的差异，提高模型的收敛速度和稳定性。</p><h2 id="3-compose"><a href="#3-compose" class="headerlink" title="3.compose"></a>3.compose</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#compose</span></span><br><span class="line"></span><br><span class="line">tran_com = transforms.Compose(</span><br><span class="line">    [tran_tensor,</span><br><span class="line">     tran_norm]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">image_compose = tran_com(image)</span><br><span class="line"><span class="built_in">print</span>(image)</span><br><span class="line"><span class="built_in">print</span>(image_compose)</span><br></pre></td></tr></table></figure><p>将不同的transform模块拼接起来，主要不同模块输入与输出，可以用ctrl+点击该函数进入，查看函数的输入输出类型。</p><h2 id="4-randomcrop"><a href="#4-randomcrop" class="headerlink" title="4.randomcrop"></a>4.randomcrop</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># randomcrop</span></span><br><span class="line"></span><br><span class="line">tran_crop = transforms.RandomCrop(<span class="number">512</span>)</span><br><span class="line">write = SummaryWriter(<span class="string">&quot;log_1&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    image_crop = tran_crop(image_tensor)</span><br><span class="line">    write.add_image(<span class="string">&quot;change&quot;</span>, image_crop, i)</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensorboard --logdir=logs --port=6007</span></span><br><span class="line">write.close()</span><br></pre></td></tr></table></figure><p>随机剪裁图片，可以用tensorboard查看<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688283109877-7f6ce614-d4ab-4b94-b82a-84dfb86dd03a.png#averageHue=%23a8afa7&clientId=u020b4e0d-5170-4&from=paste&height=357&id=ue2d29a7d&originHeight=544&originWidth=650&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=107761&status=done&style=none&taskId=u45532af1-86b5-4e24-b8b7-b772268e054&title=&width=426.6666666666667" alt="image.png"></p><h2 id="resize"><a href="#resize" class="headerlink" title="resize"></a>resize</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># resize</span></span><br><span class="line">tran_resize = transforms.Resize((<span class="number">512</span>,<span class="number">512</span>))</span><br><span class="line">image_resize = tran_resize(image_tensor)</span><br><span class="line"><span class="built_in">print</span>(image_tensor.shape)</span><br><span class="line"><span class="built_in">print</span>(image_resize.shape)</span><br><span class="line"><span class="comment"># return</span></span><br><span class="line"><span class="comment"># torch.Size([3, 512, 768])</span></span><br><span class="line"><span class="comment"># torch.Size([3, 512, 512])</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>6.nn.module</title>
      <link href="/2023/08/20/6-nn-module/"/>
      <url>/2023/08/20/6-nn-module/</url>
      
        <content type="html"><![CDATA[<h2 id="example"><a href="#example" class="headerlink" title="example"></a>example</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Model</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        <span class="keyword">return</span> F.relu(self.conv2(x))</span><br></pre></td></tr></table></figure><h2 id="最简单的神经网络"><a href="#最简单的神经网络" class="headerlink" title="最简单的神经网络"></a>最简单的神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：nn.module.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/2 16:19 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Module</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="comment"># self.conv1 = nn.Conv2d(1, 20, 5)</span></span><br><span class="line">        <span class="comment"># self.conv2 = nn.Conv2d(20, 20, 5)</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># x = F.relu(self.conv1(x))</span></span><br><span class="line">        <span class="keyword">return</span> x+<span class="number">1</span></span><br><span class="line"></span><br><span class="line">x = torch.tensor(<span class="number">1</span>) <span class="comment">#创建一个tensor1</span></span><br><span class="line"></span><br><span class="line">model = MyModule() <span class="comment"># 实例化模型</span></span><br><span class="line"></span><br><span class="line">output = model(x) <span class="comment"># callback</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="comment"># print(modle.forward(x))</span></span><br></pre></td></tr></table></figure><h2 id="神经网络实战"><a href="#神经网络实战" class="headerlink" title="神经网络实战"></a>神经网络实战</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：nn.module.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/2 16:19 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Module</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">20</span>, <span class="number">20</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = F.relu(self.conv1(x))</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">image_path = <span class="string">&quot;test.jpg&quot;</span></span><br><span class="line">image = Image.<span class="built_in">open</span>(image_path).convert(<span class="string">&quot;L&quot;</span>)</span><br><span class="line">tran_tensor = transforms.ToTensor()</span><br><span class="line">image_tensor = tran_tensor(image)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">image_tensor = image_tensor.unsqueeze(<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(image_tensor.shape)</span><br><span class="line">model = MyModule() <span class="comment"># 实例化模型</span></span><br><span class="line"></span><br><span class="line">output = model(image_tensor) <span class="comment"># callback</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="comment"># print(modle.forward(x))</span></span><br></pre></td></tr></table></figure><ul><li>unsqueeze(0)可以添加维度，其中0为维度的索引</li><li>也可以用一个torch.reshape(-1,3,28,28）去改变大小，-1表示让他自己计算。</li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>7.神经网络</title>
      <link href="/2023/08/20/7-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/2023/08/20/7-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<h1 id="Conv2d"><a href="#Conv2d" class="headerlink" title="Conv2d"></a>Conv2d</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=<span class="number">1</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, groups=<span class="number">1</span>, bias=<span class="literal">True</span>, padding_mode=<span class="string">&#x27;zeros&#x27;</span>, device=<span class="literal">None</span>, dtype=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>in_channels (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong>) – Number of channels in the input image</strong></li><li><strong>out_channels (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong>) – Number of channels produced by the convolution</strong></li><li><strong>kernel_size (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong>_ <strong>or</strong> _</strong><a href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a><strong>) – Size of the convolving kernel</strong></li><li><strong>stride (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong>_ or _</strong><a href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a><strong><em>, optional</em>) – Stride of the convolution. Default: 1  # 步长</strong></li><li><strong>padding (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong><em>,</em>_ _</strong><a href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a><strong>_ <strong>or</strong> _</strong><a href="https://docs.python.org/3/library/stdtypes.html#str">str</a><strong><em>,</em>_ _<em>optional</em>) – Padding added to all four sides of the input. Default: 0</strong></li><li><strong>padding_mode (</strong><a href="https://docs.python.org/3/library/stdtypes.html#str">str</a><strong><em>,</em>_ _<em>optional</em>) – ‘zeros’, ‘reflect’, ‘replicate’ or ‘circular’. Default: ‘zeros’</strong></li><li><strong>dilation (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong>_ or _</strong><a href="https://docs.python.org/3/library/stdtypes.html#tuple">tuple</a><strong><em>, optional</em>) – Spacing between kernel elements. Default: 1  #空洞卷积</strong></li><li><strong>groups (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong><em>,</em>_ _<em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</strong></li><li><strong>bias (</strong><a href="https://docs.python.org/3/library/functions.html#bool">bool</a><strong><em>, optional</em>) – If True, adds a learnable bias to the output. Default: True</strong></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688370102231-751b436d-1ff1-471a-a1f9-69df3d39a7c1.png#averageHue=%23cba376&clientId=uef395455-85f2-4&from=paste&height=521&id=u5a593d4d&originHeight=794&originWidth=1160&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=264007&status=done&style=none&taskId=u4d7f5d65-9457-4e69-8b63-7ef77881626&title=&width=761.4358974358975" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688370118339-755113e6-94a1-4adb-9407-bac8d1cd6ca9.png#averageHue=%23caa376&clientId=uef395455-85f2-4&from=paste&height=569&id=u8094dfe3&originHeight=867&originWidth=1472&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=294785&status=done&style=none&taskId=ucba69f46-9787-4c43-8f4a-8ff495af4f0&title=&width=966.2358974358974" alt="image.png"><br>in_channels与out_channels计算公式<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689582545743-cd304c8e-6652-4732-a27e-65b214cc8af8.png#averageHue=%23fbf8f6&clientId=u11cf2d30-1909-4&from=paste&height=225&id=u430da774&originHeight=315&originWidth=892&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=36862&status=done&style=none&taskId=ua0a945da-caa1-4ce2-9369-0884305c7e2&title=&width=636.4325746068905" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689582611945-460abe4a-31b4-49b8-a8a9-0ccc9d005414.png#averageHue=%23fcfbfa&clientId=u11cf2d30-1909-4&from=paste&height=273&id=u5ed00617&originHeight=382&originWidth=805&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=29644&status=done&style=none&taskId=u494ea59a-3050-4778-b363-79734eec140&title=&width=574.3589938997162" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：conv2d_and_pool.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/3 16:20 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Module</span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">dataset = datasets.CIFAR10(<span class="string">&quot;CIFAR10&quot;</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset=dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyCNN</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyCNN, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>,<span class="number">6</span>,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">CNN = MyCNN()</span><br><span class="line">write = SummaryWriter(<span class="string">&quot;log_3&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">    img,label = data</span><br><span class="line">    write.add_images(<span class="string">&quot;input&quot;</span>,img,i)</span><br><span class="line">    <span class="built_in">print</span>(img.shape)</span><br><span class="line"></span><br><span class="line">    output = CNN(img)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    output = torch.reshape(output,(-<span class="number">1</span>,<span class="number">3</span>,<span class="number">30</span>,<span class="number">30</span>))</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    write.add_images(<span class="string">&quot;output&quot;</span>,output,i)</span><br><span class="line"></span><br><span class="line">write.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688373712056-3ecb9249-6a87-4be6-bb0e-f1a1516c9e15.png#averageHue=%233cab3e&clientId=uef395455-85f2-4&from=paste&height=668&id=u35542230&originHeight=1017&originWidth=841&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=288571&status=done&style=none&taskId=u950c363c-b18b-4c28-97e0-b9efa1d52bc&title=&width=552.0410256410256" alt="image.png"></p><h1 id="MAXPOOL2D"><a href="#MAXPOOL2D" class="headerlink" title="MAXPOOL2D"></a>MAXPOOL2D</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MaxPool2d(kernel_size, stride=<span class="literal">None</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, return_indices=<span class="literal">False</span>, ceil_mode=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>kernel_size (</strong><a href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a><strong>_[_**<a href="https://docs.python.org/3/library/functions.html#int">int</a></strong><em>,</em>_ <em><strong><a href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></strong></em>[<em><strong><a href="https://docs.python.org/3/library/functions.html#int">int</a></strong></em>,__ <em><strong><a href="https://docs.python.org/3/library/functions.html#int">int</a></strong></em>]_<em>]</em>) – the size of the window to take a max over**</li><li><strong>stride (</strong><a href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a><strong>_[_**<a href="https://docs.python.org/3/library/functions.html#int">int</a></strong><em>, <em><strong><a href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></strong></em>[_<strong><a href="https://docs.python.org/3/library/functions.html#int">int</a></strong></em>, <em><strong><a href="https://docs.python.org/3/library/functions.html#int">int</a></strong></em>]]_) – the stride of the window. Default value is kernel_size # 默认是kernel_size大小**</li><li><strong>padding (</strong><a href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a><strong>_[_**<a href="https://docs.python.org/3/library/functions.html#int">int</a></strong><em>,</em>_ <em><strong><a href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></strong></em>[<em><strong><a href="https://docs.python.org/3/library/functions.html#int">int</a></strong></em>,__ <em><strong><a href="https://docs.python.org/3/library/functions.html#int">int</a></strong></em>]_<em>]</em>) – Implicit negative infinity padding to be added on both sides**</li><li><strong>dilation (</strong><a href="https://docs.python.org/3/library/typing.html#typing.Union">Union</a><strong>_[_**<a href="https://docs.python.org/3/library/functions.html#int">int</a></strong><em>,</em>_ <em><strong><a href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a></strong></em>[<em><strong><a href="https://docs.python.org/3/library/functions.html#int">int</a></strong></em>,__ <em><strong><a href="https://docs.python.org/3/library/functions.html#int">int</a></strong></em>]_<em>]</em>) – a parameter that controls the stride of elements in the window**</li><li><strong>return_indices (</strong><a href="https://docs.python.org/3/library/functions.html#bool">bool</a><strong>) – if True, will return the max indices along with the outputs. Useful for <strong><a href="https://pytorch.org/docs/stable/generated/torch.nn.MaxUnpool2d.html#torch.nn.MaxUnpool2d">torch.nn.MaxUnpool2d</a></strong> later</strong></li><li><strong>ceil_mode (</strong><a href="https://docs.python.org/3/library/functions.html#bool">bool</a><strong>) – when True, will use ceil instead of floor to compute the output shape＃有点去1法和进1法的意思</strong></li></ul><p><strong>作用：保持特征，减少参数</strong><br>in_channel与out_channel计算关系<br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688372309747-e09186c9-7e88-4245-a6bc-b31e6d64ab7d.png#averageHue=%23f3f2f1&clientId=uef395455-85f2-4&from=paste&height=312&id=ub34289c5&originHeight=476&originWidth=1048&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=57210&status=done&style=none&taskId=uf4eb2c0e-c606-430c-b5fc-38f9bc6d498&title=&width=687.9179487179487" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：conv2d_and_pool.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/3 16:20 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Module</span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">dataset = datasets.CIFAR10(<span class="string">&quot;CIFAR10&quot;</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset=dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyCNN</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyCNN, self).__init__()</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>,<span class="number">6</span>,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">        self.pool2d = nn.MaxPool2d(<span class="number">3</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = self.pool2d(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">CNN = MyCNN()</span><br><span class="line">write = SummaryWriter(<span class="string">&quot;log_3&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">    img,label = data</span><br><span class="line">    write.add_images(<span class="string">&quot;input&quot;</span>,img,i)</span><br><span class="line">    <span class="built_in">print</span>(img.shape)</span><br><span class="line"></span><br><span class="line">    output = CNN(img)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    output = torch.reshape(output,(-<span class="number">1</span>,<span class="number">3</span>,<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line">    write.add_images(<span class="string">&quot;output&quot;</span>,output,i)</span><br><span class="line"></span><br><span class="line">write.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688374183400-3dc782c6-4310-4d76-af49-969ab5849600.png#averageHue=%2344a442&clientId=uef395455-85f2-4&from=paste&height=661&id=u3715ebc3&originHeight=1007&originWidth=858&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=280111&status=done&style=none&taskId=u295be576-c1b7-4ad6-9b36-3446e8fe8c3&title=&width=563.2" alt="image.png"><br>自定义tensor，记得加上dtype&#x3D;torch.float32</p><h1 id="非线性激活函数"><a href="#非线性激活函数" class="headerlink" title="非线性激活函数"></a>非线性激活函数</h1><h2 id="RELU"><a href="#RELU" class="headerlink" title="RELU"></a>RELU</h2><h2 id=""><a href="#" class="headerlink" title=""></a><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688376252467-059920b4-d4f3-49bf-9a24-d83a8b3868e4.png#averageHue=%23fcfbfb&clientId=u0b238e3c-98d4-4&from=paste&height=727&id=u16ed43cf&originHeight=1108&originWidth=1099&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=112620&status=done&style=none&taskId=u77480dd1-23cd-43bd-a1fc-9df0bfb8fe8&title=&width=721.3948717948718" alt="image.png"></h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：RELU.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/3 17:24 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> ReLU, Module</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModule, self).__init__()</span><br><span class="line">        self.relu = ReLU(inplace=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.relu(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tensor = torch.tensor([[<span class="number">1</span>,-<span class="number">1</span>],[<span class="number">0.5</span>,-<span class="number">0.5</span>]])</span><br><span class="line">model = MyModule()</span><br><span class="line">output = model(tensor)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[1.0000, 0.0000],</span></span><br><span class="line"><span class="string">        [0.5000, 0.0000]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="sigmoid"><a href="#sigmoid" class="headerlink" title="sigmoid"></a>sigmoid</h2><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688376628068-b4d147cc-ce56-4d3c-9aa3-f77fd7af2846.png#averageHue=%23fcfbfb&clientId=u0b238e3c-98d4-4&from=paste&height=716&id=uf4b152bf&originHeight=1091&originWidth=1126&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=107994&status=done&style=none&taskId=u8da3603f-22a7-4ce4-a009-951a0f9603b&title=&width=739.1179487179487" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：Sigomid.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/3 17:30 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sigmoid, Module</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModule, self).__init__()</span><br><span class="line">        self.sigmoid = Sigmoid()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.sigmoid(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tensor = torch.tensor([[<span class="number">1</span>,-<span class="number">1</span>],[<span class="number">0.5</span>,-<span class="number">0.5</span>]])</span><br><span class="line">model = MyModule()</span><br><span class="line">output = model(tensor)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">output:</span></span><br><span class="line"><span class="string">tensor([[0.7311, 0.2689],</span></span><br><span class="line"><span class="string">        [0.6225, 0.3775]])</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><p>增强非线性变化，加强对特征的提取，减少过拟合，加强模型泛化能力。</p><h1 id="线性层"><a href="#线性层" class="headerlink" title="线性层"></a>线性层</h1><p>**<strong>torch.nn.Linear</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.Linear(in_features, out_features, bias=<span class="literal">True</span>, device=<span class="literal">None</span>, dtype=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688613798998-4c95b1be-1d1e-409b-8f7f-27b567bcf150.png#averageHue=%23faf8f7&clientId=u55e43857-1530-4&from=paste&height=104&id=u9ab4c1d9&originHeight=158&originWidth=884&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=22873&status=done&style=none&taskId=u7286b357-961d-4b3f-82c2-77622ba9092&title=&width=580.2666666666667" alt="image.png"></p><ul><li><strong>in_features (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong>) – size of each input sample</strong></li><li><strong>out_features (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong>) – size of each output sample</strong></li><li><strong>bias (</strong><a href="https://docs.python.org/3/library/functions.html#bool">bool</a><strong>) – If set to False, the layer will not learn an additive bias. Default: True</strong></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>8.Sequential与模型搭建实战</title>
      <link href="/2023/08/20/8-Sequential%E4%B8%8E%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%AE%9E%E6%88%98/"/>
      <url>/2023/08/20/8-Sequential%E4%B8%8E%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%AE%9E%E6%88%98/</url>
      
        <content type="html"><![CDATA[<p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688455452445-c4c58f14-2ba0-40d6-baab-b9302298d7d0.png#averageHue=%23dedede&clientId=u7ca3f253-01fa-4&from=paste&id=ucf2ca8fd&originHeight=375&originWidth=1343&originalType=url&ratio=1.5234375&rotation=0&showTitle=false&size=224151&status=done&style=none&taskId=u637e814d-f143-4ea2-b354-f2b6f0059ff&title=" alt="image.png"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：Sequential与模型搭建实战.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/4 15:25 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader,Dataset</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Module,Conv2d,MaxPool2d,Sequential,Flatten,Linear</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;CIFAR10&quot;</span>,train=<span class="literal">True</span>,transform=transforms.ToTensor(),download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset=dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">普通定义</span></span><br><span class="line"><span class="string">class MyModule(Module):</span></span><br><span class="line"><span class="string">    def __init__(self):</span></span><br><span class="line"><span class="string">        super(MyModule, self).__init__()</span></span><br><span class="line"><span class="string">        self.conv1 = Conv2d(3,32,5,padding=2)</span></span><br><span class="line"><span class="string">        self.maxpool1 =  MaxPool2d(2)</span></span><br><span class="line"><span class="string">        self.conv2 = Conv2d(32,32,5,padding=2)</span></span><br><span class="line"><span class="string">        self.maxpool2 = MaxPool2d(2)</span></span><br><span class="line"><span class="string">        self.conv3 = Conv2d(32,64,5,padding=2)</span></span><br><span class="line"><span class="string">        self.maxpool3 = MaxPool2d(2)</span></span><br><span class="line"><span class="string">        self.flatten = Flatten()</span></span><br><span class="line"><span class="string">        self.Linear1 = Linear(1024,64)</span></span><br><span class="line"><span class="string">        self.Linear2 = Linear(64,10)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    def forward(self,x):</span></span><br><span class="line"><span class="string">        x = self.conv1(x)</span></span><br><span class="line"><span class="string">        x = self.maxpool1(x)</span></span><br><span class="line"><span class="string">        x = self.conv2(x)</span></span><br><span class="line"><span class="string">        x = self.maxpool2(x)</span></span><br><span class="line"><span class="string">        x = self.conv3(x)</span></span><br><span class="line"><span class="string">        x = self.maxpool3(x)</span></span><br><span class="line"><span class="string">        x = self.flatten(x)</span></span><br><span class="line"><span class="string">        x = self.Linear1(x)</span></span><br><span class="line"><span class="string">        x = self.Linear2(x)</span></span><br><span class="line"><span class="string">        return x</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Sequential定义</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModule, self).__init__()</span><br><span class="line">        self.model = Sequential(</span><br><span class="line">        Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Flatten(),</span><br><span class="line">        Linear(<span class="number">1024</span>,<span class="number">64</span>),</span><br><span class="line">        Linear(<span class="number">64</span>,<span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = MyModule()</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">write = SummaryWriter(<span class="string">&quot;log_4&quot;</span>)</span><br><span class="line"><span class="comment"># write.add_graph(model)</span></span><br><span class="line"><span class="comment"># input = torch.ones((64,3,32,32))</span></span><br><span class="line"><span class="comment"># write.add_graph(model,input)</span></span><br><span class="line"><span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">    image,label = data</span><br><span class="line">    <span class="built_in">print</span>(image.shape)</span><br><span class="line">    write.add_graph(model,image)</span><br><span class="line">    output = model(image)</span><br><span class="line">    <span class="built_in">print</span>(output.shape)</span><br><span class="line"></span><br><span class="line">write.close()</span><br><span class="line"><span class="comment"># MyModule(</span></span><br><span class="line"><span class="comment">#   (model): Sequential(</span></span><br><span class="line"><span class="comment">#     (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span></span><br><span class="line"><span class="comment">#     (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="comment">#     (2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span></span><br><span class="line"><span class="comment">#     (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="comment">#     (4): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))</span></span><br><span class="line"><span class="comment">#     (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)</span></span><br><span class="line"><span class="comment">#     (6): Flatten(start_dim=1, end_dim=-1)</span></span><br><span class="line"><span class="comment">#     (7): Linear(in_features=1024, out_features=64, bias=True)</span></span><br><span class="line"><span class="comment">#     (8): Linear(in_features=64, out_features=10, bias=True)</span></span><br><span class="line"><span class="comment">#   )</span></span><br><span class="line"><span class="comment"># )</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688458476306-1fc29a1a-702f-4dbe-8dce-f55c9c5b1986.png#averageHue=%23f0eeee&clientId=u7ca3f253-01fa-4&from=paste&height=2141&id=u87116f92&originHeight=3262&originWidth=1950&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=321165&status=done&style=none&taskId=u6e34323b-12b4-4075-87ce-18f563ff5ac&title=&width=1280" alt="png.png"></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>9.损失函数负反馈与优化器</title>
      <link href="/2023/08/20/9-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%B4%9F%E5%8F%8D%E9%A6%88%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8/"/>
      <url>/2023/08/20/9-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%B4%9F%E5%8F%8D%E9%A6%88%E4%B8%8E%E4%BC%98%E5%8C%96%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h1><ul><li>计算实际输出与目标之间的差距</li><li>为我们更新输出提供一定的依据（反向传播）</li></ul><h2 id="CROSSENTROPYLOSS（交叉熵）"><a href="#CROSSENTROPYLOSS（交叉熵）" class="headerlink" title="CROSSENTROPYLOSS（交叉熵）"></a>CROSSENTROPYLOSS（交叉熵）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLASStorch.nn.CrossEntropyLoss(weight=<span class="literal">None</span>, size_average=<span class="literal">None</span>, ignore_index=- <span class="number">100</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>, label_smoothing=<span class="number">0.0</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>weight (</strong><a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a><strong><em>,</em>_ _<em>optional</em>) – a manual rescaling weight given to each class. If given, has to be a Tensor of size C</strong></li><li><strong>size_average (</strong><a href="https://docs.python.org/3/library/functions.html#bool">bool</a><strong><em>,</em>_ _<em>optional</em>) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True</strong></li><li><strong>ignore_index (</strong><a href="https://docs.python.org/3/library/functions.html#int">int</a><strong><em>,</em>_ _<em>optional</em>) – Specifies a target value that is ignored and does not contribute to the input gradient. When size_average is True, the loss is averaged over non-ignored targets. Note that ignore_index is only applicable when the target contains class indices.</strong></li><li><strong>reduce (</strong><a href="https://docs.python.org/3/library/functions.html#bool">bool</a><strong><em>,</em>_ _<em>optional</em>) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True</strong></li><li><strong>reduction (</strong><a href="https://docs.python.org/3/library/stdtypes.html#str">str</a><strong><em>,</em>_ _<em>optional</em>) – Specifies the reduction to apply to the output: ‘none’ | ‘mean’ | ‘sum’. ‘none’: no reduction will be applied, ‘mean’: the weighted mean of the output is taken, ‘sum’: the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: ‘mean’</strong></li><li><strong>label_smoothing (</strong><a href="https://docs.python.org/3/library/functions.html#float">float</a><strong><em>, optional</em>) – A float in [0.0, 1.0]. Specifies the amount of smoothing when computing the loss, where 0.0 means no smoothing. The targets become a mixture of the original ground truth and a uniform distribution as described in <strong><a href="https://arxiv.org/abs/1512.00567">Rethinking the Inception Architecture for Computer Vision</a></strong>. Default: 0.00.0.</strong></li></ul><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689211175565-2d46a1a1-9b95-4d91-b78b-b5cc7ad1444b.png#averageHue=%23f9f9f9&clientId=u803ecfee-1f5f-4&from=paste&height=495&id=ufb7edac8&originHeight=694&originWidth=1283&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=260176&status=done&style=none&taskId=u23e1dd0d-1c6e-4d86-8d24-ca9c26144d2&title=&width=915.406943072467" alt="image.png"><br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689212929398-69aba419-49a3-4809-b44b-8cd5c95088e7.png#averageHue=%23faf8f6&clientId=u803ecfee-1f5f-4&from=paste&height=316&id=u91ab8bbd&originHeight=443&originWidth=911&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=58091&status=done&style=none&taskId=u073183ea-0872-46d6-a81a-112f00869e5&title=&width=649.9888738417907" alt="image.png"></p><h1 id="MSELOSS（平方差）"><a href="#MSELOSS（平方差）" class="headerlink" title="MSELOSS（平方差）"></a>MSELOSS（平方差）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.MSELoss(size_average=<span class="literal">None</span>, reduce=<span class="literal">None</span>, reduction=<span class="string">&#x27;mean&#x27;</span>)</span><br></pre></td></tr></table></figure><ul><li><strong>size_average (</strong><a href="https://docs.python.org/3/library/functions.html#bool">bool</a><strong><em>,</em>_ _<em>optional</em>) – Deprecated (see reduction). By default, the losses are averaged over each loss element in the batch. Note that for some losses, there are multiple elements per sample. If the field size_average is set to False, the losses are instead summed for each minibatch. Ignored when reduce is False. Default: True</strong></li><li><strong>reduce (</strong><a href="https://docs.python.org/3/library/functions.html#bool">bool</a><strong><em>,</em>_ _<em>optional</em>) – Deprecated (see reduction). By default, the losses are averaged or summed over observations for each minibatch depending on size_average. When reduce is False, returns a loss per batch element instead and ignores size_average. Default: True</strong></li><li><strong>reduction (</strong><a href="https://docs.python.org/3/library/stdtypes.html#str">str</a><strong><em>, optional</em>) – Specifies the reduction to apply to the output: ‘none’ | ‘mean’ | ‘sum’. ‘none’: no reduction will be applied, ‘mean’: the sum of the output will be divided by the number of elements in the output, ‘sum’: the output will be summed. Note: size_average and reduce are in the process of being deprecated, and in the meantime, specifying either of those two args will override reduction. Default: ‘mean’</strong><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：loss.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/5 18:33 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> L1Loss,MSELoss,CrossEntropyLoss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">input</span> = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line">target = torch.Tensor([<span class="number">1</span>,<span class="number">2</span>,<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># L1loss</span></span><br><span class="line">loss = L1Loss() <span class="comment"># reduction=&quot;sum&quot;</span></span><br><span class="line">output = loss(<span class="built_in">input</span>,target)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># MSELoss 平方差损失</span></span><br><span class="line">loss_msl = MSELoss(reduction=<span class="string">&quot;sum&quot;</span>)</span><br><span class="line">output = loss_msl(<span class="built_in">input</span>,target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># CROSSENTROPYLOSS</span></span><br><span class="line">crossentropyloss = CrossEntropyLoss()</span><br><span class="line">output = CrossEntropyLoss(<span class="built_in">input</span>,target)</span><br><span class="line"><span class="built_in">print</span>(output)</span><br></pre></td></tr></table></figure></li></ul><h1 id="负反馈"><a href="#负反馈" class="headerlink" title="负反馈"></a>负反馈</h1><p>主要是计算梯度，然后方便下面的优化器进行下一步的更新。<br>loss.backward()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：loss_backward.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 9:29 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential, Conv2d, MaxPool2d, Linear, Flatten, Module</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;CIFAR10&quot;</span>,train=<span class="literal">True</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset=dataset,batch_size=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">loss = torch.nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 定义网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModule, self).__init__()</span><br><span class="line">        self.model = Sequential(</span><br><span class="line">        Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Flatten(),</span><br><span class="line">        Linear(<span class="number">1024</span>,<span class="number">64</span>),</span><br><span class="line">        Linear(<span class="number">64</span>,<span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = MyModule()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">    img,label = data</span><br><span class="line">    result = model(img)</span><br><span class="line">    result = result.reshape((<span class="number">1</span>,<span class="number">10</span>))</span><br><span class="line">    <span class="comment"># 打印result和label看信息</span></span><br><span class="line">    <span class="comment"># print(result)</span></span><br><span class="line">    <span class="comment"># print(label)</span></span><br><span class="line">    <span class="comment"># tensor([[ 0.0937,  0.0191,  0.0275, -0.0915, -0.0129,  0.1434,  0.1817,  0.0104,</span></span><br><span class="line">    <span class="comment">#          -0.0251, -0.0779]], grad_fn=&lt;AddmmBackward0&gt;)</span></span><br><span class="line">    <span class="comment"># tensor([2])</span></span><br><span class="line">    loss_result = loss(result,label)</span><br><span class="line">    <span class="comment"># print(&quot;loss_result:&quot;,loss_result)</span></span><br><span class="line">    loss_result.backward()</span><br><span class="line">    <span class="comment"># print(&quot;loss_result_1:&quot;,loss_result)</span></span><br><span class="line">    <span class="comment"># loss_result: tensor(2.1570, grad_fn= &lt; NllLossBackward0 &gt;)</span></span><br><span class="line">    <span class="comment"># loss_result_1: tensor(2.1570, grad_fn= &lt; NllLossBackward0 &gt;)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h1><p>有多种优化器，其实本质就是一种参数更新的算法。<br>主要就是三步</p><ul><li>optim.zero_grad()  # 梯度全部变成0</li><li>loss_result.backward()</li><li>optim.step()<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：optim.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/13 10:20 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> Sequential, Conv2d, MaxPool2d, Linear, Flatten, Module</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line">dataset = torchvision.datasets.CIFAR10(<span class="string">&quot;CIFAR10&quot;</span>,train=<span class="literal">False</span>,transform=torchvision.transforms.ToTensor(),</span><br><span class="line">                                       download=<span class="literal">True</span>)</span><br><span class="line">dataloader = DataLoader(dataset=dataset,batch_size=<span class="number">64</span>)</span><br><span class="line"><span class="comment"># 定义网络</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(<span class="title class_ inherited__">Module</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModule, self).__init__()</span><br><span class="line">        self.model = Sequential(</span><br><span class="line">        Conv2d(<span class="number">3</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Conv2d(<span class="number">32</span>,<span class="number">32</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Conv2d(<span class="number">32</span>,<span class="number">64</span>,<span class="number">5</span>,padding=<span class="number">2</span>),</span><br><span class="line">        MaxPool2d(<span class="number">2</span>),</span><br><span class="line">        Flatten(),</span><br><span class="line">        Linear(<span class="number">1024</span>,<span class="number">64</span>),</span><br><span class="line">        Linear(<span class="number">64</span>,<span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        x = self.model(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">model = MyModule()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数</span></span><br><span class="line">loss = torch.nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 定义参数更新方式</span></span><br><span class="line">optim = torch.optim.SGD(model.parameters(),lr=<span class="number">0.01</span>)</span><br><span class="line">write = SummaryWriter(<span class="string">&quot;log_5&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    run_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">        img,label = data</span><br><span class="line">        result = model(img)</span><br><span class="line">        <span class="comment"># result = result.reshape((64,10))</span></span><br><span class="line">        loss_result = loss(result,label)</span><br><span class="line">        optim.zero_grad()  <span class="comment"># 梯度全部变成0</span></span><br><span class="line">        loss_result.backward()</span><br><span class="line">        optim.step()</span><br><span class="line">        run_loss += loss_result</span><br><span class="line">    <span class="built_in">print</span>(run_loss)</span><br><span class="line">    write.add_scalar(<span class="string">&quot;loss change&quot;</span>,run_loss,epoch)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;OK!&quot;</span>)</span><br><span class="line">write.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>用的tensorboard可视化损失：<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Files already downloaded <span class="keyword">and</span> verified</span><br><span class="line">tensor(<span class="number">359.8933</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(<span class="number">353.3619</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(<span class="number">329.9563</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(<span class="number">313.8071</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(<span class="number">304.5399</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(<span class="number">295.0195</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(<span class="number">287.4640</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(<span class="number">280.7477</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(<span class="number">274.6153</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">tensor(<span class="number">269.1077</span>, grad_fn=&lt;AddBackward0&gt;)</span><br><span class="line">OK!</span><br></pre></td></tr></table></figure><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1689222880746-68213229-3a15-48d7-80ad-8380fa1df62f.png#averageHue=%23fbfbfb&clientId=u803ecfee-1f5f-4&from=paste&height=340&id=u56a7375a&originHeight=477&originWidth=578&originalType=binary&ratio=1.4015624523162842&rotation=0&showTitle=false&size=25488&status=done&style=none&taskId=u5948ff94-8f7e-4d40-ac56-5e2caf4cdec&title=&width=412.39689251433043" alt="image.png"></li></ul>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>3.dataset与datalodar</title>
      <link href="/2023/08/20/3-dataset%E4%B8%8Edatalodar/"/>
      <url>/2023/08/20/3-dataset%E4%B8%8Edatalodar/</url>
      
        <content type="html"><![CDATA[<h1 id="dataset"><a href="#dataset" class="headerlink" title="dataset"></a>dataset</h1><p>提供一种方式去获取数据及其label</p><ul><li><strong>如何获取每一个数据及其label</strong></li><li>告诉我们有多少数据</li></ul><h2 id="查看pytorch是否可以"><a href="#查看pytorch是否可以" class="headerlink" title="查看pytorch是否可以"></a>查看pytorch是否可以</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(torch.cuda.is_available()) <span class="comment"># 查看当前cuda是否可用</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">True</span><br></pre></td></tr></table></figure><h2 id="查看dataset"><a href="#查看dataset" class="headerlink" title="查看dataset"></a>查看dataset</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">help</span>(Dataset) <span class="comment"># 用帮助文档查看Dataset</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line">Help on class Dataset in module torch.utils.data.dataset:</span><br><span class="line"></span><br><span class="line">class Dataset(typing.Generic)</span><br><span class="line"> |  Dataset(*args, **kwds)</span><br><span class="line"> |  </span><br><span class="line"> |  An abstract class representing a :class:`Dataset`.</span><br><span class="line"> |  </span><br><span class="line"> |  All datasets that represent a map from keys to data samples should subclass</span><br><span class="line"> |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a</span><br><span class="line"> |  data sample for a given key. Subclasses could also optionally overwrite</span><br><span class="line"> |  :meth:`__len__`, which is expected to return the size of the dataset by many</span><br><span class="line"> |  :class:`~torch.utils.data.Sampler` implementations and the default options</span><br><span class="line"> |  of :class:`~torch.utils.data.DataLoader`.</span><br><span class="line"> |  </span><br><span class="line"> |  .. note::</span><br><span class="line"> |    :class:`~torch.utils.data.DataLoader` by default constructs a index</span><br><span class="line"> |    sampler that yields integral indices.  To make it work with a map-style</span><br><span class="line"> |    dataset with non-integral indices/keys, a custom sampler must be provided.</span><br><span class="line"> |  </span><br><span class="line"> |  Method resolution order:</span><br><span class="line"> |      Dataset</span><br><span class="line"> |      typing.Generic</span><br><span class="line"> |      builtins.object</span><br><span class="line"> |  </span><br><span class="line"> |  Methods defined here:</span><br><span class="line"> |  </span><br><span class="line"> |  __add__(self, other: &#x27;Dataset[T_co]&#x27;) -&gt; &#x27;ConcatDataset[T_co]&#x27;</span><br><span class="line"> |  </span><br><span class="line"> |  __getattr__(self, attribute_name)</span><br><span class="line"> |  </span><br><span class="line"> |  __getitem__(self, index) -&gt; +T_co</span><br><span class="line"> |  </span><br><span class="line"> |  ----------------------------------------------------------------------</span><br><span class="line"> |  Class methods defined here:</span><br><span class="line"> |  </span><br><span class="line"> |  register_datapipe_as_function(function_name, cls_to_register, enable_df_api_tracing=False) from builtins.type</span><br><span class="line"> |  </span><br><span class="line"> |  register_function(function_name, function) from builtins.type</span><br><span class="line"> |  </span><br><span class="line"> |  ----------------------------------------------------------------------</span><br><span class="line"> |  Data descriptors defined here:</span><br><span class="line"> |  </span><br><span class="line"> |  __dict__</span><br><span class="line"> |      dictionary for instance variables (if defined)</span><br><span class="line"> |  </span><br><span class="line"> |  __weakref__</span><br><span class="line"> |      list of weak references to the object (if defined)</span><br><span class="line"> |  </span><br><span class="line"> |  ----------------------------------------------------------------------</span><br><span class="line"> |  Data and other attributes defined here:</span><br><span class="line"> |  </span><br><span class="line"> |  __annotations__ = &#123;&#x27;functions&#x27;: typing.Dict[str, typing.Callable]&#125;</span><br><span class="line"> |  </span><br><span class="line"> |  __orig_bases__ = (typing.Generic[+T_co],)</span><br><span class="line"> |  </span><br><span class="line"> |  __parameters__ = (+T_co,)</span><br><span class="line"> |  </span><br><span class="line"> |  functions = &#123;&#x27;concat&#x27;: functools.partial(&lt;function Dataset.register_da...</span><br><span class="line"> |  </span><br><span class="line"> |  ----------------------------------------------------------------------</span><br><span class="line"> |  Class methods inherited from typing.Generic:</span><br><span class="line"> |  </span><br><span class="line"> |  __class_getitem__(params) from builtins.type</span><br><span class="line"> |  </span><br><span class="line"> |  __init_subclass__(*args, **kwargs) from builtins.type</span><br><span class="line"> |      This method is called when a class is subclassed.</span><br><span class="line"> |      </span><br><span class="line"> |      The default implementation does nothing. It may be</span><br><span class="line"> |      overridden to extend subclasses.</span><br><span class="line"> |  </span><br><span class="line"> |  ----------------------------------------------------------------------</span><br><span class="line"> |  Static methods inherited from typing.Generic:</span><br><span class="line"> |  </span><br><span class="line"> |  __new__(cls, *args, **kwds)</span><br><span class="line"> |      Create and return a new object.  See help(type) for accurate signature.</span><br></pre></td></tr></table></figure><h2 id="os操作读取文件夹下的对象"><a href="#os操作读取文件夹下的对象" class="headerlink" title="os操作读取文件夹下的对象"></a>os操作读取文件夹下的对象</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">dir_path = <span class="string">&quot;hymenoptera_data\\hymenoptera_data\\train\\ants&quot;</span>  <span class="comment"># 文件夹目录</span></span><br><span class="line">data_dir = os.listdir(dir_path)  <span class="comment"># 获取文件夹目录中的对象</span></span><br><span class="line">data_dir</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;0013035.jpg&#x27;,</span><br><span class="line"> &#x27;1030023514_aad5c608f9.jpg&#x27;,</span><br><span class="line"> &#x27;1095476100_3906d8afde.jpg&#x27;,</span><br><span class="line"> &#x27;1099452230_d1949d3250.jpg&#x27;,</span><br><span class="line"> &#x27;116570827_e9c126745d.jpg&#x27;,</span><br><span class="line"> &#x27;1225872729_6f0856588f.jpg&#x27;,</span><br><span class="line"> &#x27;1262877379_64fcada201.jpg&#x27;,</span><br><span class="line"> &#x27;1269756697_0bce92cdab.jpg&#x27;,</span><br><span class="line"> &#x27;1286984635_5119e80de1.jpg&#x27;,</span><br><span class="line"> &#x27;132478121_2a430adea2.jpg&#x27;,</span><br><span class="line"> &#x27;1360291657_dc248c5eea.jpg&#x27;,</span><br><span class="line"> &#x27;1368913450_e146e2fb6d.jpg&#x27;,</span><br><span class="line"> &#x27;1473187633_63ccaacea6.jpg&#x27;,</span><br><span class="line"> &#x27;148715752_302c84f5a4.jpg&#x27;,</span><br><span class="line"> &#x27;1489674356_09d48dde0a.jpg&#x27;,</span><br><span class="line"> &#x27;149244013_c529578289.jpg&#x27;,</span><br><span class="line"> &#x27;150801003_3390b73135.jpg&#x27;,</span><br><span class="line"> &#x27;150801171_cd86f17ed8.jpg&#x27;,</span><br><span class="line"> &#x27;154124431_65460430f2.jpg&#x27;,</span><br><span class="line"> &#x27;162603798_40b51f1654.jpg&#x27;,</span><br><span class="line"> &#x27;1660097129_384bf54490.jpg&#x27;,</span><br><span class="line"> &#x27;167890289_dd5ba923f3.jpg&#x27;,</span><br><span class="line"> &#x27;1693954099_46d4c20605.jpg&#x27;,</span><br><span class="line"> &#x27;175998972.jpg&#x27;,</span><br><span class="line"> &#x27;178538489_bec7649292.jpg&#x27;,</span><br><span class="line"> &#x27;1804095607_0341701e1c.jpg&#x27;,</span><br><span class="line"> &#x27;1808777855_2a895621d7.jpg&#x27;,</span><br><span class="line"> &#x27;188552436_605cc9b36b.jpg&#x27;,</span><br><span class="line"> &#x27;1917341202_d00a7f9af5.jpg&#x27;,</span><br><span class="line"> &#x27;1924473702_daa9aacdbe.jpg&#x27;,</span><br><span class="line"> &#x27;196057951_63bf063b92.jpg&#x27;,</span><br><span class="line"> &#x27;196757565_326437f5fe.jpg&#x27;,</span><br><span class="line"> &#x27;201558278_fe4caecc76.jpg&#x27;,</span><br><span class="line"> &#x27;201790779_527f4c0168.jpg&#x27;,</span><br><span class="line"> &#x27;2019439677_2db655d361.jpg&#x27;,</span><br><span class="line"> &#x27;207947948_3ab29d7207.jpg&#x27;,</span><br><span class="line"> &#x27;20935278_9190345f6b.jpg&#x27;,</span><br><span class="line"> &#x27;224655713_3956f7d39a.jpg&#x27;,</span><br><span class="line"> &#x27;2265824718_2c96f485da.jpg&#x27;,</span><br><span class="line"> &#x27;2265825502_fff99cfd2d.jpg&#x27;,</span><br><span class="line"> &#x27;226951206_d6bf946504.jpg&#x27;,</span><br><span class="line"> &#x27;2278278459_6b99605e50.jpg&#x27;,</span><br><span class="line"> &#x27;2288450226_a6e96e8fdf.jpg&#x27;,</span><br><span class="line"> &#x27;2288481644_83ff7e4572.jpg&#x27;,</span><br><span class="line"> &#x27;2292213964_ca51ce4bef.jpg&#x27;,</span><br><span class="line"> &#x27;24335309_c5ea483bb8.jpg&#x27;,</span><br><span class="line"> &#x27;245647475_9523dfd13e.jpg&#x27;,</span><br><span class="line"> &#x27;255434217_1b2b3fe0a4.jpg&#x27;,</span><br><span class="line"> &#x27;258217966_d9d90d18d3.jpg&#x27;,</span><br><span class="line"> &#x27;275429470_b2d7d9290b.jpg&#x27;,</span><br><span class="line"> &#x27;28847243_e79fe052cd.jpg&#x27;,</span><br><span class="line"> &#x27;318052216_84dff3f98a.jpg&#x27;,</span><br><span class="line"> &#x27;334167043_cbd1adaeb9.jpg&#x27;,</span><br><span class="line"> &#x27;339670531_94b75ae47a.jpg&#x27;,</span><br><span class="line"> &#x27;342438950_a3da61deab.jpg&#x27;,</span><br><span class="line"> &#x27;36439863_0bec9f554f.jpg&#x27;,</span><br><span class="line"> &#x27;374435068_7eee412ec4.jpg&#x27;,</span><br><span class="line"> &#x27;382971067_0bfd33afe0.jpg&#x27;,</span><br><span class="line"> &#x27;384191229_5779cf591b.jpg&#x27;,</span><br><span class="line"> &#x27;386190770_672743c9a7.jpg&#x27;,</span><br><span class="line"> &#x27;392382602_1b7bed32fa.jpg&#x27;,</span><br><span class="line"> &#x27;403746349_71384f5b58.jpg&#x27;,</span><br><span class="line"> &#x27;408393566_b5b694119b.jpg&#x27;,</span><br><span class="line"> &#x27;424119020_6d57481dab.jpg&#x27;,</span><br><span class="line"> &#x27;424873399_47658a91fb.jpg&#x27;,</span><br><span class="line"> &#x27;450057712_771b3bfc91.jpg&#x27;,</span><br><span class="line"> &#x27;45472593_bfd624f8dc.jpg&#x27;,</span><br><span class="line"> &#x27;459694881_ac657d3187.jpg&#x27;,</span><br><span class="line"> &#x27;460372577_f2f6a8c9fc.jpg&#x27;,</span><br><span class="line"> &#x27;460874319_0a45ab4d05.jpg&#x27;,</span><br><span class="line"> &#x27;466430434_4000737de9.jpg&#x27;,</span><br><span class="line"> &#x27;470127037_513711fd21.jpg&#x27;,</span><br><span class="line"> &#x27;474806473_ca6caab245.jpg&#x27;,</span><br><span class="line"> &#x27;475961153_b8c13fd405.jpg&#x27;,</span><br><span class="line"> &#x27;484293231_e53cfc0c89.jpg&#x27;,</span><br><span class="line"> &#x27;49375974_e28ba6f17e.jpg&#x27;,</span><br><span class="line"> &#x27;506249802_207cd979b4.jpg&#x27;,</span><br><span class="line"> &#x27;506249836_717b73f540.jpg&#x27;,</span><br><span class="line"> &#x27;512164029_c0a66b8498.jpg&#x27;,</span><br><span class="line"> &#x27;512863248_43c8ce579b.jpg&#x27;,</span><br><span class="line"> &#x27;518773929_734dbc5ff4.jpg&#x27;,</span><br><span class="line"> &#x27;522163566_fec115ca66.jpg&#x27;,</span><br><span class="line"> &#x27;522415432_2218f34bf8.jpg&#x27;,</span><br><span class="line"> &#x27;531979952_bde12b3bc0.jpg&#x27;,</span><br><span class="line"> &#x27;533848102_70a85ad6dd.jpg&#x27;,</span><br><span class="line"> &#x27;535522953_308353a07c.jpg&#x27;,</span><br><span class="line"> &#x27;540889389_48bb588b21.jpg&#x27;,</span><br><span class="line"> &#x27;541630764_dbd285d63c.jpg&#x27;,</span><br><span class="line"> &#x27;543417860_b14237f569.jpg&#x27;,</span><br><span class="line"> &#x27;560966032_988f4d7bc4.jpg&#x27;,</span><br><span class="line"> &#x27;5650366_e22b7e1065.jpg&#x27;,</span><br><span class="line"> &#x27;6240329_72c01e663e.jpg&#x27;,</span><br><span class="line"> &#x27;6240338_93729615ec.jpg&#x27;,</span><br><span class="line"> &#x27;649026570_e58656104b.jpg&#x27;,</span><br><span class="line"> &#x27;662541407_ff8db781e7.jpg&#x27;,</span><br><span class="line"> &#x27;67270775_e9fdf77e9d.jpg&#x27;,</span><br><span class="line"> &#x27;6743948_2b8c096dda.jpg&#x27;,</span><br><span class="line"> &#x27;684133190_35b62c0c1d.jpg&#x27;,</span><br><span class="line"> &#x27;69639610_95e0de17aa.jpg&#x27;,</span><br><span class="line"> &#x27;707895295_009cf23188.jpg&#x27;,</span><br><span class="line"> &#x27;7759525_1363d24e88.jpg&#x27;,</span><br><span class="line"> &#x27;795000156_a9900a4a71.jpg&#x27;,</span><br><span class="line"> &#x27;822537660_caf4ba5514.jpg&#x27;,</span><br><span class="line"> &#x27;82852639_52b7f7f5e3.jpg&#x27;,</span><br><span class="line"> &#x27;841049277_b28e58ad05.jpg&#x27;,</span><br><span class="line"> &#x27;886401651_f878e888cd.jpg&#x27;,</span><br><span class="line"> &#x27;892108839_f1aad4ca46.jpg&#x27;,</span><br><span class="line"> &#x27;938946700_ca1c669085.jpg&#x27;,</span><br><span class="line"> &#x27;957233405_25c1d1187b.jpg&#x27;,</span><br><span class="line"> &#x27;9715481_b3cb4114ff.jpg&#x27;,</span><br><span class="line"> &#x27;998118368_6ac1d91f81.jpg&#x27;,</span><br><span class="line"> &#x27;ant photos.jpg&#x27;,</span><br><span class="line"> &#x27;Ant_1.jpg&#x27;,</span><br><span class="line"> &#x27;army-ants-red-picture.jpg&#x27;,</span><br><span class="line"> &#x27;formica.jpeg&#x27;,</span><br><span class="line"> &#x27;hormiga_co_por.jpg&#x27;,</span><br><span class="line"> &#x27;imageNotFound.gif&#x27;,</span><br><span class="line"> &#x27;kurokusa.jpg&#x27;,</span><br><span class="line"> &#x27;MehdiabadiAnt2_600.jpg&#x27;,</span><br><span class="line"> &#x27;Nepenthes_rafflesiana_ant.jpg&#x27;,</span><br><span class="line"> &#x27;swiss-army-ant.jpg&#x27;,</span><br><span class="line"> &#x27;termite-vs-ant.jpg&#x27;,</span><br><span class="line"> &#x27;trap-jaw-ant-insect-bg.jpg&#x27;,</span><br><span class="line"> &#x27;VietnameseAntMimicSpider.jpg&#x27;]</span><br></pre></td></tr></table></figure><p>注意在windows下，路径使用双斜线\</p><h2 id="Dataset实操"><a href="#Dataset实操" class="headerlink" title="Dataset实操"></a>Dataset实操</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mydata</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,root_path,label_path</span>):</span><br><span class="line">        self.root_path = root_path  <span class="comment"># hymenoptera_data/hymenoptera_data/train</span></span><br><span class="line">        self.label_path = label_path  <span class="comment"># /ants</span></span><br><span class="line">        self.path = os.path.join(self.root_path,self.label_path)  <span class="comment"># 从根目录开始的绝对路径</span></span><br><span class="line">        self.image_path = os.listdir(self.path) <span class="comment"># 从根目录开始绝对路径文件夹下的对象 hymenoptera_data/hymenoptera_data/train/ants下的图片 type--&gt; list</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        image_name = self.image_path[idx] <span class="comment"># 单一的图片名称</span></span><br><span class="line">        image_item_path = os.path.join(self.root_path,self.label_path,image_name)</span><br><span class="line">        img = Image.<span class="built_in">open</span>(image_item_path)</span><br><span class="line">        label = self.label_path</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.image_path)</span><br><span class="line"></span><br><span class="line">ants_root_path = <span class="string">&quot;hymenoptera_data\\hymenoptera_data\\train&quot;</span></span><br><span class="line">ants_label_path = <span class="string">&quot;ants&quot;</span></span><br><span class="line">Ants = Mydata(ants_root_path,ants_label_path)</span><br><span class="line">Ants[<span class="number">0</span>][<span class="number">0</span>].show() <span class="comment"># 第一个0是索引，拿到第一个图像和标签，第二个0是拿到第一个图像，并显示出来</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">D:\anaconda\envs\Gpu-Pytorch\lib\site-packages\tqdm\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html</span><br><span class="line">  from .autonotebook import tqdm as notebook_tqdm</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688024599649-be5c0241-4ba7-4e71-8544-0f1407dd6e9c.png#averageHue=%23e1e5da&from=url&id=jNmXo&originHeight=824&originWidth=1208&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bee_root_path = <span class="string">&quot;hymenoptera_data\\hymenoptera_data\\train&quot;</span></span><br><span class="line">bee_label_path = <span class="string">&quot;bees&quot;</span></span><br><span class="line">Bees = Mydata(bee_root_path,bee_label_path)</span><br><span class="line">Bees[<span class="number">0</span>][<span class="number">0</span>].show()</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688024599649-be5c0241-4ba7-4e71-8544-0f1407dd6e9c.png#averageHue=%23e1e5da&from=url&id=wiTcx&originHeight=824&originWidth=1208&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建训练集</span></span><br><span class="line"></span><br><span class="line">train = Ants + Bees   <span class="comment"># 直接将数据集加起来</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the length of Ants is &quot;</span>,Ants.__len__())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the length of Bees is &quot;</span>,Bees.__len__())</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;the length of train is &quot;</span>,train.__len__())</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">the length of Ants is  124</span><br><span class="line">the length of Bees is  121</span><br><span class="line">the length of train is  245</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看是否正确</span></span><br><span class="line">train[<span class="number">123</span>][<span class="number">0</span>].show() <span class="comment"># 应该为蚂蚁</span></span><br><span class="line">train[<span class="number">124</span>][<span class="number">0</span>].show() <span class="comment"># 应该为蜜蜂</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688024599649-be5c0241-4ba7-4e71-8544-0f1407dd6e9c.png#averageHue=%23e1e5da&from=url&id=gUmQj&originHeight=824&originWidth=1208&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="><br><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688024599857-7554878b-c250-49f7-b9cd-7917140a1d45.png#averageHue=%23e0dacc&from=url&id=nHJ8C&originHeight=824&originWidth=1208&originalType=binary&ratio=1&rotation=0&showTitle=false&status=done&style=none&title="></p><h2 id="Dataset-实操二"><a href="#Dataset-实操二" class="headerlink" title="Dataset 实操二"></a>Dataset 实操二</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch学习 </span></span><br><span class="line"><span class="string">@File    ：task_3.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/6/29 14:29 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mydata</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,root_path,image_path,label_path</span>):</span><br><span class="line">        self.root_path = root_path</span><br><span class="line">        self.image_path = image_path</span><br><span class="line">        self.label_path = label_path</span><br><span class="line">        self.A_image_path = os.path.join(self.root_path,self.image_path)</span><br><span class="line">        self.A_label_path = os.path.join(self.root_path,self.label_path)</span><br><span class="line">        self.img_item = os.listdir(self.A_image_path)</span><br><span class="line">        self.label_item = os.listdir(self.A_label_path)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        img_name = self.img_item[idx]</span><br><span class="line">        img_path = os.path.join(self.A_image_path, img_name)</span><br><span class="line">        label_list = [i.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> self.label_item <span class="keyword">if</span> i.count(<span class="string">&quot;.&quot;</span>) == <span class="number">1</span>]</span><br><span class="line">        <span class="comment"># print(label_list)</span></span><br><span class="line">        <span class="keyword">if</span> img_name.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>] <span class="keyword">in</span> label_list:</span><br><span class="line">            img = Image.<span class="built_in">open</span>(img_path)</span><br><span class="line">            label_path = os.path.join(self.A_label_path,img_name.split(<span class="string">&quot;.&quot;</span>)[<span class="number">0</span>])</span><br><span class="line">            label_path += <span class="string">&quot;.txt&quot;</span></span><br><span class="line">            file = <span class="built_in">open</span>(label_path, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">            label = file.read()</span><br><span class="line">            file.close()</span><br><span class="line">            <span class="keyword">return</span> img,label</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;&#123;0&#125;没有对应的标签&quot;</span>.<span class="built_in">format</span>(img_name))</span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.img_item)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">train_ants_root_path = <span class="string">&quot;练手数据集\\train&quot;</span></span><br><span class="line">train_ants_image_path = <span class="string">&quot;ants_image&quot;</span></span><br><span class="line">train_ants_label_path = <span class="string">&quot;ants_label&quot;</span></span><br><span class="line">Ants = Mydata(train_ants_root_path,train_ants_image_path,train_ants_label_path)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(Ants.__len__()):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="built_in">print</span>(Ants[i][<span class="number">1</span>])</span><br><span class="line">    <span class="keyword">except</span> TypeError:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;跳过此张图片！&quot;</span>)</span><br><span class="line"><span class="comment"># Ants[122][0].show()</span></span><br><span class="line"><span class="comment"># print(Ants[122][1])</span></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br></pre></td><td class="code"><pre><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">formica.jpeg没有对应的标签</span><br><span class="line">跳过此张图片！</span><br><span class="line">ants</span><br><span class="line">imageNotFound.gif没有对应的标签</span><br><span class="line">跳过此张图片！</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br><span class="line">ants</span><br></pre></td></tr></table></figure><p>添加了异常捕获，解决了图片没有对应标签的问题！</p><h2 id="dataset实操三"><a href="#dataset实操三" class="headerlink" title="dataset实操三"></a>dataset实操三</h2><p>使用torchvision中的数据集创建dataset</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment"># -*- coding: UTF-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">@Project ：Pytorch_learn </span></span><br><span class="line"><span class="string">@File    ：dataset_3.py</span></span><br><span class="line"><span class="string">@IDE     ：PyCharm </span></span><br><span class="line"><span class="string">@Author  ：咋</span></span><br><span class="line"><span class="string">@Date    ：2023/7/2 14:58 </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> tensorboardX <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line">dataset = torchvision.datasets.MNIST(<span class="string">&quot;./Mnist&quot;</span>,train=<span class="literal">True</span>,download=<span class="literal">True</span>,transform=transforms.ToTensor())</span><br><span class="line">dataloader = DataLoader(dataset,batch_size=<span class="number">64</span>,shuffle=<span class="literal">False</span>,num_workers=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用tensorboard将dataloader展示出来</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;方式一</span></span><br><span class="line"><span class="string"># write = SummaryWriter(&quot;log_2&quot;)</span></span><br><span class="line"><span class="string"># count = 0</span></span><br><span class="line"><span class="string"># for data in dataloader:</span></span><br><span class="line"><span class="string">#     image,label = data</span></span><br><span class="line"><span class="string">#     # print(data[1])</span></span><br><span class="line"><span class="string">#     # print(image.shape)</span></span><br><span class="line"><span class="string">#     write.add_images(&quot;dataloader&quot;,image,count)</span></span><br><span class="line"><span class="string">#     count += 1</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 方式二</span></span><br><span class="line">write = SummaryWriter(<span class="string">&quot;log_3&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> i,data <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">    image,label = data</span><br><span class="line">    write.add_images(<span class="string">&quot;dataloader&quot;</span>,image,i)</span><br><span class="line"></span><br><span class="line">write.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/34335114/1688285573130-852a3bbe-242c-4b1f-9789-d2a3d3ae7ce9.png#averageHue=%23f58716&clientId=u0bbfe70d-00dd-4&from=paste&height=406&id=u28018417&originHeight=619&originWidth=653&originalType=binary&ratio=1.5234375&rotation=0&showTitle=false&size=47094&status=done&style=none&taskId=u2955b002-f252-4ee0-9984-5ec65a450af&title=&width=428.63589743589745" alt="image.png"><br>enumerate会将可迭代对象中的内容和其索引一起返回：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">例如对于一个seq，得到：</span><br><span class="line">(<span class="number">0</span>, seq[<span class="number">0</span>]), (<span class="number">1</span>, seq[<span class="number">1</span>]), (<span class="number">2</span>, seq[<span class="number">2</span>])</span><br></pre></td></tr></table></figure><h1 id="datalodar"><a href="#datalodar" class="headerlink" title="datalodar"></a>datalodar</h1><p>为后面的网络提供不同的数据类型</p><h1 id="自定义dataset并用datalodar加载"><a href="#自定义dataset并用datalodar加载" class="headerlink" title="自定义dataset并用datalodar加载"></a>自定义dataset并用datalodar加载</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> net <span class="keyword">import</span> Net</span><br><span class="line"><span class="keyword">import</span> softmax</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">transform_tool = transforms.ToTensor()  <span class="comment"># 创建一个transform工具</span></span><br><span class="line"><span class="comment"># # image_tensor = transform_tool(image)</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;mnist-label.txt&quot;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    label_str = f.read().strip()   <span class="comment"># 打开文件读入缓存</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Mydata</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,image_path</span>):</span><br><span class="line">        self.image_path = image_path</span><br><span class="line">        <span class="comment"># self.label_path = label_path  # /ants</span></span><br><span class="line">        self.image = os.listdir(self.image_path) <span class="comment"># 从根目录开始绝对路径文件夹下的对象 hymenoptera_data/hymenoptera_data/train/ants下的图片 type--&gt; list</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, idx</span>):</span><br><span class="line">        image_name = self.image[idx] <span class="comment"># 单一的图片名称</span></span><br><span class="line">        image_item_path = os.path.join(self.image_path,image_name)</span><br><span class="line">        img = Image.<span class="built_in">open</span>(image_item_path)</span><br><span class="line">        <span class="comment"># transform_tool = transforms.ToTensor()  # 创建一个transform工具</span></span><br><span class="line">        img = transform_tool(img)</span><br><span class="line">        labels_list = [<span class="built_in">int</span>(label) <span class="keyword">for</span> label <span class="keyword">in</span> label_str.split(<span class="string">&#x27;,&#x27;</span>)]  <span class="comment"># 读取标签，不用每次都打开</span></span><br><span class="line">        labels = np.array(labels_list)</span><br><span class="line">        label = labels[idx]</span><br><span class="line">        <span class="keyword">return</span> img,label</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.image)</span><br><span class="line"><span class="comment"># trainset = Mydata(&quot;mnist-dataset&quot;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置训练参数</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">epochs = <span class="number">5</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># 数据集</span></span><br><span class="line"><span class="comment"># transform = transforms.Compose([transforms.ToTensor(),</span></span><br><span class="line"><span class="comment">#                                 transforms.Normalize((0.5,), (0.5,))])</span></span><br><span class="line"><span class="comment"># trainset =</span></span><br><span class="line"><span class="comment"># trainset = datasets.MNIST(&#x27;~/.pytorch/MNIST_data/&#x27;, download=True, train=True, transform=transform)</span></span><br><span class="line">trainset = Mydata(<span class="string">&quot;mnist-dataset&quot;</span>)</span><br><span class="line"></span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=<span class="literal">False</span>,num_workers=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(trainloader))</span><br><span class="line"><span class="comment"># 输出提示信息</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;batch_size:&quot;</span>, batch_size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;data_batches:&quot;</span>, <span class="built_in">len</span>(trainloader))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;epochs:&quot;</span>, epochs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 神经网络</span></span><br><span class="line">net = Net().to(device)</span><br><span class="line"><span class="comment"># net.load_state_dict(torch.load(&#x27;./model/model.pth&#x27;))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 损失函数和优化器</span></span><br><span class="line"><span class="comment"># 负对数似然损失</span></span><br><span class="line">criterion = nn.NLLLoss()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.0005</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line">total_correct = <span class="number">0</span></span><br><span class="line">total_samples = <span class="number">0</span></span><br><span class="line"><span class="comment"># 训练网络</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> i, data <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader):</span><br><span class="line">        inputs, labels = data</span><br><span class="line">        inputs, labels = Variable(inputs).to(device), Variable(labels).to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 反向传播优化参数</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        <span class="comment"># outputs = int(net(inputs))</span></span><br><span class="line">        <span class="comment"># print(outputs)</span></span><br><span class="line">        labels = labels.long()</span><br><span class="line">        <span class="comment"># print(labels)</span></span><br><span class="line">        <span class="comment"># print(type(labels))</span></span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        <span class="comment"># 计算每个batch的准确率</span></span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total_samples += labels.size(<span class="number">0</span>)</span><br><span class="line">        total_correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">5</span> == <span class="number">0</span>:    <span class="comment"># 每轮输出损失值</span></span><br><span class="line">            accuracy = <span class="number">100.0</span> * total_correct / total_samples</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;[epoch: %d, batches: %d] loss: %.5f accuracy: %.2f%%&#x27;</span> %</span><br><span class="line">                  (epoch + <span class="number">1</span>, i + <span class="number">1</span>, running_loss / <span class="number">2000</span>, accuracy))</span><br><span class="line">            total_correct = <span class="number">0</span></span><br><span class="line">            total_samples = <span class="number">0</span></span><br><span class="line">            running_loss = <span class="number">0.0</span></span><br><span class="line">torch.save(net.state_dict(), <span class="string">&#x27;model.pth&#x27;</span>)  <span class="comment"># 每轮保存模型参数</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>打开文件可以在定义类之前打开，把文件信息读入缓存中，在__getitem__中读取各个标签，不用每次执行__getitem__都打开一次文件。</p><h1 id="os的一些操作"><a href="#os的一些操作" class="headerlink" title="os的一些操作"></a>os的一些操作</h1><p>windows使用两个\表示路径</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">dir_path = <span class="string">&quot;/home/aistudio&quot;</span>  <span class="comment"># 文件夹目录</span></span><br><span class="line">data_dir = os.listdir(dir_path)  <span class="comment"># 获取文件夹目录中的对象</span></span><br><span class="line">label_path = <span class="string">&quot;label&quot;</span></span><br><span class="line">all_path = os.path.join(dir_path,label_path)</span><br></pre></td></tr></table></figure>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>孤注一掷——基于文心Ernie-3.0大模型的影评情感分析</title>
      <link href="/2023/08/20/%E5%AD%A4%E6%B3%A8%E4%B8%80%E6%8E%B7%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E6%96%87%E5%BF%83Ernie-3-0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E8%AF%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/"/>
      <url>/2023/08/20/%E5%AD%A4%E6%B3%A8%E4%B8%80%E6%8E%B7%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E6%96%87%E5%BF%83Ernie-3-0%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%BD%B1%E8%AF%84%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="孤注一掷——基于文心Ernie-3-0大模型的影评情感分析"><a href="#孤注一掷——基于文心Ernie-3-0大模型的影评情感分析" class="headerlink" title="孤注一掷——基于文心Ernie-3.0大模型的影评情感分析"></a>孤注一掷——基于文心Ernie-3.0大模型的影评情感分析</h1><h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>前些天看了<font size=4 color=green><strong>《孤注一掷》</strong></font>，感觉是一个很不错的电影，<strong>狠狠劝赌！</strong></p><ul><li><p>人有两颗心，一颗贪心，一颗不甘心，诱惑的背后只有陷阱，恐惧的尽头只剩绝望。</p></li><li><p>希望大家提高防诈骗意识，<strong>别信，别贪，别冲动！</strong><br><img src="https://ai-studio-static-online.cdn.bcebos.com/e3986421f0364fc0b47fa0c5b95f24a9aa5d01b9a77d4f998755d6e60410e932"></p></li><li><p>这个项目使用文言一心大模型，对爬取的电影评论数据进行小样本的预训练学习。</p></li><li><p>使用<strong>Ernie-3.0-medium-zh</strong>大模型（感谢三岁大佬），为百亿参数知识增强的大模型，能够快速解决中文数据学习困难，准确率低的问题。</p></li><li><p>项目环境：<code>PaddlePaddle2.4.0</code>，<code>PaddleNLP2.4.2</code></p></li></ul><h2 id="一、数据直观可视化"><a href="#一、数据直观可视化" class="headerlink" title="一、数据直观可视化"></a>一、数据直观可视化</h2><p>电影《孤注一掷》豆瓣短评数据信息如下（感谢马哥<code>公众号老男孩的平凡之路</code>）</p><ul><li>共30页，600条数据</li><li>含6个字段：页码,评论者昵称,评论星级（1-5星）,评论时间,评论者IP属地,评论内容</li><li>豆瓣短评页面上最多显示30页，再往后翻页就会显示“加载中”，获取不到后面的数据，所以只有30页</li><li>对数据进行简单的处理，由于涉及到情感分类，将评星低于三星的认为差评，等于三星的认为中立，高于三星的认为好评</li></ul><h3 id="1-1-各评价所占人数"><a href="#1-1-各评价所占人数" class="headerlink" title="1.1 各评价所占人数"></a>1.1 各评价所占人数</h3><p>由于存在一定误差（比如三星的评论可能是好评也可能是差评，低于三星的评论也可能是好评，还有一些没有价值的评论），故用误差棒使结果更加严谨，从数据中统计可得：</p><ul><li><code>好评</code>：218人</li><li><code>中立</code>：159人</li><li><code>差评</code>：223人<br><img src="https://ai-studio-static-online.cdn.bcebos.com/f3094d266cac4b96839167444a84d038aa429243a11a4b4887c24c9750a00d86"></li></ul><p>可以看出三个评价的人数<code>基本相近</code></p><h3 id="1-2-词云可视化"><a href="#1-2-词云可视化" class="headerlink" title="1.2 词云可视化"></a>1.2 词云可视化</h3><ul><li><p>词云可视化可以帮助用户快速识别影评中的关键词和热门话题。通过将频率较高的词语放大显示，用户可以一目了然地了解影评的主题和重点。</p></li><li><p>我将背景设置成一个骷髅，不知道大家能不能看出来<br><img src="https://ai-studio-static-online.cdn.bcebos.com/2d9ee553231848e3982bbf4a0380626b98331e631c1c4d8bb1162068257a4eea"></p></li><li><p>由于aistudio里面词云字体会出现打不开的情况，所有我是在本地跑的，现在将代码贴在这里，感兴趣的小伙伴可以copy下来在自己的本地环境里面跑一下。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> wordcloud <span class="keyword">import</span> WordCloud  <span class="comment"># 词云库</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt  <span class="comment"># 数学绘图库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读数据</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;output.txt&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    text = f.read()</span><br><span class="line"></span><br><span class="line">mask = np.array(Image.<span class="built_in">open</span>(<span class="string">&quot;img_7.png&quot;</span>))</span><br><span class="line">wc1 = WordCloud(</span><br><span class="line">    background_color=<span class="string">&quot;white&quot;</span>,  <span class="comment"># 背景为白色</span></span><br><span class="line">    font_path=<span class="string">&#x27;C:/Windows/Fonts/msyh.ttc&#x27;</span>,  <span class="comment"># 使用的字体库:当前字体支持中文</span></span><br><span class="line">    max_words=<span class="number">2000</span>,  <span class="comment"># 最大显示的关键词数量</span></span><br><span class="line">    width=<span class="number">1000</span>,  <span class="comment"># 生成词云的宽</span></span><br><span class="line">    height=<span class="number">860</span>,  <span class="comment"># 生成词云的高</span></span><br><span class="line">    collocations=<span class="literal">False</span>,  <span class="comment"># 解决关键词重复：是否包括两个词的搭配</span></span><br><span class="line">    mask=mask</span><br><span class="line">    <span class="comment"># stopwords=STOPWORDS, #屏蔽的内容</span></span><br><span class="line">)</span><br><span class="line">wc2 = wc1.generate(text)</span><br><span class="line"></span><br><span class="line">plt.imshow(wc2)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.savefig(<span class="string">&#x27;词云.jpg&#x27;</span>, dpi=<span class="number">2600</span>, bbox_inches=<span class="string">&#x27;tight&#x27;</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">**&lt;font size=<span class="number">6</span> color=green&gt;接下来正式开始大模型之旅！**</span><br><span class="line"></span><br><span class="line"><span class="comment">## 二、更新PaddleNLP</span></span><br><span class="line">`clear_output`主要是为了清除输出信息，对更新没有影响，为了最后项目的美观，所以在最后加上了一句 `clear_output`</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="comment"># 清除输出，使项目更清晰</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> clear_output</span><br><span class="line">!pip install paddlenlp==<span class="number">2.4</span><span class="number">.2</span> -i https://pypi.org/simple</span><br><span class="line"><span class="comment"># 清除输出</span></span><br><span class="line">clear_output()</span><br></pre></td></tr></table></figure></li></ul><p>查看版本号是否正确</p><ul><li><code>paddlepaddle</code>的版本为<code>2.4.0</code>，<code>paddlenlp</code>的版本为<code>2.4.2</code></li><li>如果版本不匹配的话可能后面会出现cannot import name <code>&#39;AutoModelForSequenceclassification&#39; from paddlenlp.transfomers</code>的错误</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddlenlp</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;paddle版本&quot;</span>,paddle.__version__)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;paddlenlp版本&quot;</span>,paddlenlp.__version__)</span><br></pre></td></tr></table></figure><pre><code>paddle版本 2.4.0paddlenlp版本 2.4.2</code></pre><h2 id="二、数据处理"><a href="#二、数据处理" class="headerlink" title="二、数据处理"></a>二、数据处理</h2><ul><li>利用&#96;正则表达式清理数据</li><li>利用<code>paddlenlp.datasets</code>中的 <code>DatasetBuilder</code>函数对数据进行处理</li><li>数据变成了[{‘text_a’: ‘data’, ‘label’: label},……] 的格式</li></ul><h3 id="2-1-清洗数据"><a href="#2-1-清洗数据" class="headerlink" title="2.1 清洗数据"></a>2.1 清洗数据</h3><ul><li>使用<code>正则表达式</code>去除音频中的中文标点符号，并和标签一起写入txt文件中</li><li>用到的正则表达式为<code> re.sub(r&#39;[^\u4e00-\u9fa5a-zA-Z0-9\s]+&#39;, &#39; &#39;, content)</code></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="comment"># 读取CSV文件</span></span><br><span class="line">df = pd.read_csv(<span class="string">&#x27;data.csv&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 遍历每一行，将内容存入txt文件</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;output.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    <span class="keyword">for</span> index, row <span class="keyword">in</span> df.iterrows():</span><br><span class="line">        content = row[<span class="string">&#x27;content&#x27;</span>]</span><br><span class="line">        content =  re.sub(<span class="string">r&#x27;[^\u4e00-\u9fa5a-zA-Z0-9\s]+&#x27;</span>, <span class="string">&#x27; &#x27;</span>, content)</span><br><span class="line">        label = row[<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">        file.write(<span class="string">f&quot;<span class="subst">&#123;label&#125;</span>\t<span class="subst">&#123;content&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure><ul><li>清洗完的数据如下：</li></ul><p><img src="https://ai-studio-static-online.cdn.bcebos.com/4baf88211b974dbb86dc4bc5fc10d8503606abaf10ef4ec490d3ce2b36ead0c5"></p><h3 id="2-2-划分数据集"><a href="#2-2-划分数据集" class="headerlink" title="2.2 划分数据集"></a>2.2 划分数据集</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取output.txt文件中的内容</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;output.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    lines = file.readlines()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机打乱数据</span></span><br><span class="line">random.shuffle(lines)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算切分的索引</span></span><br><span class="line">total_lines = <span class="built_in">len</span>(lines)</span><br><span class="line">train_end = <span class="built_in">int</span>(total_lines * <span class="number">0.7</span>)</span><br><span class="line">validation_end = <span class="built_in">int</span>(total_lines * <span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 切分数据</span></span><br><span class="line">train_data = lines[:train_end]</span><br><span class="line">validation_data = lines[train_end:validation_end]</span><br><span class="line">test_data = lines[validation_end:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据写入train.txt</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;train.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.writelines(train_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据写入validation.txt</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;validation.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.writelines(validation_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将数据写入test.txt</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;test.txt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">    file.writelines(test_data)</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="2-3-加载数据"><a href="#2-3-加载数据" class="headerlink" title="2.3 加载数据"></a>2.3 加载数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入DatasetBuilder</span></span><br><span class="line"><span class="keyword">from</span> paddlenlp.datasets <span class="keyword">import</span> DatasetBuilder</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">NewsData</span>(<span class="title class_ inherited__">DatasetBuilder</span>):</span><br><span class="line">    SPLITS = &#123;</span><br><span class="line">        <span class="string">&#x27;train&#x27;</span>: <span class="string">&#x27;/home/aistudio/train.txt&#x27;</span>,  <span class="comment"># 训练集</span></span><br><span class="line">        <span class="string">&#x27;dev&#x27;</span>: <span class="string">&#x27;/home/aistudio/validation.txt&#x27;</span>,      <span class="comment"># 验证集</span></span><br><span class="line">        <span class="string">&#x27;test&#x27;</span>: <span class="string">&#x27;/home/aistudio/test.txt&#x27;</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_get_data</span>(<span class="params">self, mode, **kwargs</span>):</span><br><span class="line">        filename = self.SPLITS[mode]</span><br><span class="line">        <span class="keyword">return</span> filename</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_read</span>(<span class="params">self, filename</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;读取数据&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(filename, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> f:</span><br><span class="line">                <span class="keyword">if</span> line == <span class="string">&#x27;\n&#x27;</span>:</span><br><span class="line">                    <span class="keyword">continue</span></span><br><span class="line">                data = line.strip().split(<span class="string">&quot;\t&quot;</span>)    <span class="comment"># 以&#x27;\t&#x27;分隔各列</span></span><br><span class="line">                label, text_a = data</span><br><span class="line">                text_a = text_a.replace(<span class="string">&quot; &quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">                <span class="keyword">if</span> label <span class="keyword">in</span> [<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>]:</span><br><span class="line">                    <span class="keyword">yield</span> &#123;<span class="string">&quot;text_a&quot;</span>: text_a, <span class="string">&quot;label&quot;</span>: label&#125;  <span class="comment"># 此次设置数据的格式为：text_a,label，可以根据具体情况进行修改</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">get_labels</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="keyword">return</span> label_list   <span class="comment"># 类别标签</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义数据集加载函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">load_dataset</span>(<span class="params">name=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 data_files=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 splits=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 lazy=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                 **kwargs</span>):</span><br><span class="line">   </span><br><span class="line">    reader_cls = NewsData  <span class="comment"># 加载定义的数据集格式</span></span><br><span class="line">    <span class="built_in">print</span>(reader_cls)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> name:</span><br><span class="line">        reader_instance = reader_cls(lazy=lazy, **kwargs)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        reader_instance = reader_cls(lazy=lazy, name=name, **kwargs)</span><br><span class="line">    datasets = reader_instance.read_datasets(data_files=data_files, splits=splits)</span><br><span class="line">    <span class="keyword">return</span> datasets</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载训练和验证集</span></span><br><span class="line">label_list = [<span class="string">&#x27;0&#x27;</span>, <span class="string">&#x27;1&#x27;</span>]</span><br><span class="line">train_ds, dev_ds, text_t = load_dataset(splits=[<span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;dev&#x27;</span>, <span class="string">&#x27;test&#x27;</span>])</span><br></pre></td></tr></table></figure><pre><code>&lt;class &#39;__main__.NewsData&#39;&gt;</code></pre><h3 id="2-4-展示数据"><a href="#2-4-展示数据" class="headerlink" title="2.4 展示数据"></a>2.4 展示数据</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train_ds[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure><pre><code>[&#123;&#39;text_a&#39;: &#39;人有两颗心一颗是贪心一颗是不甘心&#39;, &#39;label&#39;: 0&#125;, &#123;&#39;text_a&#39;: &#39;一边张灯结彩一边天人永别太讽刺了&#39;, &#39;label&#39;: 0&#125;, &#123;&#39;text_a&#39;: &#39;C从我自己的观影感受里就可以感知到观众对于真正的中国犯罪电影有多么的渴望犯罪链条上每一个奇观展现都让我觉得抓眼带感这不是所谓的短视频猎奇而是我们真的想要看国内电影里存在这样的东西一些陆家嘴之狼CBD风云最大的问题当然是没有人物也没有主题为正的导向更是让它不可能具有任何的人性深度但值得肯定的是申奥还是一定程度上把人对金钱的狂热拍了出来&#39;,  &#39;label&#39;: 0&#125;, &#123;&#39;text_a&#39;: &#39;暑期档继续发疯紧张刺激&#39;, &#39;label&#39;: 0&#125;, &#123;&#39;text_a&#39;: &#39;请不要在反诈宣传片里插播偶像剧&#39;, &#39;label&#39;: 1&#125;]</code></pre><h2 id="三、RNIE-3-0文心大模型"><a href="#三、RNIE-3-0文心大模型" class="headerlink" title="三、RNIE 3.0文心大模型"></a>三、RNIE 3.0文心大模型</h2><p><a href="https://arxiv.org/abs/2112.12731">ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation</a> 论文摘要：<code>经过预训练的语言模型在各种自然语言处理（NLP）任务中取得了最先进的结果。GPT-3已经表明，扩大预先训练的语言模型可以进一步开发它们的巨大潜力。最近提出了一个名为ERNIE3.0的统一框架，用于预训练大规模知识增强模型，并训练了一个具有100亿个参数的模型。ERNIE3.0在各种NLP任务上的表现优于最先进的模型。为了探索扩大ERNIE3.0的性能，我们在飞桨平台上训练了一个名为ERNIE3.0Titan的数百亿参数模型，其参数高达2600亿。此外，我们设计了一个自监督的对抗性损失和一个可控的语言建模损失，使ERNIE3.0 Titan生成可信和可控的文本。为了减少计算开销和碳排放，我们为ERNIE3.0 Titan提出了一个在线蒸馏框架，教师模型将同时教授学生和训练自己。ERNIE3.0泰坦是迄今为止中国最大的密集预训练模型。经验结果表明，ERNIE3.0 Titan在68个NLP数据集上的性能优于最先进的模型。</code><br><img src="https://ai-studio-static-online.cdn.bcebos.com/71e361e00b7f41a99710abe7537f54ccd77f9c56ebf34c36bb98499173465378"><br><code>两种生成机制的示意图（左）和预训练的数据策略（右）。绿色、橙色和蓝色的方块表示源文本、目标文本和人造符号。</code><br><img src="https://ai-studio-static-online.cdn.bcebos.com/64da5eca8ed34b8ea38c04be2c0527211799a24565364f6a87c1ef66717958ba"></p><p><code>消融研究结果</code></p><h3 id="3-1-导入模型"><a href="#3-1-导入模型" class="headerlink" title="3.1 导入模型"></a>3.1 导入模型</h3><p>详细教程可以参考<a href="https://paddlenlp.readthedocs.io/zh/latest/model_zoo/index.html">PaddleNLP Transformer预训练模型</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line"><span class="keyword">import</span> paddlenlp</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddlenlp.transformers <span class="keyword">import</span> AutoModelForSequenceClassification, AutoTokenizer</span><br><span class="line">model_name = <span class="string">&quot;ernie-3.0-medium-zh&quot;</span></span><br><span class="line">model = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=<span class="number">2</span>)</span><br><span class="line">tokenizer = AutoTokenizer.from_pretrained(model_name)</span><br></pre></td></tr></table></figure><pre><code>[2023-08-20 17:09:48,154] [    INFO] - We are using &lt;class &#39;paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification&#39;&gt; to load &#39;ernie-3.0-medium-zh&#39;.[2023-08-20 17:09:48,159] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh[2023-08-20 17:09:48,162] [    INFO] - Downloading ernie_3.0_medium_zh.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams100%|██████████| 313M/313M [00:09&lt;00:00, 32.9MB/s] W0820 17:09:58.220381   204 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2W0820 17:09:58.224973   204 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.[2023-08-20 17:10:01,278] [    INFO] - We are using &lt;class &#39;paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer&#39;&gt; to load &#39;ernie-3.0-medium-zh&#39;.[2023-08-20 17:10:01,282] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh[2023-08-20 17:10:01,285] [    INFO] - Downloading ernie_3.0_medium_zh_vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt100%|██████████| 182k/182k [00:00&lt;00:00, 9.63MB/s][2023-08-20 17:10:01,391] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/tokenizer_config.json[2023-08-20 17:10:01,394] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/special_tokens_map.json</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> partial</span><br><span class="line"><span class="keyword">from</span> paddlenlp.data <span class="keyword">import</span> Stack, <span class="type">Tuple</span>, Pad</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span>  convert_example, create_dataloader</span><br><span class="line"><span class="comment"># 模型运行批处理大小</span></span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">max_seq_length = <span class="number">128</span></span><br><span class="line"></span><br><span class="line">trans_func = partial(</span><br><span class="line">    convert_example,</span><br><span class="line">    tokenizer=tokenizer,</span><br><span class="line">    max_seq_length=max_seq_length)</span><br><span class="line">batchify_fn = <span class="keyword">lambda</span> samples, fn=<span class="type">Tuple</span>(</span><br><span class="line">    Pad(axis=<span class="number">0</span>, pad_val=tokenizer.pad_token_id),  <span class="comment"># input</span></span><br><span class="line">    Pad(axis=<span class="number">0</span>, pad_val=tokenizer.pad_token_type_id),  <span class="comment"># segment</span></span><br><span class="line">    Stack(dtype=<span class="string">&quot;int64&quot;</span>)  <span class="comment"># label</span></span><br><span class="line">): [data <span class="keyword">for</span> data <span class="keyword">in</span> fn(samples)]</span><br><span class="line">train_data_loader = create_dataloader(</span><br><span class="line">    train_ds,</span><br><span class="line">    mode=<span class="string">&#x27;train&#x27;</span>,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    batchify_fn=batchify_fn,</span><br><span class="line">    trans_fn=trans_func)</span><br><span class="line">dev_data_loader = create_dataloader(</span><br><span class="line">    dev_ds,</span><br><span class="line">    mode=<span class="string">&#x27;dev&#x27;</span>,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    batchify_fn=batchify_fn,</span><br><span class="line">    trans_fn=trans_func)</span><br></pre></td></tr></table></figure><h3 id="3-2-模型训练"><a href="#3-2-模型训练" class="headerlink" title="3.2 模型训练"></a>3.2 模型训练</h3><p>数据量太少了，很容易过拟合，这里的的</p><ul><li>epoch设置成20</li><li>weight_decay 设置成0.1</li><li>learning_rate 设置成 5e-6 </li><li>大概两分钟即可训练完成</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddlenlp <span class="keyword">as</span> ppnlp</span><br><span class="line"><span class="keyword">import</span> paddle</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> paddlenlp.transformers <span class="keyword">import</span> LinearDecayWithWarmup</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练过程中的最大学习率</span></span><br><span class="line">learning_rate = <span class="number">5e-6</span> </span><br><span class="line"><span class="comment"># 训练轮次</span></span><br><span class="line">epochs = <span class="number">20</span> <span class="comment">#3</span></span><br><span class="line"><span class="comment"># 学习率预热比例</span></span><br><span class="line">warmup_proportion = <span class="number">0.3</span></span><br><span class="line"><span class="comment"># 权重衰减系数，类似模型正则项策略，避免模型过拟合</span></span><br><span class="line">weight_decay = <span class="number">0.1</span></span><br><span class="line"></span><br><span class="line">num_training_steps = <span class="built_in">len</span>(train_data_loader) * epochs</span><br><span class="line">lr_scheduler = LinearDecayWithWarmup(learning_rate, num_training_steps, warmup_proportion)</span><br><span class="line">optimizer = paddle.optimizer.AdamW(</span><br><span class="line">    learning_rate=lr_scheduler,</span><br><span class="line">    parameters=model.parameters(),</span><br><span class="line">    weight_decay=weight_decay,</span><br><span class="line">    apply_decay_param_fun=<span class="keyword">lambda</span> x: x <span class="keyword">in</span> [</span><br><span class="line">        p.name <span class="keyword">for</span> n, p <span class="keyword">in</span> model.named_parameters()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">any</span>(nd <span class="keyword">in</span> n <span class="keyword">for</span> nd <span class="keyword">in</span> [<span class="string">&quot;bias&quot;</span>, <span class="string">&quot;norm&quot;</span>])</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">criterion = paddle.nn.loss.CrossEntropyLoss()</span><br><span class="line">metric = paddle.metric.Accuracy()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> paddle.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> evaluate</span><br><span class="line">all_train_loss=[]</span><br><span class="line">all_train_accs = []</span><br><span class="line">Batch=<span class="number">0</span></span><br><span class="line">Batchs=[]</span><br><span class="line">global_step = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, epochs + <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> step, batch <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_data_loader, start=<span class="number">1</span>):</span><br><span class="line">        input_ids, segment_ids, labels = batch</span><br><span class="line">        logits = model(input_ids, segment_ids)</span><br><span class="line">        loss = criterion(logits, labels)</span><br><span class="line">        probs = F.softmax(logits, axis=<span class="number">1</span>)</span><br><span class="line">        correct = metric.compute(probs, labels)</span><br><span class="line">        metric.update(correct)</span><br><span class="line">        acc = metric.accumulate()</span><br><span class="line">        global_step += <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> global_step % <span class="number">10</span> == <span class="number">0</span> :</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;global step %d, epoch: %d, batch: %d, loss: %.5f, acc: %.5f&quot;</span> % (global_step, epoch, step, loss, acc))</span><br><span class="line">            Batch += <span class="number">10</span> </span><br><span class="line">            Batchs.append(Batch)</span><br><span class="line">            all_train_loss.append(loss)</span><br><span class="line">            all_train_accs.append(acc)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        lr_scheduler.step()</span><br><span class="line">        optimizer.clear_grad()</span><br><span class="line">    evaluate(model, criterion, metric, dev_data_loader)</span><br><span class="line"></span><br><span class="line">model.save_pretrained(<span class="string">&#x27;/home/aistudio/checkpoint&#x27;</span>)</span><br><span class="line">tokenizer.save_pretrained(<span class="string">&#x27;/home/aistudio/checkpoint&#x27;</span>)</span><br></pre></td></tr></table></figure><pre><code>eval loss: 0.75054, accu: 0.43902global step 10, epoch: 2, batch: 2, loss: 0.66468, acc: 0.59375eval loss: 0.75193, accu: 0.43902global step 20, epoch: 3, batch: 4, loss: 0.57682, acc: 0.64062eval loss: 0.75422, accu: 0.43902global step 30, epoch: 4, batch: 6, loss: 0.64896, acc: 0.56771eval loss: 0.74524, accu: 0.43902global step 40, epoch: 5, batch: 8, loss: 0.62321, acc: 0.62205eval loss: 0.75564, accu: 0.43902eval loss: 0.77395, accu: 0.43902global step 50, epoch: 7, batch: 2, loss: 0.56548, acc: 0.65625eval loss: 0.73238, accu: 0.43902global step 60, epoch: 8, batch: 4, loss: 0.57789, acc: 0.67969eval loss: 0.74135, accu: 0.46341global step 70, epoch: 9, batch: 6, loss: 0.57494, acc: 0.70312eval loss: 0.71202, accu: 0.51220global step 80, epoch: 10, batch: 8, loss: 0.43934, acc: 0.76378eval loss: 0.72221, accu: 0.53659eval loss: 0.71013, accu: 0.57317global step 90, epoch: 12, batch: 2, loss: 0.44184, acc: 0.87500eval loss: 0.72470, accu: 0.57317global step 100, epoch: 13, batch: 4, loss: 0.34039, acc: 0.90625eval loss: 0.71655, accu: 0.63415global step 110, epoch: 14, batch: 6, loss: 0.21924, acc: 0.93229eval loss: 0.78495, accu: 0.62195global step 120, epoch: 15, batch: 8, loss: 0.21976, acc: 0.95669eval loss: 0.78816, accu: 0.64634eval loss: 0.88699, accu: 0.59756global step 130, epoch: 17, batch: 2, loss: 0.13201, acc: 0.95312eval loss: 0.83912, accu: 0.64634global step 140, epoch: 18, batch: 4, loss: 0.13333, acc: 0.97656eval loss: 0.79599, accu: 0.65854global step 150, epoch: 19, batch: 6, loss: 0.11692, acc: 0.98958eval loss: 0.89906, accu: 0.63415global step 160, epoch: 20, batch: 8, loss: 0.11152, acc: 0.96457eval loss: 0.91676, accu: 0.63415[2023-08-20 17:10:31,859] [    INFO] - tokenizer config file saved in /home/aistudio/checkpoint/tokenizer_config.json[2023-08-20 17:10:31,863] [    INFO] - Special tokens file saved in /home/aistudio/checkpoint/special_tokens_map.json(&#39;/home/aistudio/checkpoint/tokenizer_config.json&#39;, &#39;/home/aistudio/checkpoint/special_tokens_map.json&#39;, &#39;/home/aistudio/checkpoint/added_tokens.json&#39;)</code></pre><h3 id="3-3-可视化训练曲线"><a href="#3-3-可视化训练曲线" class="headerlink" title="3.3 可视化训练曲线"></a>3.3 可视化训练曲线</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">draw_train_acc</span>(<span class="params">Batchs, train_accs,train_loss</span>):</span><br><span class="line">    title=<span class="string">&quot;training accs&quot;</span></span><br><span class="line">    plt.title(title, fontsize=<span class="number">24</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&quot;batch&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;acc&quot;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">    plt.plot(Batchs, train_accs, color=<span class="string">&#x27;green&#x27;</span>, label=<span class="string">&#x27;training accs&#x27;</span>)</span><br><span class="line">    plt.plot(Batchs, train_loss, color=<span class="string">&#x27;red&#x27;</span>, label=<span class="string">&#x27;training loss&#x27;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line">draw_train_acc(Batchs,all_train_accs,all_train_loss)</span><br></pre></td></tr></table></figure><p><img src="/output_34_0.png" alt="png"></p><h3 id="3-5-模型预测"><a href="#3-5-模型预测" class="headerlink" title="3.5 模型预测"></a>3.5 模型预测</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载模型参数</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> paddle</span><br><span class="line">params_path = <span class="string">&#x27;checkpoint/model_state.pdparams&#x27;</span></span><br><span class="line"><span class="keyword">if</span> params_path <span class="keyword">and</span> os.path.isfile(params_path):</span><br><span class="line">    state_dict = paddle.load(params_path)</span><br><span class="line">    model.set_dict(state_dict)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Successful Loaded down!&quot;</span>)</span><br></pre></td></tr></table></figure><pre><code>Successful Loaded down!</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> utils <span class="keyword">import</span> predict</span><br><span class="line">batch_size = <span class="number">32</span></span><br><span class="line">data = text_t</span><br><span class="line">label_map = &#123;<span class="number">0</span>: <span class="string">&#x27;0&#x27;</span>, <span class="number">1</span>: <span class="string">&#x27;1&#x27;</span>,<span class="number">2</span>:<span class="string">&#x27;2&#x27;</span>&#125;</span><br><span class="line">results = predict(</span><br><span class="line">    model, data, tokenizer, label_map, batch_size=batch_size)</span><br><span class="line"><span class="keyword">for</span> idx, text <span class="keyword">in</span> <span class="built_in">enumerate</span>(data):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Data: &#123;&#125; \t Lable: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(text, results[idx]))</span><br></pre></td></tr></table></figure><pre><code>Data: &#123;&#39;text_a&#39;: &#39;阿才太帅了纯爱战神啊阿天那条线是最令人唏嘘的阿天母亲的演的太好了这边哭天抢地下一个镜头就是放鞭炮庆祝的转场戏剧性拉满&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;这种宣传片为啥不在电视或网络上免费普及给广大群众呢还让人民群众花银子受俩小时的教育把坏人往有血有肉有情有义里演成大活人把好人往假大空伟光正里演成稻草人真是的&#39;, &#39;label&#39;: 1&#125;  Lable: 1Data: &#123;&#39;text_a&#39;: &#39;这个故事告诉我们只要长的好看有才华就算被拐卖到境外也可以被编剧老师眷顾这部片跟奈飞的距离差了3个陈思诚反诈宣传片从预告片就开始在诈骗&#39;, &#39;label&#39;: 1&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;反诈宣传片但是现实绝对比电影更残酷&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;母亲从门框伸出的手拉不回被贪心拖向地狱的儿荷官从屏幕伸出的手推下了想要上岸却坠落的人这边是关在牢笼里绑在石头上的动物那边是晒出来也会发霉刺进去不会流血的黑心我以为吞得下秘密你以为赚得到真金用筷子夹了一张纸钞从抽屉拿走了一块玉镯我用它来孤注一掷却满盘皆输&#39;, &#39;label&#39;: 1&#125;  Lable: 1Data: &#123;&#39;text_a&#39;: &#39;很现实电信诈骗真的远远比我们想的恐怖就在前段时间我的朋友才刚刚被骗了几万块就渐渐被带进去了当突然意识到的时候已经晚了每个人物都很饱满很现实是因为结局并不是合家欢的这真的除不尽不仅要靠国家更要靠自己甄别并不是聪明就不会被骗全员演技在线算是这段时间让人眼前一亮的电影了&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;命题作文中表现较好的但现实里不会有坏人的仁慈&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;炸裂今年最牛最棒最赞最精彩国产片&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;开头很好后面就编得不行主次不分了不过7分没问题为了正常上映很多黄暴没有拍出来点到为止放在90年代的香港拍那就更好了&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;现实主义题材是目前国内适时应该出现的反诈电影本片用三分之一段落描述潘生和梁安娜被骗进诈骗团伙有用三分之一的段落完整揭示一个真实上当人生被毁的案例后三分之一是艰难反诈斗争的正能量宁浩在本片虽然之挂名监制但很明显给导演申奥的助力很多孤注一掷的节奏很好而且第二段真实诈骗段落的展开深入精彩有力而且孤在强调犯罪者的狡诈和阴险之外还保留了他们的人性让孤的结局更真实更有余味&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;潘生安娜阿天三条故事线都很有警示作用瓦里只会比电影中更残忍更癫狂推荐观看全民防诈少一点人间悲剧上一次看孙阳还是在过春天上一次看王传君还是无名所以阿才和陆经理又是怎么上的贼船呢很高兴这俩角色都没完全偏平化还有最后一个镜头脑袋发麻申奥导演可以的&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;看哭了咱就是说阿天的父母该有多么心痛啊&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;比较碎人物描摹和事件编排节奏都虎头蛇尾空有一个略显不伦不类的花架子几次视角的转换不如直接做成接力式的叙事结构暴力氛围也一般想想南车摩托车飞头的突然震撼最吃惊的是张艺兴这拉胯演技对标的竟是胡歌被抓前的一段妆造都是比着胡歌来的吧咏梅封后后的表演面瘫感更重了不能说演的不好就有种随它吧老娘想演就来一段不想演你也给我瞪着眼看着的感觉&#39;, &#39;label&#39;: 1&#125;  Lable: 1Data: &#123;&#39;text_a&#39;: &#39;几个人物挺出彩的前半段远好于后半段教育意义远大于艺术价值&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;更像网剧一些剧作可以再顺畅一些张艺兴这人设在片头的动机太牵强了在线教育老总那条线也直接断了倒是任务片里的私货在线教育和传销作比民众围殴警察有点意思7&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;在网络世界里看着形形色色的人可能一直被锤炼一直不服输的张艺兴就是申奥导演最想要抓住的人物特质张艺兴也做到了演绎潘生不仅是把绝地求生的人物体现出来也是把希望送给了每一位观影的观众&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;和现实最大的区别就是阿才不会心软&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;16最恶劣的那种电影之一简单粗暴非常剥削在大旗下一步一步一段一段逼人接受请君入瓮仿佛新秩序式的那种缺点在看似复杂的行动中对观众的操纵性过强不留一点空间&#39;, &#39;label&#39;: 1&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;说不上哪里好但又不觉得差给五星觉得高但不给五星又觉得对不起我观看时不由自主的种种反应里面所有以前我认为演戏突兀尴尬的几位在里面表演都出奇的流畅和合适一点不出戏节奏把控也很好还真挺震撼的但不是因为血腥是因为心底的恐惧代入到自己身上的绝望美中不足阿才长太帅了要是个又丑又邋遢猥琐的放了顶多觉得良心发现或者还有后招但是这个演员太帅了放了的场景让我衍生出了几秒恋爱脑降低了本片的警示意味和严肃性真是不应该啊不应该是说我见缝插针恋爱脑不应该&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;前面还是电影后面就成宣传片了主角从受害人变成了咏梅关键破案过程也不好看神兵天降加反派降智叙事混乱加节奏仓促我不知道那个馒头是怎么如此精准地投递给张艺兴的而他又怎么瞬间就明白了火柴盒的用途还有个让我不满但也许观众会觉得很爽的地方就是影片有很多暴力与性暗示镜头这些更多是商业噱头看不出对这些受害者有什么人文关怀&#39;, &#39;label&#39;: 1&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;呃我就说一句能不能别把反派里的男人塑造的情深似海了逃出缅北靠爱情就真的不要这样好烦啊&#39;, &#39;label&#39;: 1&#125;  Lable: 1Data: &#123;&#39;text_a&#39;: &#39;放走金晨那段纯属强行给反派降智&#39;, &#39;label&#39;: 1&#125;  Lable: 1Data: &#123;&#39;text_a&#39;: &#39;为什么从广州去新加坡还需要转机这么离谱从一开始故事就不成立了槽点不胜枚举年度诈骗电影&#39;, &#39;label&#39;: 1&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;拍出了受害者的可恨拍出了诈骗者的迫不得已良心未泯反诈宣传片诈骗工厂宣传片&#39;, &#39;label&#39;: 1&#125;  Lable: 1Data: &#123;&#39;text_a&#39;: &#39;看似反诈科普实则利用血腥和暴力场面恫吓国民让大家趁早打消出国念头把钱留给内循环这与中式家长动辄恐吓小孩的祖传教育思想如出一辙近年来国产商业片只要涉及异域必定要服膺一种外国即地狱风景这边独好的保守主义思潮这当然是一场属于部分民众和宣传工具的双向奔赴你甚至很难苛责一个背刺字幕组和靠抖音热门拍片的导演拍出这样一部前一半剥削电影后一半战狼出征的怪胎毕竟他最后会带着大几十亿的票房骄傲地反问你一句人民群众喜闻乐见你不喜欢你算老几&#39;, &#39;label&#39;: 1&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;王大陆演技不错&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;影片本身承担了很重的责任在这个框架内主创已经尽力拉高了影片的可看性在一切都为一个大的主题辅助的前提下角色符号化几乎是不可避免的看完影片观众记住电信诈骗的危害就行了关心不关心角色不是重点但我还是想呼吁适当的分级或者统一审查标准不要那边要求不能出现红色的血这边人脑袋上扎钉子&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;骗子太可恶了&#39;, &#39;label&#39;: 0&#125;  Lable: 1Data: &#123;&#39;text_a&#39;: &#39;演员张艺兴值得信赖为了过审只能舍掉一些细节理想化一下结局&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;不开玩笑这个开分绝对偏低了不说剧情紧张刺激猎奇更多的是影片本身的普世价值和社会意义过审不容易目睹过身边的人赌博以及被骗的真实经历一点也不夸张真诚地推荐所有人以及带着家人一起看对小广告深恶痛绝反诈宣传从我做起&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;有教育意义诈骗戏份可大学生和警察戏份比较不好看喜欢里面的孙阳&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;极其扯淡的电影甚至骂都是浪费时间和人生大事一样浪费好题材整部电影一盘散沙从被骗到诈骗的经历再到受害者的故事再到破获案件的过程没有一个部分拍好的花钱去看电影就好比你花钱去看cctv的公益广告整部电影亮点只有王传君但如此傻逼的剧情把这个角色都搞得水泄不通诈骗犯有兄弟情有爱情TM来搞笑的伟光正男主真的全场尬住ok申奥可以拉进黑名单了&#39;, &#39;label&#39;: 1&#125;  Lable: 1Data: &#123;&#39;text_a&#39;: &#39;我这辈子是不去东南亚了&#39;, &#39;label&#39;: 0&#125;  Lable: 1Data: &#123;&#39;text_a&#39;: &#39;完成度一般演技也掉线叙事缺逻辑编剧不给力安娜和潘生出戏让人懵宁浩加申奥效果不太妙&#39;, &#39;label&#39;: 1&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;那么多国产片歌功颂德描绘盛世粉饰太平至少它直面了人生的恶人性的恶人的恶哪怕只是一小部分走出影院是夏日傍晚热浪蝉鸣车流人群街道路边摊即使裹挟着灰尘与嘈杂但一切都很真实充满烟火气仿佛自己也刚经历了一场暗夜之行而重返人间忽然好想去找家小店坐下来喝碗粉丝汤&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;烂&#39;, &#39;label&#39;: 1&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;七位主角和一众黄金配角的戏非常精彩让影片远超我预期逻辑硬漏洞不去想不去提单纯为看到周也开心也为看到咏梅孙阳王传君开心孙阳演技大进步&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;孙阳像辣椒炒肉油辣得刚好黄艺馨演受刑比金晨好500个张艺兴&#39;, &#39;label&#39;: 1&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;用一组狂派以暴制暴莫名想起王道吉&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;片子本身挺扎实作为半命题作文故事完整演员发挥OK除了某些不得不做的戏剧性设置如金晨被孙阳恋爱脑给救了基本拥有了与其宣传话题匹配的可看性抖音密集投放两个月的短视频宣传也被证明这是抓住大陆下沉市场以获得最大路人关注榨取最广大345678线城市票房的最优手段当然这样的宣传手段也得益于本片自身所拥有的优秀话题性即非常贴合时下缅北诈骗这一社会热点两相结合之下本片与最广大普通观众群体神奇地达成了双向奔赴那句最朴实的价值观念多一人观影少一人受骗的口号也发挥出了实实在在的作用个人看完之后听到身边很多人都在交流是被前期宣传吸引来的看完之后也确实得到了一点关于诈骗的小小震撼和警示私以为这就很不错了豆瓣这群文青们一个个自恃智商奇高不会受骗反而纷纷以观看此片为受诈也挺可笑&#39;, &#39;label&#39;: 0&#125;  Lable: 0Data: &#123;&#39;text_a&#39;: &#39;社会热点自然会很火但确实把赌博境外诈骗这个产业链有好好表达了最重要是这就发生在我们每个人身边希望这更有社会现实意义的电影被更多人看到&#39;, &#39;label&#39;: 0&#125;  Lable: 0</code></pre><p>可以看到有正确的也有错误的，整体来说还是正确的多一些，我觉得主要的问题在于数据量太少了，训练的数据量至少要上万，但是由于这是个小demo初体验项目，影刺没有爬取太多的数据，只有区区600条，用于训练的只用420条数据，很容易造成过拟合的情况，导致模型在测试集、验证集上面的效果并不好。<br><img src="https://ai-studio-static-online.cdn.bcebos.com/df71cd0ded03423b829b21befb467cc85979e7b478704cf88fac329c3afa96b6"></p><h2 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a>四、总结</h2><ul><li>通过这个项目了解了文心大模型Ernie-3.0的使用方法</li><li>采用超小样本的预训练对现在非常火的孤注一掷电影影评进行分析</li><li>整体来说，效果还算不错</li><li>大多数人进了缅北的人，并没有成为潘生，多数是悲惨的一生</li><li><strong>珍爱生命，远离诈骗，远离赌博</strong>！<br><img src="https://ai-studio-static-online.cdn.bcebos.com/c9b8752bcca84ca3be76bda889286bb1da194be4dc984261a318f56207915f63"></li></ul><h2 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h2><h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul><li><a href="https://aistudio.baidu.com/projectdetail/5125584?channelType=0&channel=0">三岁大佬的基于Ernie-3.0的电影评论情感分析</a></li><li><a href="https://arxiv.org/abs/2112.12731">ERNIE 3.0 Titan: Exploring Larger-scale Knowledge Enhanced Pre-training for Language Understanding and Generation</a></li><li><a href="https://paddlenlp.readthedocs.io/zh/latest/model_zoo/index.html">PaddleNLP Transformer预训练模型</a></li><li><a href="https://github.com/PaddlePaddle/PaddleNLP">PaddleNlp-Github</a></li></ul><h3 id="作者简介"><a href="#作者简介" class="headerlink" title="作者简介"></a>作者简介</h3><ul><li>作者为一名在校大三学生，<strong>人工智能专业</strong></li><li>学习方向：<strong>深度学习和计算机视觉</strong></li><li>百度飞桨PPDE，百度飞桨领航团成员，阿里云开发者社区博客专家，<strong>csdn人工智能领域新星创作者 万粉博主</strong></li></ul><ul><li><a href="https://github.com/lzypython">Github主页</a>：<a href="https://github.com/lzypython">https://github.com/lzypython</a></li><li><a href="https://www.lizhiyang.xyz/">个人博客主页</a>：<a href="https://www.lizhiyang.xyz/">https://www.lizhiyang.xyz/</a></li><li><a href="https://lizhiyang.blog.csdn.net/">CSDN主页</a>：<a href="https://lizhiyang.blog.csdn.net/">https://lizhiyang.blog.csdn.net/</a></li></ul><p><font size=5><strong>欢迎关注，交流学习！</strong></font></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
